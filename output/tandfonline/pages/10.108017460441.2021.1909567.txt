<div id="s0001" class="NLM_sec NLM_sec-type_intro NLM_sec_level_1">
 <h2 id="_i3" class="section-heading-2">1. Introduction</h2>
 <p>Machine learning algorithms have been widely applied for computer-assisted drug discovery [<span class="ref-lnk lazy-ref"><a data-rid="cit0001 cit0002 cit0003" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>1–3</a></span>]. Deep learning approaches, that is, artificial neural networks with several hidden processing layers [<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>4</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>5</a></span>], have recently gathered renewed attention owing to their ability to perform automatic feature extractions from the input data, and their potential to capture nonlinear input–output relationships. These properties of deep learning techniques complement traditional machine learning approaches that rely on human-crafted molecular descriptors [<span class="ref-lnk lazy-ref"><a data-rid="cit0006" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>6</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0007" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>7</a></span>]. Drug discovery has experienced a relatively late resurgence in the interest for deep learning[<span class="ref-lnk lazy-ref"><a data-rid="cit0008" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>8</a></span>], which already led to an unprecedented explosion of novel modeling approaches and applications [<span class="ref-lnk lazy-ref"><a data-rid="cit0009 cit0010 cit0011 cit0012" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>9–12</a></span>]. Many areas of the chemical sciences have already benefited from the ever-advancing developments in deep learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0013 cit0014 cit0015" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>13–15</a></span>]. This opinion article delineates, through examples, some of the aspects that have allowed deep learning methodologies to flourish, and in some cases, outperform the existing approaches in chemoinformatics. Specifically, ligand-based quantitative structure-activity/property relationship (QSAR/QSPR), as well as structure-based modeling, de novo molecular design, and synthesis prediction are addressed (<a href="#f0001">Figure 1</a>). We also highlight the limitations of contemporary artificial intelligence (AI) in each of the considered topics and predict how it could shape the future landscape of computer-assisted drug discovery.</p>
 <div class="figure figureViewer" id="f0001">
  <div class="hidden figureViewerArticleInfo">
   <span class="figViewerTitle">Artificial intelligence in drug discovery: recent advances and future perspectives</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Jim%C3%A9nez-Luna%2C+Jos%C3%A9"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Jim%C3%A9nez-Luna%2C+Jos%C3%A9"><span class="NLM_given-names">José</span> Jiménez-Luna</a> <a href="https://orcid.org/0000-0002-5335-7834"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Grisoni%2C+Francesca"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Grisoni%2C+Francesca"><span class="NLM_given-names">Francesca</span> Grisoni</a> <a href="https://orcid.org/0000-0001-8552-6615"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Weskamp%2C+Nils"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Weskamp%2C+Nils"><span class="NLM_given-names">Nils</span> Weskamp</a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Schneider%2C+Gisbert"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Schneider%2C+Gisbert"><span class="NLM_given-names">Gisbert</span> Schneider</a> <a href="https://orcid.org/0000-0001-6706-1084"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/17460441.2021.1909567">https://doi.org/10.1080/17460441.2021.1909567</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>02 April 2021
    </div>
   </div>
  </div>
  <div class="figureThumbnailContainer">
   <div class="figureInfo">
    <div class="short-legend">
     <p class="captionText"><span class="captionLabel">Figure 1. </span> Schematic diagram of the transition between classical and modern methodologies for some relevant problems in drug discovery, such as QSAR/QSPR modeling, de novo drug design, and synthesis planning. Abbreviations: ML, machine learning; SVM, support vector machine; RF, random forest; QSAR/QSPR, quantitative structure-activity/property relationship; NN, neural network; SE(3), special Euclidean group in three-dimensions; NLP, natural language processing; MCTS, Monte Carlo tree search</p>
    </div>
   </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0001image" src="/na101/home/literatum/publisher/tandf/journals/content/iedc20/2021/iedc20.v016.i09/17460441.2021.1909567/20210913/images/medium/iedc_a_1909567_f0001_oc.jpg" loading="lazy" height="500" width="444"></a>
   <div class="figureDownloadOptions">
    <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
   </div>
  </div>
 </div>
 <div class="hidden rs_skip" id="fig-description-f0001">
  <p class="captionText"><span class="captionLabel">Figure 1. </span> Schematic diagram of the transition between classical and modern methodologies for some relevant problems in drug discovery, such as QSAR/QSPR modeling, de novo drug design, and synthesis planning. Abbreviations: ML, machine learning; SVM, support vector machine; RF, random forest; QSAR/QSPR, quantitative structure-activity/property relationship; NN, neural network; SE(3), special Euclidean group in three-dimensions; NLP, natural language processing; MCTS, Monte Carlo tree search</p>
 </div>
 <div class="hidden rs_skip" id="figureFootNote-f0001">
  <div class="figureFootNote-f0001"></div>
 </div>
 <p></p>
</div>
<div id="s0002" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i5" class="section-heading-2">2. State of the art applications of artificial intelligence</h2>
 <div id="s0002-s2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i6">2.1. QSAR/QSPR and structure-based modeling with artificial intelligence</h3>
  <p>QSAR/QSPR modeling has come a long way since its inception more than 50&nbsp;years ago [<span class="ref-lnk lazy-ref"><a data-rid="cit0016" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>16</a></span>]. The impact of these computational models on drug discovery is undeniable, evidenced by the successful prediction of biological activity and pharmacokinetic parameters, viz. absorption, distribution, metabolism, excretion, and toxicity (ADMET) [<span class="ref-lnk lazy-ref"><a data-rid="cit0017 cit0018 cit0019 cit0020 cit0021" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>17–21</a></span>]. For ligand-based QSAR/QSPR modeling, the structural features of molecules (<i>e.g</i>. as pharmacophore distribution, physicochemical properties, and functional groups) are commonly converted into machine-readable numbers using the so-called molecular descriptors [<span class="ref-lnk lazy-ref"><a data-rid="cit0007" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>7</a></span>]. The spectrum of hand-crafted molecular descriptors is wide[<span class="ref-lnk lazy-ref"><a data-rid="cit0007" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>7</a></span>], aiming to capture a variety of aspects of the underlying chemical structure. In general, QSAR/QSPR approaches have transitioned from the use of simpler models, such as linear regression and <i>k</i>-nearest neighbors, toward more universally applicable machine learning techniques, such as support vector machines (SVM) and gradient boosting methods (GBM) [<span class="ref-lnk lazy-ref"><a data-rid="cit0015" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>15</a></span>], aiming to address more complex and potentially nonlinear relationships between the chemical structure and its physicochemical/biological properties, often at the expenses of intepretability [<span class="ref-lnk lazy-ref"><a data-rid="cit0022" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>22</a></span>].</p>
  <p>Deep learning is not a new technique [<span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>23</a></span>]. Artificial neural networks in chemoinformatics had their first heyday in the 1990s when many of the current concepts were pioneered [<span class="ref-lnk lazy-ref"><a data-rid="cit0024 cit0025 cit0026" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>24–26</a></span>], including deep and adaptive network architectures, self-organizing maps, recurrent systems for sequence and time-series analysis, and autoencoders. However, deep networks had their final breakthrough arguably after their success in the Merck Molecular Activity Challenge in 2012 [<span class="ref-lnk lazy-ref"><a data-rid="cit0027" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>27</a></span>]. While there is some controversy as to whether the latter type of models are superior performance-wise to other approaches (<i>e.g</i>. gradient boosting machines [<span class="ref-lnk lazy-ref"><a data-rid="cit0028" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>28</a></span>]) when using the same set of descriptors [<span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>29</a></span>], deep learning methods offer several advantages. Arguably, the most important one is that deep networks can perform automatic feature extraction during the training procedure. Graph neural networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0012" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>12</a></span>] (also referred to as message-passing approaches) and recurrent neural networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0030" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>30</a></span>] in particular, are able to generate internal context-specific representations of molecular structures. In the specific case of graph neural networks, this is achieved by learning latent atom and bond representations during the training process. Therefore, deep learning approaches are promising for modeling tasks for which classical descriptors had not been initially engineered. Examples include the modeling of peptides [<span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>31</a></span>], macrocycles, and proteolysis-targeting chimeras (PROTACs) [<span class="ref-lnk lazy-ref"><a data-rid="cit0032" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>32</a></span>]. Another potential advantage of deep architectures is their applicability to multitask learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0033 cit0034 cit0035" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>33–35</a></span>], which aims to find a common internal representation that is useful for a set of related endpoints (not to be confused with multi-output learning which does not explicitly exploit related information between the tasks to be learned). As drug discovery is a multiparameter optimization challenge [<span class="ref-lnk lazy-ref"><a data-rid="cit0036" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>36</a></span>], multitask learning might make more efficient use of correlated data in common scenarios where the entirety of a molecular library is not exhaustively tested on all endpoints of interest, and without the need for prior imputation. The idea of multi-output QSAR modeling, aiming to relate a set of predefined chemical descriptors to observable endpoints, had been explored before the rise of popularity of deep learning approaches [<span class="ref-lnk lazy-ref"><a data-rid="cit0037 cit0038 cit0039 cit0040 cit0041 cit0042" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>37–42</a></span>]. Despite the promise of multitask learning, to date, only modest performance improvements over single-task models have been reported [<span class="ref-lnk lazy-ref"><a data-rid="cit0043 cit0044 cit0045 cit0046" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>43–46</a></span>].</p>
  <p>A well-known drawback of deep learning is its poor performance in medium-to-low data scenarios [<span class="ref-lnk lazy-ref"><a data-rid="cit0047" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>47</a></span>]. Some chemogenomic-based approaches might provide further insight in these scenarios by exploiting additional genomic or biological interactome data sources [<span class="ref-lnk lazy-ref"><a data-rid="cit0048" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>48</a></span>]. In addition, recent advances in ‘few-shot’ learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0049" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>49</a></span>] (<i>i.e</i>. a set of approaches that can use prior knowledge to obtain better generalization when data is scarce) and meta-learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>50</a></span>] (<i>i.e</i>. a family of methods that aims to develop a set of learnable parameters that can quickly adapt to new, unseen tasks) hold promise in mitigating some of these issues. Along those lines, purely data-driven approaches for molecular property predictions are, in contrast to techniques that are (fully or partially) physics-based, fundamentally limited in their ability to extrapolate and make reliable predictions for unseen compound classes. Physics-inspired machine learning approaches and additional active learning strategies (<i>i.e</i>. approaches where the model has a role in requesting specific training data for improved generalization) provide additional tools to overcome these limitations [<span class="ref-lnk lazy-ref"><a data-rid="cit0051" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>51</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>52</a></span>]. The success of these strategies, will furthermore critically depend on how well their specific implementations cope with data sparsity, given that suitable sources that would allow for efficient data imputation are often scarce [<span class="ref-lnk lazy-ref"><a data-rid="cit0053" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>53</a></span>].</p>
  <p>Deep-learning models have also been widely criticized for their notorious debugging difficulty and ‘black-box’ character [<span class="ref-lnk lazy-ref"><a data-rid="cit0054" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>54</a></span>]. In contrast, the manual development of domain-specific features [<span class="ref-lnk lazy-ref"><a data-rid="cit0055" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>55</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0056" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>56</a></span>] (<i>i.e</i>. descriptors specifically engineered with a specific task in mind) still holds the potential to integrate background knowledge in a more human-intelligible way. Explainable AI techniques could offer partial solutions to these problems by providing comprehensible interpretations of the decision-making process undertaken by deep learning approaches [<span class="ref-lnk lazy-ref"><a data-rid="cit0057" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>57</a></span>]. Continued development of feature attribution techniques [<span class="ref-lnk lazy-ref"><a data-rid="cit0058" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>58</a></span>] (<i>i.e</i>. approaches that aim to highlight the overall importance of an input) instance-based explanations (<i>e.g</i>. counterfactuals, model-generated examples that are conditioned on user-defined queries) [<span class="ref-lnk lazy-ref"><a data-rid="cit0054" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>54</a></span>], and attention-based networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0059" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>59</a></span>] will help narrow the gap between deep learning and drug-discovery specialists. Hence, close collaboration between these fields is imperative.</p>
  <p>Another commonly-claimed disadvantage of deep-learning approaches is their high computational cost. Without specialized hardware such as consumer-grade graphical processing or tensor-processing units, deep learning typically entails longer training and evaluation times than many other machine-learning approaches. While the previous statement holds true under most scenarios, deep-learning models can learn in an online setting by naturally taking advantage of its most popular training strategy, <i>i.e</i>. stochastic gradient-descent optimization [<span class="ref-lnk lazy-ref"><a data-rid="cit0060" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>60</a></span>]. This has the advantage of scaling linearly with respect to the size of the training dataset, and thus it does not require the latter to be entirely loaded into the system’s memory. We argue that the capability to train deep learning models stochastically on sequential, random, batches of data can make them more suitable than other alternatives in big data scenarios [<span class="ref-lnk lazy-ref"><a data-rid="cit0061" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>61</a></span>]. A related issue is that predictive deep learning tends to require significantly more human expertise in many practical scenarios compared to other, more thoroughly tested approaches. For instance, while one can train a well-performing random forest model with a relatively small effort for hyperparameter tuning, our understanding of contemporary deep learning approaches is not yet at the level of reliable defaults, although recent theory suggests that this may change in the near future [<span class="ref-lnk lazy-ref"><a data-rid="cit0062" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>62</a></span>].</p>
  <p>Furthermore, neural networks might provide the right answers for misleading reasons (<i>i.e</i>. the so-called Clever Hans effect [<span class="ref-lnk lazy-ref"><a data-rid="cit0063" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>63</a></span>]) and have a tendency to produce overly confident predictions, even when these are evidently wrong [<span class="ref-lnk lazy-ref"><a data-rid="cit0064" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>64</a></span>]. This is further exacerbated in the context of property prediction in drug discovery, as experiments under similar conditions can provide significantly different measurements. This drawback might be alleviated in the next few years with the wider adoption of uncertainty estimation techniques, either with deep learning approaches that have uncertainty directly embedded into their design, such as Bayesian neural networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0065" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>65</a></span>], or <i>post hoc</i> techniques such as ensemble learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0066" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>66</a></span>].</p>
  <p>Remarkable progress has also been made in the structure-based prediction of protein-ligand activities which, unlike classical QSAR, requires a co-crystal or a docked pose to generalize over different targets. Many classical approaches modeled an explicit, predefined mathematical relationship of the protein-ligand complex via partial least squares or multiple linear regression, in order to accurately consider the contribution of individual descriptors (<i>e.g</i>. physicochemical properties) for a target property [<span class="ref-lnk lazy-ref"><a data-rid="cit0067 cit0068 cit0069 cit0070 cit0071" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>67–71</a></span>]. Approaches making use of more advanced as well as more flexible non-linear models, such as random forests or support vector machines, appeared in the 2000s [<span class="ref-lnk lazy-ref"><a data-rid="cit0072" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>72</a></span>], and became popular in the early 2010s, coupled with a wide range of descriptors such as protein-ligand atom pair counts [<span class="ref-lnk lazy-ref"><a data-rid="cit0073" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>73</a></span>], property-encoded shape distributions [<span class="ref-lnk lazy-ref"><a data-rid="cit0074" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>74</a></span>], or basic atomic interactions [<span class="ref-lnk lazy-ref"><a data-rid="cit0075" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>75</a></span>]. Similar to its purely ligand-based counterpart, this particular subfield has recently witnessed the advent of deep learning and used it to its advantage. Early approaches were inspired by the advances of computer vision and image recognition which were mostly driven by convolutional neural networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0076" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>76</a></span>], and ultimately adapted for bioactivity prediction [<span class="ref-lnk lazy-ref"><a data-rid="cit0077 cit0078 cit0079 cit0080" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>77–80</a></span>]. Others studies used graph-based approaches in conjunction with distance and angle-based featurizations toward the same goal [<span class="ref-lnk lazy-ref"><a data-rid="cit0010" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>10</a></span>]. Some of these were reported to provide incremental performance improvements over previous approaches in structure-based virtual screening and lead optimization competitions [<span class="ref-lnk lazy-ref"><a data-rid="cit0081" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>81</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0082" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>82</a></span>], although it is argued whether some well-known benchmarks tend to favor ML-based scoring functions over classical ones [<span class="ref-lnk lazy-ref"><a data-rid="cit0083" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>83</a></span>]. In keeping with an increased interest in interpretable AI, recent attempts toward explaining structure-based convolutional neural network models have shown that these are able to highlight relevant protein-ligand interactions in comprehensible terms, such as hydrogen bridging and π-π stacking [<span class="ref-lnk lazy-ref"><a data-rid="cit0079" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>79</a></span>].</p>
  <p>Approaches based on three-dimensional convolutional neural networks, however, possessed certain theoretical limitations, namely the lack of rotational invariance with respect to the input, a desirable property when modeling atomistic systems. How to overcome this issue has recently become a very active area of research, with newly developed neural network architectures such as Euclidean Neural Networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0084 cit0085 cit0086" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>84–86</a></span>] and SchNet [<span class="ref-lnk lazy-ref"><a data-rid="cit0087" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>87</a></span>], featuring equivariance with respect to the special Euclidean group in three-dimensions (SE(3)) (<i>i.e</i>. rotations and translations) directly embedded into their design. These architectures have already been applied to several molecular tasks, such as the prediction of electronic properties of molecules [<span class="ref-lnk lazy-ref"><a data-rid="cit0088" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>88</a></span>]. Research in this direction is expected to intensify in the near future, opening up fresh modeling opportunities.</p>
  <p>Given the growth of deep learning applications in drug discovery and the fact that these methods benefit from large training sets, diligent data curation and proper benchmarking of newly developed models is mandatory. The availability and size of chemical compound libraries has improved over the past few years, with databases such as ZINC [<span class="ref-lnk lazy-ref"><a data-rid="cit0089" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>89</a></span>] and ChEMBL [<span class="ref-lnk lazy-ref"><a data-rid="cit0090" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>90</a></span>] representing a commonly-used starting point for ligand-based projects. A similar trend was observed for structure-based modeling, for which databases such as PDBbind [<span class="ref-lnk lazy-ref"><a data-rid="cit0091" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>91</a></span>] and BindingDB [<span class="ref-lnk lazy-ref"><a data-rid="cit0092" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>92</a></span>] provide highly detailed structural information on protein-ligand complexes, as well as their associated bioactivity data. Recent progress in the field of protein structure prediction and determination warrants optimism that structural information for many more drug targets will become available in the future [<span class="ref-lnk lazy-ref"><a data-rid="cit0093" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>93</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0094" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>94</a></span>].</p>
  <p>Much has already been invested in open and standardized assessments of machine learning methodologies in the context of cheminformatics. For example, the MoleculeNet benchmarking suite [<span class="ref-lnk lazy-ref"><a data-rid="cit0009" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>9</a></span>] aims to facilitate model testing by providing a timely evaluation of many popular deep learning architectures for drug-related property predictions in well-curated datasets from areas such as biophysics, physical chemistry, and physiology. Nonetheless, while we have argued that the amount of public data is increasing at a fast pace, most of the structural activity/property relationship data are still generated by commercial research organizations, publishers, and pharmaceutical companies [<span class="ref-lnk lazy-ref"><a data-rid="cit0095 cit0096 cit0097" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>95–97</a></span>], which often consider the generated data as a differentiating asset to be kept confidential. Recent developments have shown that molecular structures can often be partially recovered from molecular descriptors, which may further complicate data sharing even at the latent feature level [<span class="ref-lnk lazy-ref"><a data-rid="cit0098" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>98</a></span>]. Attempts to overcome such limitations, <i>for example</i>, by developing federated and intellectual property (IP)-preserving learning techniques, are underway [<span class="ref-lnk lazy-ref"><a data-rid="cit0099" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>99</a></span>].</p>
  <p>With regards to model evaluation, it is now known that testing performance on sets drawn from a database in a pseudo-random fashion can produce overly confident results. Alternatives such as scaffold-based [<span class="ref-lnk lazy-ref"><a data-rid="cit0100" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>100</a></span>] or time-based splits [<span class="ref-lnk lazy-ref"><a data-rid="cit0101" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>101</a></span>], which try to approximate the course of a lead optimization project, are potentially more informative. However, one should keep in mind that there is no such thing as a ‘one-split-fits-all’ strategy, as each evaluation portrays model performance in a different applicability domain. Furthermore, even though prospective applications should be considered the gold standard for model benchmarking, we note that these are not necessarily straightforward and are not devoid of biases either [<span class="ref-lnk lazy-ref"><a data-rid="cit0102" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>102</a></span>]. However, while the lack of benchmarking consensus is not ideal, it has not prevented machine-learning scoring functions [<span class="ref-lnk lazy-ref"><a data-rid="cit0103" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>103</a></span>] to be surprisingly predictive in some virtual screening campaigns [<span class="ref-lnk lazy-ref"><a data-rid="cit0104" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>104</a></span>]. Additionally, many efforts have been dedicated to the use of proper performance metrics for classification and regression models, and the limitations thereof [<span class="ref-lnk lazy-ref"><a data-rid="cit0105 cit0106 cit0107 cit0108" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>105–108</a></span>].</p>
 </div>
 <div id="s0002-s2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i7">2.2. De novo drug design with artificial intelligence</h3>
  <p>De novo design, the generation of novel molecular entities with desired pharmacological properties from scratch [<span class="ref-lnk lazy-ref"><a data-rid="cit0109" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>109</a></span>], can be considered as one of the most challenging computer-assisted tasks in drug discovery, due to the cardinality of the chemical space of drug-like molecules (estimated to range in the order of 10<sup>60</sup>–10<sup>100</sup>) [<span class="ref-lnk lazy-ref"><a data-rid="cit0110" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>110</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0111" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>111</a></span>]. De novo molecule generation faces the problem of combinatorial explosion due to the number of different atomic types and molecular topologies one could investigate [<span class="ref-lnk lazy-ref"><a data-rid="cit0112" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>112</a></span>]. Depending on the information used to guide the de novo design, the respective approaches can either be ligand-based, structure-based, or a mixture of both.</p>
  <p>Ligand-based methodologies may be divided into two major categories: (i) rule-based approaches, which use a set of construction rules for molecule assembly from a set of ‘building blocks’ (<i>i.e</i>. reagents or molecular fragments), and (ii) rule-free approaches, which do not employ explicit construction rules. One of the ancestors of contemporary rule-based de novo design is the Topliss scheme [<span class="ref-lnk lazy-ref"><a data-rid="cit0113" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>113</a></span>], for the stepwise generation of analogs of an active lead compound to maximize potency [<span class="ref-lnk lazy-ref"><a data-rid="cit0113" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>113</a></span>]. Contemporary approaches are based on applying a given set of molecular transformations for optimization, such as matched molecular pairs [<span class="ref-lnk lazy-ref"><a data-rid="cit0114" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>114</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0115" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>115</a></span>], or rules-of-thumb for functional group and molecular framework modification [<span class="ref-lnk lazy-ref"><a data-rid="cit0116" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>116</a></span>]. Synthesis-oriented approaches explicitly include synthesis rules for building block assembly and ligand generation. These approaches are useful, for instance, to design synthetically accessible libraries [<span class="ref-lnk lazy-ref"><a data-rid="cit0117" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>117</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0118" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>118</a></span>], such as BI CLAIM [<span class="ref-lnk lazy-ref"><a data-rid="cit0119" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>119</a></span>] and CHIPMUNK [<span class="ref-lnk lazy-ref"><a data-rid="cit0120" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>120</a></span>]. Since the late 1990s, hybrid approaches, such as TOPAS [<span class="ref-lnk lazy-ref"><a data-rid="cit0121" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>121</a></span>], DOGS [<span class="ref-lnk lazy-ref"><a data-rid="cit0122" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>122</a></span>], and DINGOS [<span class="ref-lnk lazy-ref"><a data-rid="cit0123" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>123</a></span>], have been developed to steer the generation of novel compounds by simultaneously maximizing both their similarity to known bioactive ligands and the chemical synthesizability of the designs.</p>
  <p>‘Rule-free’ approaches aim to directly generate molecules with desired properties without the need for molecular construction rules. Contemporary approaches are often based on generative deep learning models [<span class="ref-lnk lazy-ref"><a data-rid="cit0124" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>124</a></span>], which sample new molecules from a learned latent molecular representation. Although these approaches have gained popularity in the last few years, the idea of sampling from a numerical representation of molecules for de novo design dates back to the ‘inverse QSAR’ problem formulated in the pioneering work of Skvortsova and Zefirov in the early 1990s [<span class="ref-lnk lazy-ref"><a data-rid="cit0125 cit0126 cit0127" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>125–127</a></span>]. Inverse QSAR leverages an existing QSAR model to identify the descriptor values corresponding to a desired property, and uses this information for molecule generation [<span class="ref-lnk lazy-ref"><a data-rid="cit0128 cit0129 cit0130 cit0131" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>128–131</a></span>]. The latter approaches pose several challenges, such as the existence of multiple solutions for any given property and the issue of reverse-decoding molecular descriptors into valid structures. Generative deep learning overcomes some of these issues by modeling the underlying distribution of a given set of molecules, and then generating novel compounds by sampling from the learned distribution [<span class="ref-lnk lazy-ref"><a data-rid="cit0132" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>132</a></span>]. The most commonly used generative models are those borrowed from the field of natural language processing, coupled with Simplified Molecular Input Line Entry Systems (SMILES) [<span class="ref-lnk lazy-ref"><a data-rid="cit0133" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>133</a></span>]. These models are trained to learn the SMILES ‘syntax’ (<i>i.e</i>. how to generate a chemically valid string) on chosen ‘semantics’ (<i>i.e</i>. bioactivity or other desired molecular properties). They are mostly based on recurrent neural networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0134" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>134</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0135" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>135</a></span>], coupled with transfer [<span class="ref-lnk lazy-ref"><a data-rid="cit0134" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>134</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0135" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>135</a></span>] or reinforcement learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0136 cit0137 cit0138" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>136–138</a></span>]. Other popular deep-learning-based generative learning models, such as variational autoencoders [<span class="ref-lnk lazy-ref"><a data-rid="cit0139" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>139</a></span>], or generative adversarial networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0140" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>140</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0141" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>141</a></span>] have also been commonly reported, as well as others based on graph convolutions [<span class="ref-lnk lazy-ref"><a data-rid="cit0142" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>142</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0143" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>143</a></span>]. Recently, instances of conditional generative approaches have been suggested, which leverage additional information guiding the design, such as three-dimensional shape [<span class="ref-lnk lazy-ref"><a data-rid="cit0144" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>144</a></span>], drug-likeness [<span class="ref-lnk lazy-ref"><a data-rid="cit0142" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>142</a></span>], synthesizability [<span class="ref-lnk lazy-ref"><a data-rid="cit0142" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>142</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0145" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>145</a></span>], molecular descriptors values [<span class="ref-lnk lazy-ref"><a data-rid="cit0146" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>146</a></span>], and gene expression signatures [<span class="ref-lnk lazy-ref"><a data-rid="cit0147" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>147</a></span>]. A major upcoming challenge in this context will be the definition of balanced objective functions that enable complex and constrained multi-parameter optimizations, similarly to those used in Pareto [<span class="ref-lnk lazy-ref"><a data-rid="cit0148" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>148</a></span>] or in desirability-based approaches [<span class="ref-lnk lazy-ref"><a data-rid="cit0149 cit0150 cit0151 cit0152" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>149–152</a></span>], that are typically required in drug discovery.</p>
  <p>Fueled in part by the rapid development of novel generative neural network approaches, the number of ligand-based design methods has skyrocketed. A recent review [<span class="ref-lnk lazy-ref"><a data-rid="cit0153" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>153</a></span>] reported more than 40 new models that were developed in the last couple of years. This explosion of potential drug-design tools has motivated researchers to evaluate and benchmark generative approaches in a fair and standardized manner. Recent efforts include the MOSES [<span class="ref-lnk lazy-ref"><a data-rid="cit0154" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>154</a></span>] and GuacaMol platforms [<span class="ref-lnk lazy-ref"><a data-rid="cit0155" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>155</a></span>], which implement several popular neural generative models, as well as more classical models (<i>e.g</i>. genetic algorithms [<span class="ref-lnk lazy-ref"><a data-rid="cit0156" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>156</a></span>]), and provide several metrics for their comparison. While de novo design tools are in general more difficult to evaluate retrospectively than predictive methods, some of the commonly used metrics are: (i) validity of the generated molecular representations and novelty of the corresponding molecules, (ii) similarity to known compounds in terms of chemical and biological properties [<span class="ref-lnk lazy-ref"><a data-rid="cit0157" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>157</a></span>], and (iii) scaffold and fragment diversity.</p>
  <p>Rule-based and rule-free approaches have different advantages. Rule-based methods, by relying on preexisting knowledge, such as building blocks and reaction rules, can generate molecules that are often readily synthesizable and possess the desired physicochemical properties. However, the chemical diversity of the designs is influenced by the hard-coded rules and the chosen building block libraries. Rule-free approaches learn directly from the data without the need of hard-coded design/similarity rules, thus theoretically allowing a broader exploration of the chemical space. As a downside, this freedom of exploration risks the generation of compounds that are more difficult, if not impossible, to synthesize. Mixed approaches combining rule-free and rule-based methods might represent a promising middle ground for the design of novel bioactive and synthesizable molecular entities. Recently, a mixed strategy showed promise in designing bioactive molecules in a rule-free manner, while at the same time retaining synthesizability within a microfluidics system, thanks to a set of predefined virtual reactions [<span class="ref-lnk lazy-ref"><a data-rid="cit0145" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>145</a></span>].</p>
  <p>To date, most of the deep-learning-based de novo design studies have focused on ligand-based approaches. Structure-based generative design constitutes a promising complementary research direction for targeting orphan receptors and hitherto unexplored macromolecules [<span class="ref-lnk lazy-ref"><a data-rid="cit0158" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>158</a></span>]. These approaches, which typically leverage information about the ligand-binding site (<i>e.g</i>. by fragment linking or growing<sup>109</sup>), to the best of our knowledge, have not been yet permeated extensively by deep learning. However, initial developments for ligand design have emerged by taking into account the shape and properties of the binding pocket [<span class="ref-lnk lazy-ref"><a data-rid="cit0159 cit0160 cit0161" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>159–161</a></span>].</p>
 </div>
 <div id="s0002-s2003" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i8">2.3. Automated synthesis planning with artificial intelligence</h3>
  <p>The majority of all known organic compounds can be synthesized with a limited number of robust reactions [<span class="ref-lnk lazy-ref"><a data-rid="cit0162" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>162</a></span>]. However, reliable and fully automated synthesis planning in chemistry is a challenge that is yet to be met [<span class="ref-lnk lazy-ref"><a data-rid="cit0163" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>163</a></span>]. Part of the reason is owing to the extensive chemistry expertise that is required for efficient forward and retrosynthetic planning [<span class="ref-lnk lazy-ref"><a data-rid="cit0164" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>164</a></span>]. Synthesis planning with AI has a rich history, dating back to the 1970s in the field of computer-aided retrosynthetic prediction [<span class="ref-lnk lazy-ref"><a data-rid="cit0165" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>165</a></span>]. Increased computational capabilities, the advent of big data, and the development of novel algorithms for deep learning and optimization, have resulted in a resurgence of AI for synthetic organic chemistry. In retrosynthesis, where the main goal is to recursively design efficient synthetic routes for a molecule of interest, rule-based methods [<span class="ref-lnk lazy-ref"><a data-rid="cit0122" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>122</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0123" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>123</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0166" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>166</a></span>] are indisputably valuable. These aim to suggest retrosynthetic pathways via reaction mechanism encoding and skeletal building. One of their main limitations is their dependency on explicit chemical transformations/reactions. These usually entail manual construction and curation. The field has recently drawn inspiration from natural language processing methods, such as sequence-to-sequence models [<span class="ref-lnk lazy-ref"><a data-rid="cit0167" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>167</a></span>] and transformer models [<span class="ref-lnk lazy-ref"><a data-rid="cit0168" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>168</a></span>]. This line of research is motivated by the observation that the rank distribution of fragments in organic molecules is similar to that of words in the English language [<span class="ref-lnk lazy-ref"><a data-rid="cit0169" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>169</a></span>]. Rule-free approaches typically consider products in a text-based representation (<i>e.g</i>. SMILES), and process them via an encoder-decoder architecture, which is subsequently used to predict the corresponding synthetic precursors at a one-step reaction distance [<span class="ref-lnk lazy-ref"><a data-rid="cit0170" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>170</a></span>]. Improvements over this architecture feature the use of tiered neural networks [<span class="ref-lnk lazy-ref"><a data-rid="cit0171" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>171</a></span>], whose goal is to partition the retrosynthesis prediction problem into reaction type classification and reaction rule selection steps. This separation, inspired by a previously reported molecular similarity method [<span class="ref-lnk lazy-ref"><a data-rid="cit0172" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>172</a></span>], was shown to achieve performance gains over previous baselines.</p>
  <p>While most of the above-described methods focus on the linear one-step retrosynthesis problem, a more realistic scenario faces a rapidly exploding combinatorial problem. Inspired by progress in reinforcement learning, one of the most important breakthroughs in the last few years came from the widespread usage of sophisticated search methods, such as Monte Carlo Tree Search [<span class="ref-lnk lazy-ref"><a data-rid="cit0173" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>173</a></span>], to efficiently navigate through chemical reaction spaces [<span class="ref-lnk lazy-ref"><a data-rid="cit0174" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>174</a></span>]. A recent study [<span class="ref-lnk lazy-ref"><a data-rid="cit0175" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>175</a></span>] has attempted to elucidate both reactants and reagents via the use of transformer models, employing one-step precursor predictions in combination with the construction of hyper-graphs (<i>i.e</i>. directed acyclic graphs where edges can link multiple nodes simultaneously), which represent synthetic pathways. In order to find a reasonable synthetic pathway, these hyper-graphs are explored with beam search, aided by a Bayesian-like probability scheme that is biased toward the suggestion of chemically simpler precursors [<span class="ref-lnk lazy-ref"><a data-rid="cit0172" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>172</a></span>].</p>
  <p>Forward synthesis planning distinguishes itself from retrosynthesis. While the latter might be solvable by leveraging existing reaction databases, forward synthesis would require information from reactions that yield no product whatsoever. The current chemical reaction databases are heavily skewed toward productive reaction data [<span class="ref-lnk lazy-ref"><a data-rid="cit0176" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>176</a></span>]. There is a critical demand for additional data, such as experimental conditions (<i>e.g</i>. solvent and temperature) or side-product information. With the aim of addressing some of these limitations, several steps have been taken to expand known reaction databases with negative reaction outcomes [<span class="ref-lnk lazy-ref"><a data-rid="cit0177" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>177</a></span>], and thereby, create new customized data compilations for automated synthesis planning [<span class="ref-lnk lazy-ref"><a data-rid="cit0178" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>178</a></span>].</p>
  <p>Some of the earlier approaches ranked candidate products using hard-coded reaction templates derived from data [<span class="ref-lnk lazy-ref"><a data-rid="cit0177" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>177</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0179" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>179</a></span>]. Proof-of-concept machine learning ranked reaction templates, when the details of reactants and reagents were given [<span class="ref-lnk lazy-ref"><a data-rid="cit0180" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>180</a></span>]. Newer approaches aim to directly rank products by viewing the chemical reaction prediction problem as a graph transformation task [<span class="ref-lnk lazy-ref"><a data-rid="cit0181" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>181</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0182" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>182</a></span>]. Driven by advances in quantum mechanics, another set of approaches opted for using first-principle calculations (<i>e.g</i>. density functional theory) to evaluate the energy barriers of a particular reaction. However, this approach is computationally prohibitive for medium-to-large systems. The accurate prediction of energies and forces [<span class="ref-lnk lazy-ref"><a data-rid="cit0183" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>183</a></span>] via quantum-mechanical machine learning might help bridge this gap in the near future. With regard to template-free forward synthesis prediction, natural language processing approaches based on transformer [<span class="ref-lnk lazy-ref"><a data-rid="cit0184" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>184</a></span>] or recurrent neural network architectures [<span class="ref-lnk lazy-ref"><a data-rid="cit0185" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>185</a></span>] are also becoming popular. These have reported a top-1 reactant accuracy above 90%. Other recent alternative deep learning approaches [<span class="ref-lnk lazy-ref"><a data-rid="cit0186" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>186</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0187" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>187</a></span>] have opted to encode reaction prediction as an electron rearrangement exercise alongside the usage of message-passing neural networks. The latter approach, however, requires filtering reactions where electron flow is not directly identifiable, which excludes many relevant organic ones.</p>
 </div>
</div>
<div id="s0003" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i9" class="section-heading-2">3. Expert opinion</h2>
 <p>Evidence suggests that AI applications are starting to become ubiquitous in drug discovery and design. These techniques are slowly living up to some of the community’s expectations, with remarkable advances in QSAR modeling, de novo molecular design, and synthesis planning, among others. However, whether these techniques will actually prove useful by aiding researchers to design and synthesize ‘better drug candidates faster’ still remains to be demonstrated [<span class="ref-lnk lazy-ref"><a data-rid="cit0188" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>188</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0189" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>189</a></span>].</p>
 <p>In the context of ligand-based property prediction, methods relying on more ‘raw’ chemical representations (<i>e.g</i>. graph neural networks and SMILES-based recurrent neural networks) can be anticipated to perform at least on-par with standard descriptor-based models. Moreover, deep learning approaches are easily adaptable to a wider class of chemical entities and modeling tasks, and allow for a more efficient use of data, for example, via multitask and online learning. In contrast, conformation-aware deep learning, especially considering methodologies that embed three-dimensional symmetries into their design, are still in their infancy. Nonetheless, rapid progress can be expected toward their application in drug discovery and related areas, such as quantum mechanics and material science, particularly as a proxy for first-principle calculations, which are computationally more demanding.</p>
 <p>In de novo drug design, we have been slowly witnessing an augmentation of rule-based approaches along with rule-free approaches in the past few years. While the latter hold promise in exploring unseen regions of the chemical space, they also come with limitations, such as limited synthesizability. Mixing rule-free and rule-based methods (<i>i.e</i>. ‘hybrid’ methods) might provide a pragmatic solution. Particular attention will be drawn toward generative approaches that can exploit additional sources of information, such as some of the pioneering works including gene expression [<span class="ref-lnk lazy-ref"><a data-rid="cit0120" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>120</a></span>], conformational space [<span class="ref-lnk lazy-ref"><a data-rid="cit0123" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>123</a></span>], and ligand binding site information [<span class="ref-lnk lazy-ref"><a data-rid="cit0131" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>131</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0132" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>132</a></span>].</p>
 <p>For automated synthesis planning and reaction prediction, advanced natural language processing will continue to inspire and drive innovation. Much needed attention will be drawn to commonly less explored topics, such as yield estimation, side-product formation, and the prediction of suitable reaction conditions. Advances in robotics and reinforcement learning will lay the groundwork for fully automated synthesis in the next few years.</p>
 <p>The newfound interest in explainable AI [<span class="ref-lnk lazy-ref"><a data-rid="cit0057" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>57</a></span>], with methodologies such as feature attribution [<span class="ref-lnk lazy-ref"><a data-rid="cit0190" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>190</a></span>], instance-based molecular counterfactual explanation [<span class="ref-lnk lazy-ref"><a data-rid="cit0191" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>191</a></span>], and uncertainty estimation [<span class="ref-lnk lazy-ref"><a data-rid="cit0064" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>64</a></span>], will increase the acceptance of AI-supported drug discovery. The development and validation of these techniques will require further interdisciplinary research. Special consideration will also be given to approaches that can exploit information in low-data regimes, such as transfer learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0192" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>192</a></span>], as well as multi-task and meta-learning [<span class="ref-lnk lazy-ref"><a data-rid="cit0193" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>193</a></span>]. The barriers against learning and prospectively applying deep learning approaches have been greatly lowered for interested practitioners in the last few years. The current trend suggests that these methods will be increasingly accessible in the foreseeable future, with the continued development of general high-level research and deployment software packages [<span class="ref-lnk lazy-ref"><a data-rid="cit0194" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>194</a></span>,<span class="ref-lnk lazy-ref"><a data-rid="cit0195" data-reflink="_i10 _i11 _i12 _i13" href="#"><span class="off-screen">Citation</span>195</a></span>], as well as comprehensible documentation.</p>
</div>