<div id="S0001" class="NLM_sec NLM_sec-type_intro NLM_sec_level_1">
 <h2 id="_i3" class="section-heading-2">Introduction</h2>
 <p>The teaching of qualitative research has recently received increased attention (Eisenhart &amp; Jurow, <span class="ref-lnk lazy-ref"><a data-rid="CIT0020" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>). This paper addresses whether and how AI-supported machine interpretation can support the teaching of procedures related to reconstructive methods in social sciences. It is mainly concerned with teaching method skills of reconstructive approaches to qualitative empirical social research (and their possible support by AI) and not with teaching qualitative methods in general (Eisenhart &amp; Jurow, <span class="ref-lnk lazy-ref"><a data-rid="CIT0020" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>; Flick, <span class="ref-lnk lazy-ref"><a data-rid="CIT0021" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>; Denzin &amp; Lincoln, <span class="ref-lnk lazy-ref"><a data-rid="CIT0017" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2018</a></span>). However, the term reconstructive research (Pfaff et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0045" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2010</a></span>) refers to methods this article summarizes under the collective term deep interpretation, which culminates with AI-supported machine interpretation to a practice of distributed interpretation.</p>
 <p>Artificial Intelligence (AI), coined by computer scientists McCarthy and Minsky (<span class="ref-lnk lazy-ref"><a data-rid="CIT0040" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1955</a></span>), has been discussed controversially and in many ways. In addition to genuine computer science publications (Chowdhary, <span class="ref-lnk lazy-ref"><a data-rid="CIT0014" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>; Mackworth &amp; Poole, <span class="ref-lnk lazy-ref"><a data-rid="CIT0037" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2017</a></span>; Russell &amp; Norvig, <span class="ref-lnk lazy-ref"><a data-rid="CIT0050" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2016</a></span>; Kaplan, <span class="ref-lnk lazy-ref"><a data-rid="CIT0028" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2016</a></span>), publications in the intersection of computer science, social and cultural sciences are indirectly relevant for this research (e.g., Bostrom, <span class="ref-lnk lazy-ref"><a data-rid="CIT0012" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2017</a></span>; Beer, <span class="ref-lnk lazy-ref"><a data-rid="CIT0004" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2017</a></span>). The debate about AI in education (Williamson &amp; Eynon, <span class="ref-lnk lazy-ref"><a data-rid="CIT0061" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>) in the research fields of educational data mining and learning analytics (Ifenthaler &amp; Gibson, <span class="ref-lnk lazy-ref"><a data-rid="CIT0026" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>) is already relevant. However, the literature on the direct connection between AI and qualitative methods is still scarce. Although a variety of research fields use AI-based text evaluations, e.g., in the digital humanities (Toon, <span class="ref-lnk lazy-ref"><a data-rid="CIT0058" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2019</a></span>), and machine learning methods have also found their way into the social sciences (Edelmann et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0019" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>), there is only a rudimentary discussion of qualitative social research and AI relevant for the underlying research of this article (Costa et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0016" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>). In particular, the article does not refer to forms of machine interpretation such as sentiment analysis (Saxena et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0052" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>) or computational text analysis in general (Baden et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0002" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>). However, it attempts to teach existing AI applications a specific form of interpretation that is as similar as possible to human interpretation.</p>
 <p>The theoretical background of the underlying research of this article differentiates between a general explicit method knowledge and a specific procedural method skill of reconstructive research methods (1.1). This article approaches this differentiation by exploring how teaching and learning method skills take place. The central research question is Can AI support teaching method skills for doctoral candidates? First, it highlights research workshops as the most effective way of teaching method skills, along with the question of how (primarily young) learners acquire method skills in those settings (1.2). For AI-related questions in educational sciences discussing implicit educational inscriptions in computer-assisted qualitative data analysis software (CAQDAS) and Generative Pre-Trained Transformers (GPTs) (1.3) prepares for the question regarding the possibilities and limitations of implementing AI in a teaching-learning environment of reconstructive methods. Via a case study, this article addresses practical methodological questions on how NLP models (= natural language processing) can implement fragments of the documentary method and how doctoral candidates react to use cases of an interpreting NLP model, providing an empirical basis for further research (2). Using prompt engineering, the underlying research demonstrates the training of an NLP model to create machine-generated interpretations (2.1). In the second step, these interpretations are the basis for a group discussion conducted with doctoral candidates who were—at that time—learning method skills to pursue further research (2.2). Both methods form a case study highlighting the workflow of teaching an AI to interpret texts with the documentary method and an explorative reconstruction of learners’ perspectives on interpreting with AI. The presentation of the results follows these methodical implementations (3), consisting of a demonstration of prompt engineering creating a machine-generated interpretation (3.1) and articulated orientations about interpretation from the group discussion regarding that <i>interpretation</i> (3.2). Further, these results are discussed and deepened (4). Finally, this article’s research reconstructs orientations exploratively concerning machine interpretation and consequences for teaching reconstructive methods concerning Reciprocal Perspectives on AI and Human Intelligence in Education (5).</p>
</div>
<div id="S0002" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i4" class="section-heading-2">Theoretical background: on the what and how of teaching reconstructive methods</h2>
 <p>The theoretical background of this article starts by articulating the relevance of method skills for deep interpretation and distinguishing it from theoretical method knowledge (1.1). Then, research workshops, compared to textbooks and conventional seminars, are presented as the most successful organization for teaching method skills in the field of qualitative reconstructive methods so far (1.2). Finally, possibilities of technology-supported teaching methods are presented based on pedagogical inscriptions in CAQDAS and GPTs. (1.3)</p>
 <div id="S0002-S2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i5">Method skills for the implementation of deep interpretation procedures</h3>
  <p>The underlying research fundamentally differentiates between a general abstract-theoretical "method knowledge" and a specific-concrete "method skill" (Schäffer, <span class="ref-lnk lazy-ref"><a data-rid="CIT0053" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>, p. 164). Method knowledge generally covers methods, methodologies, and fundamental and subject theories (Dörner &amp; Schäffer, 2022). Someone with such explicit and conceptual method knowledge can assess how object-related questions are framed in basic theory and can methodologically justify the use of methods in research projects. However, this is theoretical knowledge about something—a methodological "knowing that" in the terminology of Ryle (<span class="ref-lnk lazy-ref"><a data-rid="CIT0051" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1949</a></span>, p. 28). A methodological "knowing how" (ibid.), on the other hand, comprises procedural knowledge that can translate into concrete actions, i.e., a method skill that grounds practical knowledge of the central interpretation of empirical material.</p>
  <p>Schäffer (<span class="ref-lnk lazy-ref"><a data-rid="CIT0054" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>) characterizes the procedural logic of deep interpretation as compellingly sequential procedural steps in interpreting empirical materials (line by line) that also strictly consider the context. The procedures mentioned have established corresponding methodological step sequences that prevent this decontextualization or enable a sequentially analytical approach. For example, in a group discussion, it is necessary to consider how a statement relates to previously made statements and gains its meaning through this.</p>
  <p>The methodological sequence of steps for interpreting a group discussion is vital for the documentary method (Weller, <span class="ref-lnk lazy-ref"><a data-rid="CIT0059" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2019</a></span>). During these steps, abductive inference (Reichertz, <span class="ref-lnk lazy-ref"><a data-rid="CIT0048" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2004</a></span>), i.e., "an act of insight, although extremely fallible insight" (Peirce, <span class="ref-lnk lazy-ref"><a data-rid="CIT0044" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1960</a></span>, p. 113), may already emerge during early interpretation steps. While knowing the sequence of interpretation steps of the documentary method refers to theoretical method knowledge, creating abductive inferences refers to practical method skill.</p>
  <p>How interpreters ultimately arrived at their interpretations of text passages in these interpretation procedures, i.e., how the act of interpretation specifically took place, tends to remain unclear. This <i>hidden layer</i> problem of reconstructive research (i.e., the problem of not being able to reconstruct the essential abductive steps of the interpretation) mainly concerns the core of interpreting empirical materials and can be reconstructed not only in the documentary method. However, interpretation can be justified in retrospect in an intersubjectively comprehensible way.</p>
  <p>The problem with teaching procedures of deep interpretation originates here. When students receive studies that have arrived at their results using such procedures, they only see the "context of justification" (Hoyningen-Huene, <span class="ref-lnk lazy-ref"><a data-rid="CIT0025" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>, pp. 90, 91). The crucial "context of discovery" (ibid, p. 7), i.e., the process of interpretation itself, must be ensured by other didactic procedures. There are research workshops, which are essential for all deep interpretation procedures. Because here is the chance to look behind the described hidden layers. Therefore, they are of primary interest, as they represent a hinge between research and teaching procedures of deep interpretation.</p>
 </div>
 <div id="S0002-S2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i6">Research workshops as communities of practice of distributed interpretation</h3>
  <p>In textbooks and the context of conventional university seminars on reconstructive research methods, method skills can only be taught to a relatively limited extent. The strengths here lie in teaching the theoretical foundations of "Knowing That" in Ryle’s diction (Ryle, <span class="ref-lnk lazy-ref"><a data-rid="CIT0051" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1949</a></span>, p. 28). Nevertheless, their deficits are apparent when teaching practical steps, the "Knowing How" (ibid.). The forms above of teaching are necessary to build up an explicit knowledge of methods. However, procedural method skills in the sense of being able to interpret, as defined above, cannot be acquired with them. Riemann and Schütze (<span class="ref-lnk lazy-ref"><a data-rid="CIT0049" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1987</a></span>), following the work in the framework of grounded theory by Glaser and Strauss (2009[1967].), therefore consider "research workshops" to be the ideal way to teach and acquire reconstructive methods. Research workshops have their roots in the sociology of the Chicago School and have been made known in Germany primarily by Juliet Corbin and Strauss (<span class="ref-lnk lazy-ref"><a data-rid="CIT0015" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2015</a></span>).</p>
  <p>With Lave and Wenger (<span class="ref-lnk lazy-ref"><a data-rid="CIT0031" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1991</a></span>), a research workshop can be described as a form of "situated learning" in which the novices can initially observe it being done for a few sessions unencumbered by action (so-called "Legitimate Peripheral Participation", ibid.). Then, they socialize into existing <i>Communities of Practice</i> (Wenger, <span class="ref-lnk lazy-ref"><a data-rid="CIT0060" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1998</a></span>) of interpretation. From the perspective of method skills advocated here, the mimetic aspect (Gebauer &amp; Wulf, <span class="ref-lnk lazy-ref"><a data-rid="CIT0022" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1995</a></span>) is central in research workshops: Learners socialize into a research practice by an existing collective of interpreters through imitation. Thus, learning interpretation skills becomes a distributed endeavor in a collective of interpreters.</p>
 </div>
 <div id="S0002-S2003" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i7">Implicit teaching through educational inscriptions in CAQDAS and NLP</h3>
  <p>Software supporting qualitative research consists of inscribed teaching dimensions. Thus, conventional CAQDAS<a href="#EN0001"><sup>1</sup></a> supports qualitative research differently (Zhao et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0063" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2016</a></span>; Silver &amp; Lewins, <span class="ref-lnk lazy-ref"><a data-rid="CIT0056" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>; Mayring, <span class="ref-lnk lazy-ref"><a data-rid="CIT0039" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>; Rädiker &amp; Kuckartz, <span class="ref-lnk lazy-ref"><a data-rid="CIT0047" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2019</a></span>; Costa et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0016" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>). In this respect, what Jornitz and Klinge (<span class="ref-lnk lazy-ref"><a data-rid="CIT0027" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>) write about "digital technologies, such as learning analytics (…), apps (…) or learning software" also applies in part to CAQDAS. Digital technologies "are not pedagogically neutral but hold assumptions about the subject and they stage learning in a certain way: these visualize through algorithmic information processing, knowledge construction and educational practices in particular ways" (ibid., p. 237). These assumptions form a hidden digital curriculum, i.e., an implicit idea of which form of analysis is relevant. In those mentioned above, widespread CAQDAS currently favors specific analysis techniques primarily based on text passages’ coding in the sense of content analysis (Mayring, <span class="ref-lnk lazy-ref"><a data-rid="CIT0039" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>).</p>
  <p>In the broader sense, these educational inscriptions also occur when using AI to support the teaching of method knowledge and skills. Current developments in NLP models are essential regarding epistemological questions in teaching reconstructive research methods through AI. Recently, generative pre-trained transformers (GPTs) such as GPT-3 from OpenAI or the luminous models from Aleph-Alpha are state-of-the-art in natural language generation (NLG). These AI models are pre-trained based on large data sets (Brown et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0013" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>). They base on "deep learning" principles of artificial neural networks (Chowdhary, <span class="ref-lnk lazy-ref"><a data-rid="CIT0014" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>, p. 436). These principles detect "intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer" (LeCun et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0032" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2015</a></span>, p. 436). In the case study presented below, the question is whether AI models can learn the interpretation steps of the documentary method, generate interpretations, and then use this ability in teaching research methods.</p>
 </div>
</div>
<div id="S0003" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i8" class="section-heading-2">Methods: Integrating AI into the teaching of reconstructive methods – a case study</h2>
 <p>The software architectures described so far suggest a way of working for the users, but they are still in charge of concrete interpretation. This article explores whether and how NLP supports interpretation processes itself and what follows from this for teaching and presents a case study within the KISOFT project.</p>
 <p>The KISOFT project initially engages the challenge of integrating existing AI applications into the architecture of <a class="ext-link" href="https://dokumet.de/en/homepage" target="_blank">DokuMet QDA</a>, a software developed for interpretation with the documentary method. At the same time, this article explores the real possibilities of AI’s role in the interpretation process with procedures of deep interpretation (Schäffer, <span class="ref-lnk lazy-ref"><a data-rid="CIT0054" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>), creating a practice of distributed interpretation, especially the documentary method (Bohnsack, <span class="ref-lnk lazy-ref"><a data-rid="CIT0009" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>). Mainly it is interested in the extent to which this could be beneficial for teaching these methods. For this purpose, this article demonstrates a case study with accessible AI models to discover AI’s principal possibilities in the context of interpretation (2.1). In answering the question about the teaching of reconstructive methods by AI, further research must clarify how and whether humans take up such AI abilities. The underlying research to answer this question consists of group discussions (Bohnsack, <span class="ref-lnk lazy-ref"><a data-rid="CIT0008" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2010</a></span>; Weller, <span class="ref-lnk lazy-ref"><a data-rid="CIT0059" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2019</a></span>) via ZOOM with members of research workshops (2.2). In total, the case study demonstrates the use of prompt engineering training NLP models to interpret texts with the documentary method and the reactions of young researchers to that process via group discussion.</p>
 <div id="S0003-S2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i9">Prompt engineering: Training AI to interpret texts</h3>
  <p>The currently used NLP models for the case study are from OpenAI<a href="#EN0002"><sup>2</sup></a> and Aleph Alpha<a href="#EN0003"><sup>3</sup></a>. They were transmitting tasks of the documentary method to the models through human-machine interfaces called <i>playgrounds</i>, allowing easy and intuitive handling of the AI model via a text field. The underlying research of this article uses prompt engineering in these playgrounds to test to what extent the AI can interpret in the style of the documentary method. "Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP" (Bach et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0001" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>, p. 1).</p>
  <p>Prompt engineering differentiates between three approaches of prompting. While zero-shot prompts are easy tasks like short instructions or the beginning of a text in the playground of the model (e.g., <i>luminous-base</i> and <i>luminous-supreme</i> from Aleph-Alpha or <i>GPT-3</i> from OpenAI), one-shot and few-shot prompts are given one or few example(s) to learn how to complete a task. More examples increase the quality of those tasks (Tingiris, <span class="ref-lnk lazy-ref"><a data-rid="CIT0057" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2021</a></span>, pp. 7-9) but also use more computing power.</p>
  <p>Learning the documentary method is complex and understanding it takes quite some time in a young researcher’s professional life. Therefore, training an NLP model to work as a research machine using this method is challenging. The luminous models and GPT-3 consist of large data sets, but assuming they do not have any particular knowledge about the practice of this method, it is vital to train these models. Thus, giving the short instruction "interpret the following texts with the documentary method"—a zero-shot prompt—will not do the trick because the model will produce an output that will not be of any quality.</p>
  <p>Instead, prompt engineering requires preparation and testing for a successful output in the form of a viable interpretation. The research behind this article focused in the beginning on writing different prompts to try out the wording and adjusting it by observing the output. Then, the results get evaluated, whether they express the intended task of generating an interpretation of a given text and documented. These steps of exploring, evaluating, and documenting are repeated several times until the model generates a viable interpretation (Bach et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0001" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>).</p>
  <p>The ongoing challenge is to train a complex research method such as the documentary method. Due to its complexity, it has to be fragmented into many different tasks that can be fit into a prompt, considering it is usually limited to roughly 1000 − 1500 words. Doing so includes a short instruction and some examples. Therefore, training NLP models to perform steps of the documentary method requires few-shot prompts. The following diagram illustrates constructing a prompt in a playground for a specific fragment of the documentary method (<a href="#F0001">Figure 1</a>):</p>
  <div class="figure figureViewer" id="F0001">
   <div class="hidden figureViewerArticleInfo">
    <span class="figViewerTitle">Distributed interpretation – teaching reconstructive methods in the social sciences supported by artificial intelligence</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Sch%C3%A4ffer%2C+Burkhard"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Sch%C3%A4ffer%2C+Burkhard"><span class="NLM_given-names">Burkhard</span> Schäffer</a> <a href="https://orcid.org/0000-0001-9396-3081"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Lieder%2C+Fabio+Roman"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Lieder%2C+Fabio+Roman"><span class="NLM_given-names">Fabio Roman</span> Lieder</a> <a href="https://orcid.org/0000-0001-9735-323X"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/15391523.2022.2148786">https://doi.org/10.1080/15391523.2022.2148786</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>22 November 2022
     </div>
    </div>
   </div>
   <div class="figureThumbnailContainer">
    <div class="figureInfo">
     <div class="short-legend">
      <p class="captionText"><span class="captionLabel">Figure 1. </span> Prompt.</p>
     </div>
    </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="F0001image" src="/na101/home/literatum/publisher/tandf/journals/content/ujrt20/2023/ujrt20.v055.i01/15391523.2022.2148786/20230209/images/medium/ujrt_a_2148786_f0001_b.jpg" loading="lazy" height="328" width="500"></a>
    <div class="figureDownloadOptions">
     <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
    </div>
   </div>
  </div>
  <div class="hidden rs_skip" id="fig-description-F0001">
   <p class="captionText"><span class="captionLabel">Figure 1. </span> Prompt.</p>
  </div>
  <div class="hidden rs_skip" id="figureFootNote-F0001">
   <div class="figureFootNote-F0001"></div>
  </div>
  <p>The AI model aims to generate an output that a researcher working with the documentary method can identify as an interpretation. To achieve that, three full-length interpretations of transcript excerpts of an interview are inserted into the text field of the experimental environment. Each is a transcript excerpt followed by a <i>formulating</i> and a <i>reflecting interpretation</i> in the sense of the documentary method.</p>
  <p>The challenge here is to modify the prompt so that a satisfactory result is generated using three examples. The basic idea is to train general language models individually on a specific material to be interpreted through prompt engineering. Prompt engineering, in this case, is the art of achieving much with just a few resources. However, training a model with a large data set would have the disadvantage that the unstructuredness of qualitative data can only be taken into account to a small extent since the material is as diverse as the people who interpret it.</p>
  <p>Further, the structure and content of the inputs contribute significantly to satisfactory results. Thus, making the inputs uniform as far as possible is advisable. For example, the number of characters used in the inputs should be approximately the same, and a homogeneous content influences the result positively.</p>
 </div>
 <div id="S0003-S2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i11">Group discussion: potential practical orientations of junior researchers regarding machine interpretation</h3>
  <p>Group discussion and focus group procedures originated in the 1920s (Bogardus, <span class="ref-lnk lazy-ref"><a data-rid="CIT0006" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1926</a></span>). However, the procedure was discovered relatively late by the mainstream social sciences (Liamputtong, <span class="ref-lnk lazy-ref"><a data-rid="CIT0033" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2011</a></span>). The international literature is (still) more focused on the pragmatics of survey forms (Krueger &amp; Casey, <span class="ref-lnk lazy-ref"><a data-rid="CIT0029" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>). Only recently, there has been research on focus groups in symbolic interactionism (Liamputtong, <span class="ref-lnk lazy-ref"><a data-rid="CIT0033" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2011</a></span>) and grounded theory (Barbour, <span class="ref-lnk lazy-ref"><a data-rid="CIT0003" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2007</a></span>). Even before that, group discussions explored class, gender, and race dimensions in British cultural studies (Livingstone &amp; Lunt, <span class="ref-lnk lazy-ref"><a data-rid="CIT0035" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1996</a></span>). Overall, focus groups became popular in the Anglo-Saxon world as a method that seemed more suitable for pretesting and hypothesis generation than for valid and reliable research (Merton, <span class="ref-lnk lazy-ref"><a data-rid="CIT0041" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1987</a></span>; Krueger &amp; Casey, <span class="ref-lnk lazy-ref"><a data-rid="CIT0029" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>).</p>
  <p>In contrast, an independent group discussion line developed in the German-speaking world (Pollock, <span class="ref-lnk lazy-ref"><a data-rid="CIT0046" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1955</a></span>; Mangold, <span class="ref-lnk lazy-ref"><a data-rid="CIT0038" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1960</a></span>), with little overlap with the focus group line. In this praxeological perspective in the tradition of the documentary method (Bohnsack, <span class="ref-lnk lazy-ref"><a data-rid="CIT0009" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2014</a></span>), the focus is neither on analyzing individual opinions in a group context nor on group dynamics developments during the discussion. Instead, Bohnsack (<span class="ref-lnk lazy-ref"><a data-rid="CIT0008" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2010</a></span>) conceives groups as carriers of collective orientations and as epiphenomena of collective entities that go beyond the concrete group. Opinions and attitudes expressed in a discussion form a document for underlying fundamental (action) orientations. In this perspective, issues and opinions may change in a discussion, but the underlying collective orientations, formed from shared or structurally identical collective experiences, remain constant. They form the <i>modus operandi</i>, within which a group treats different issues and opinions in the same way (over and over again). Thus, analyses of group discussions in this tradition focus on experience-based, collective (practical) orientations.</p>
  <p>In terms of the research interest in the project, this means the following. First, the group discusses the initial opening question about common interpretive practices: <i>How do you actually interpret empirical material?</i> Collective narratives and descriptions are elicited or generated in the first phase of the discussion, from which general practical orientations concerning interpretive practices can be worked out. Next, the group observes interpretive AI and discusses the question: <i>What do you think of this now? What’s going through your minds?</i> In reaction, different opinions will undoubtedly be expressed in propositions that agree, disagree, or are neutral about interpreting with an AI.</p>
  <p>However, the participants look for references to their interpretation practice and discuss with others their experiences. It is then the task of the researchers to work out the embedded opinions within the larger framework of general interpretive orientations concerning interpreting with AI. Ultimately, it also becomes apparent whether collective action orientations based on shared or structurally identical experiences can be drawn. After all, representatives of different collective orientations of action can physically sit together in a collocated group who do not have a shared collective orientation framework and then work off each other in the form of an oppositional discourse organization (pro and contra). Presumably, such an oppositional constellation will be less the case in groups working together for a more extended period than in groups assembled ad hoc, which is why the sample preference will be given to recruiting groups from different research groups workshops that take place regularly. First, the groups observe how an AI interprets a text passage (= machine interpretation) via screen sharing. Second, the discourse communication gives into their orientations about <i>distributed interpretation</i> between the machine and researchers. The discussions aim to highlight opinions and reconstruct orientations toward machine interpretation to assess the extent to which learners would engage with the new possibilities of teaching in the first place.</p>
 </div>
</div>
<div id="S0004" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i12" class="section-heading-2">Results: Usable prompts and reactions from learners</h2>
 <p>First, the case study results demonstrate an exemplary interpretation generated by the above prompt (3.1). By addressing whether the NLP model can learn fragments of interpretation steps of the documentary method, this article shows the actual AI-generated output with the NLP luminous-models from Aleph-Alpha and discusses its quality. Further, by demonstrating the results of a group discussion with doctoral candidates, this article highlights explorative orientations on the potential usage of machine interpretation within the documentary method (3.2).</p>
 <div id="S0004-S2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i13">Machine interpretation with the models luminous-base and luminous-supreme – possibilities of teaching AI to interpret in the sense of the documentary method</h3>
  <p>To clarify, the three inputs to create a viable machine-generated interpretation were taken from the same material. Considering the sequential steps of the documentary method, it is a text fragment and a human-made interpretation of an interview transcript spoken by the same person ("Richard"). The input reads as follows:</p>
  <p>Richard: So, if we think about this webinar now, that would not have been possible fifteen years ago, so period. Yes, and now we have the possibility actually, with sixty-eight, we were over a hundred people, to be in one room at the same time. And that’s a new possibility that actually the digitality brings.</p>
  <p>AI: FI: Possibility of digitality</p>
  <p>RI: The topic is continued by Richard concretely based on the webinar, stating that this would not have been possible "fifteen years ago." He emphasizes this assertion and the already known irrefutability by leading the assertion at the end of the sentence with the statement "so period"; which gives the impression that this is a final truth that cannot be questioned. Furthermore, Richard states that the possibility now exists to gather "sixty-eight" participants in one room. Again, the possible attempt of valorization by naming the exact number of participants is shown.</p>
  <p>This input is one of three examples inserted in the playground to train the models <i>luminous-base</i> and <i>luminous</i>-<i>supreme</i> from Aleph Alpha via few-shot prompting. The following two examples given to the model are from the same material; thus, they resemble each other in structure but not in content even though the theme is not entirely different, because it is always "Richard" who speaks in these examples.</p>
  <p>Finally, the prompt consists of a fourth input that only includes an excerpt from the transcript, which is to be interpreted by the models. Using the three example inputs, the models reproduce their structure and generate a new interpretation of the following transcript passage:</p>
  <p>Richard: I’m not a fan of these comparisons because I’m not comparing apples and oranges either, but we simply say we now have digital media. And the digital media we try to rethink and design other didactic scenarios.</p>
  <p>These samples form the prompt for the model to generate a coherent interpretation. Prompt engineering refers to optimizing these inputs to suggest the best possible result.</p>
  <p>In the case of successful prompt engineering, the AI model appropriates the structure of the interpretation and continues it on its own. For example, the following output results from a generated interpretation by luminous-base:</p>
  <p>FI: Compare</p>
  <p>RI: Richard uses the phrase "we now have digital media" to compare what was possible before and what is possible now or how learning has changed through the digitalization of the learning world itself. Once again, there is no further questioning or explanation here as to why it should be necessary for him as a scientist to draw such comparisons (cf. chapter 4.3). Richard also assumes an irrevocability concerning the didactics of learning by stating that "we" are trying to "think anew." This suggests that other people could also take on this task ("we").</p>
  <p>Apart from some irritations, the machine-generated interpretation shows that the AI clearly <i>simulates</i> an understanding of the meaning of the transcript. It created an <i>interpretation</i> that makes sense for a human being. The model luminous-base recognized that the formulating interpretation names what Richard (in this case) said in a transcript. The theme "Compare" is not particularly profound but captures the issue. The content of the reflecting interpretation also reads bumpy, but with just three examples, the AI model has generated a text of meaningful interpretations.</p>
  <p>While luminous-base can generate an acceptable interpretation, the further development luminous-supreme is already much more powerful. For comparison, the following shows a machine interpretation based on the same input:</p>
  <p>FI: Comparison of apples and pears, but not with digital media</p>
  <p>RI: Richard starts the last section of his speech by explaining "I am not a friend" of making certain comparisons (apples/pears) or that he also avoids them in relation to digital learning media ("we just say we have digital media now"). However, he justifies this only by stating the incomparability of these two things without giving further reasons or explanations why this is so… Subsequently, it turns out what exactly was meant when it came to a possible comparison - namely to rethink a didactic scenario for digital learning! This makes it clear how important this topic is from the speaker’s point of view; after all, this is about working out a new didactics in the field of digital teaching-learning forms…</p>
  <p>Even with this machine-generated interpretation, there are still some errors that a human interpreter would not have made. For example, luminous-supreme speaks in a quotation of a "friend" although the input uses the word "fan". Nevertheless, it is immediately recognizable that the generated text is of higher quality than the text generated by luminous-base (e.g. in terms of coherence and comprehensibility).</p>
  <p>It can be assumed that "[f]urthermore, training directly on collections of prompts can enable large models to generalize to new prompts more robustly" (Bach et&nbsp;al., <span class="ref-lnk lazy-ref"><a data-rid="CIT0001" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2022</a></span>, p. 1). Fine-tuning the models with several hundred (better: several thousand) interpretation examples would thus enable the generation of much better interpretations. Further, the article shows how members of a research workshop received these machine interpretations—based on the group discussion.</p>
 </div>
 <div id="S0004-S2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i14">Explorative orientations on machine interpretation – "I looked at that and thought that can’t be true."</h3>
  <p>How does an interpretation group from a research workshop, consisting of typical young researchers at the beginning of their interpretation career, react to the interpretation of the AI? The following table describes the sample consisting of eight participants in the group discussion (<button class="ref showTableEventRef" data-id="t0001">Table 1</button>):</p>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Distributed interpretation – teaching reconstructive methods in the social sciences supported by artificial intelligence</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Sch%C3%A4ffer%2C+Burkhard"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Sch%C3%A4ffer%2C+Burkhard"><span class="NLM_given-names">Burkhard</span> Schäffer</a> <a href="https://orcid.org/0000-0001-9396-3081"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Lieder%2C+Fabio+Roman"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Lieder%2C+Fabio+Roman"><span class="NLM_given-names">Fabio Roman</span> Lieder</a> <a href="https://orcid.org/0000-0001-9735-323X"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/15391523.2022.2148786">https://doi.org/10.1080/15391523.2022.2148786</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>22 November 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <div class="short-legend">
     <h3><p class="captionText"><span class="captionLabel">Table 1. </span> Sample.</p></h3>
    </div>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="t0001-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0001&amp;doi=10.1080%2F15391523.2022.2148786&amp;downloadType=CSV"> Download CSV</a><a data-id="t0001" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p>The group is torn when confronted with an AI-generated interpretation and the talk impulse (<i>What do you think of this now? What’s going through your minds</i>?). On the one hand, the AI is seen positively as a "counterpart" with whom one can "virtually interact" (689–690<a href="#EN0004"><sup>4</sup></a>). On the other hand, one could look at "what the AI says" to "perhaps also get new impulses, complementary to what I have from research workshops" (744–746). The essentialist question of whether the output of an AI equates with "what the human mind" produces meets with approval: it is "really great when machines can do that" (821).</p>
  <p>On the other hand, there are skeptical opinions that suggest an underlying rejectionist orientation toward action: What emerges with the help of the mind is "more convincing (…) than what is ultimately produced by zero and one" (859–864). The digital machine is here denied equality with the human mind. Such passages can be read as an anthropocentric perspective against artificial intelligence’s disempowerment of the human spirit. A participant describes AI as an "absolute seduction" (691) in a negative sense. One "gives something out of one’s hand", has "no control" anymore (695–697), and runs the risk of "becoming comfortable as a researcher" (739). In a parallel argumentation structure, negative evaluations often counter positive ones. The participants try to protect themselves from letting the fascination with the possibilities of interpreting with an AI get out of hand. One would have looked at it and thought, "that can’t be true" (763), and "as a scientist", one immediately thought about how one could "check that very carefully" (769).</p>
  <p>The desire for a stronger counterpart in the form of AI, and certainly in the sense of a significant other who makes suggestions for interpretation, is central for software that "simulates the research workshop a bit, so to speak"; as a "partner" that "simply suggests another way of reading" (314–315).</p>
  <p>Overall, the discussion documents that the participants evaluate the possibilities of AI against the background of their own interpretive experiences. For example, their observations differ depending on how they have worked with CAQDA software. Due to the lack of substantial personal experience with AI support, the results can also be seen as a document for the digital mindsets of the participants, which are characterized by great ambivalence. When introducing this technology into teaching contexts, educators should consider this ambivalence. Otherwise, failure is to be expected from the outset.</p>
 </div>
</div>
<div id="S0005" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i15" class="section-heading-2">Discussion of the results from prompt engineering and group discussion</h2>
 <p>The participants’ examination of the results of machine interpretation is a prerequisite for placing trust in it. However, doing so is countered by today’s AIs, which are mainly nontransparent due to their complexity and the sheer volume of data processed in the hidden layers. Their use in an interpretive process insofar presupposes a "risky investment" through the "trusting expectation" (Luhmann, <span class="ref-lnk lazy-ref"><a data-rid="CIT0036" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1979</a></span>, p. 24) that the use of an AI helps find new perspectives without overextending oneself in the state of almost infinite contingency. Interpreting, especially in a research workshop, already means exposing oneself to many contingent attributions of meaning and possibilities of interpretation. As a result, the material to be researched initially appears opaque and confusing, especially for beginners. This state intensifies by the participation of an AI in the interpretation process if it is not blindly trusted. Instead, regarding its hidden layers, the desire is expressed for verifiability. De Witt and Leineweber (<span class="ref-lnk lazy-ref"><a data-rid="CIT0062" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2018</a></span>) counter the resulting complexity with the necessity of limiting the knowledge of both the AI and the researchers since subjective perspectives are necessarily subject to incompleteness.</p>
 <p>The desire for a stronger counterpart, a significant other in Mead’s terms as an AI, shows that some participants adhere to a technically supported utopia of education and support. The AI should simulate different persons who all offer different interpretations of the same passage. Such a utopia was already formulated in earlier years by J. C. R. Licklider (<span class="ref-lnk lazy-ref"><a data-rid="CIT0034" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1967</a></span>), in which "[t]hrough such interaction, the heuristic capabilities of men and the algorithmic capabilities of computers—the highest capabilities of the cooperating partners—can be melted together to produce what may turn out to be a significant augmentation of intellectual power" (ibid., p. 40). Nevertheless, whether the interpretive offers are a significant other is questionable. A significant other in a research workshop can justify and defend his interpretation when asked. Justifying an interpretation is not (currently) possible with AI, so one could rather speak of an <i>opaque other</i> here. Interpreters would then take on the role of a spider in the web, whose task is to sift through the different perspectives of the AI, evaluate them and create a synthesis. Ultimately, an interpretation process understood in this way can be described <i>together with AI</i> as a constellation of distributed intelligence that manifests itself "across minds, persons, and the symbolic physical environments, both natural and artificial" (Pea, <span class="ref-lnk lazy-ref"><a data-rid="CIT0043" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1993</a></span>, p. 47). Thus, research is not interpreted in isolation by a researcher but within a socio-technical network of people and machines. As documented in the group discussion, these are practices "for avoiding mental work, or for avoiding error, and they are adapted creatively almost without notice" (ibid., p. 48).</p>
</div>
<div id="S0006" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i16" class="section-heading-2">Conclusions on reciprocal perspectives on machine and human interpretation in education</h2>
 <p>This article highlights that interpreting is multifaceted, a reciprocal relationship of different actors and artifacts as tools that form an interpretive network of distributed intelligence (Pea, <span class="ref-lnk lazy-ref"><a data-rid="CIT0043" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1993</a></span>). Subsequently, this article proposes the notion of distributed interpretation as a practice of reconstructive research that resembles a neural network consisting of machine interpretation by AI on the one hand and deep interpretation by human interpreters on the other. Reciprocal relations between these entities result in abductive leaps and, thus, creative interpretive performances, which promote method skills. AI becomes an interpretation generator whose potential, but also danger, lies on the one hand in generating an infinite number of machine interpretations—sometimes more, sometimes less accurate. On the other hand it enables abductive leaps and loosens creative blockades by irritating the human interpreters. Machine interpretation thus extends deep interpretation, creating a state of distributed interpretation. The AI takes on the role of an opaque other, in a certain sense, like an oracle, and a hybrid research workshop emerges in which learners acquire method knowledge and skills together with the AI. Some conceptual sharpening was necessary to answer whether AI is suitable for supporting research with and teaching reconstructive methods. Discussing different teaching method skills leads to research workshops that best address the level of method skills.</p>
 <p>CAQDAS presents possibilities for teaching method knowledge (which often remains implicit) and method skills. This article highlighted options for research with and teaching reconstructive methods resulting from using machine interpretation. The following can be stated in light of the case study and the group discussion.</p>
 <ul class="NLM_list NLM_list-list_type-bullet">
  <li><p class="inline">AI will put the procedures of deep interpretation under high pressure to change into a practice of distributed interpretation. Moreover, it will open new possibilities for their teaching.</p></li>
  <li><p class="inline">Teaching, learning, and research are highly collective, interdependent endeavors.</p></li>
  <li><p class="inline">Lack of trust in AI stems from the high degree of opacity in generating results within the hidden layers of AI. Thus, AI is not a significant but an opaque other.</p></li>
  <li><p class="inline">A state of "tolerance of uncertainty" (Luhmann, <span class="ref-lnk lazy-ref"><a data-rid="CIT0036" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1979</a></span>, p. 15) with machine-generated interpretation reduces the threatening complexity through conscious self-restraint, accepting the unverifiability of these interpretations</p></li>
  <li><p class="inline">Teaching deep interpretation with AI aims to develop a new dimension of method skills, i.e., the ability to deal productively with an AI’s interpretive offers and, if necessary, to reject them.</p></li>
 </ul>
 <p></p>
 <p>Researchers should learn to deal with the resulting contingency through self-determination and responsibility (De Witt &amp; Leineweber, <span class="ref-lnk lazy-ref"><a data-rid="CIT0062" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2018</a></span>). Presumably, machine interpretation will improve the possibilities of teaching reconstructive methods in the long run. A new type of research-based teaching and learning in the sense of the "hybrid actor" (Latour, <span class="ref-lnk lazy-ref"><a data-rid="CIT0030" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1994</a></span>, p. 33) appears possible. Students and researchers acquire the necessary method knowledge through reading, seminars, lectures, and the help areas in conventional CAQDAS and cultivate the exchange of content in research workshops. They acquire part of their method skills in the mode of <i>Legitimate Peripheral Participation</i> (Lave &amp; Wenger, <span class="ref-lnk lazy-ref"><a data-rid="CIT0031" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1991</a></span>). The acquisition and deepening of a different part of the method skills occur through interaction with the machine interpretation outputs. Their suggestions for interpretation are used alone or in research workshops as a potential source of irritation.</p>
 <p>Future research aims at integrating machine interpretation into the <a class="ext-link" href="https://dokumet.de/en/homepage" target="_blank">DokuMet QDA</a> environment so that users can make queries to the AI from within an interpretation they are currently working at. In addition, the KISOFT Project intends to make the AI-supported CAQDAS available to groups of researchers with different prior experiences and to reconstruct how users implement machine interpretations in their work process based on usage history data.</p>
 <p>The common practice in research workshops does not quantify the goodness of their interpretations but is oriented toward the "forceless force of the better argument" (Habermas, <span class="ref-lnk lazy-ref"><a data-rid="CIT3633875" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>1999</a></span>, p. 332). In the future, the underlying research intends to intersubjectively assure the quality of the machine-generated interpretations. For this purpose, the following rating scale has already been developed, which will be presented to test persons with a mixture of human and machine-generated interpretations. On the one hand, the test persons are to assess the quality, and, on the other hand - quite in the sense of the Turing Test - they are to assess whether a human or a machine generated the interpretation. The following table explicates this largely implicit experiential knowledge by rating both machine and human interpretation on a scale of one to six (<button class="ref showTableEventRef" data-id="t0002">Table 2</button>).<a href="#EN0005"><sup>5</sup></a></p>
 <div class="tableViewerArticleInfo hidden">
  <span class="figViewerTitle">Distributed interpretation – teaching reconstructive methods in the social sciences supported by artificial intelligence</span>
  <div class="articleAuthors articleInfoSection">
   <div class="authorsHeading">
    All authors
   </div>
   <div class="authors">
    <a class="entryAuthor" href="/action/doSearch?Contrib=Sch%C3%A4ffer%2C+Burkhard"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Sch%C3%A4ffer%2C+Burkhard"><span class="NLM_given-names">Burkhard</span> Schäffer</a> <a href="https://orcid.org/0000-0001-9396-3081"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Lieder%2C+Fabio+Roman"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Lieder%2C+Fabio+Roman"><span class="NLM_given-names">Fabio Roman</span> Lieder</a> <a href="https://orcid.org/0000-0001-9735-323X"><img src="/templates/jsp/images/orcid.png"></a>
   </div>
  </div>
  <div class="articleLowerInfo articleInfoSection">
   <div class="articleLowerInfoSection articleInfoDOI">
    <a href="https://doi.org/10.1080/15391523.2022.2148786">https://doi.org/10.1080/15391523.2022.2148786</a>
   </div>
   <div class="articleInfoPublicationDate articleLowerInfoSection border">
    <h6>Published online:</h6>22 November 2022
   </div>
  </div>
 </div>
 <div class="tableView">
  <div class="tableCaption">
   <div class="short-legend">
    <h3><p class="captionText"><span class="captionLabel">Table 2. </span> Scale.</p></h3>
   </div>
  </div>
  <div class="tableDownloadOption" data-hascsvlnk="false" id="t0002-table-wrapper">
   <a data-id="t0002" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
  </div>
 </div>
 <p>In the KISOFT project, this evaluation is used in the further course of the research to evaluate and compare large sets of machine-generated and human-generated interpretations.</p>
 <p>Additional group discussions will generate more data regarding orientations to machine interpretation to construct a typology of the practice of distributed interpretation processes through comparison. Further, research should be oriented toward developing a <i>computational documentary method</i>, e.g., following Nelson (<span class="ref-lnk lazy-ref"><a data-rid="CIT0042" data-reflink="_i17 _i18" href="#"><span class="off-screen">Citation</span>2020</a></span>). KISOFT will move beyond the support by computers and software to small tasks such as sentiment analysis and will grant an AI model in a trusting expectation a more responsible role in the interpretation process. Further, it will fine-tune the models by Aleph Alpha and the models by OpenAI with larger data sets.</p>
 <p>At the end of this research stands an interpretive AI model embedded in DokuMet QDA, forming a hybrid research workshop of distributed interpretation. As a result, researchers would always have the option to engage in a teaching-learning interaction with different AI-based interpretive partners about the method, methodology, and practice.</p>
</div>