<div id="s0001" class="NLM_sec NLM_sec_level_1">
 <p>Human conversational interactions are, naturally, a complex phenomenon. When we take part in such interactions, we may utilize a range of visual, verbal, and linguistic cues to interpret the intentions of other participants, formulate responses and organize turns of talk (Goodwin, <span class="ref-lnk lazy-ref"><a data-rid="cit0040" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1981</a></span>). Even when considered solely in an audio or text-based form, the utterances of an interaction cannot be fully understood on an individual basis, but rather must be interpreted within the context of their position within the sequence of utterances (Ekman &amp; Scherer, <span class="ref-lnk lazy-ref"><a data-rid="cit0033" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1984</a></span>). The question of how such intricate conversational data can be represented in a computationally practical format remains an open problem within Natural Language Processing (NLP) research.</p>
 <p>The predominant approach to representing dialogue semantics, for the purpose of NLP, is the use of Dialogue Acts (DA). Originating from John Austin’s “illocutionary act” theory (Austin, <span class="ref-lnk lazy-ref"><a data-rid="cit0009" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1962</a></span>), and later developed with John Searle’s “speech acts” (Searle, <span class="ref-lnk lazy-ref"><a data-rid="cit0064" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1969</a></span>), a DA defines the semantic content and communicative function of a single utterance of dialogue, for example, a question, statement or greeting. The utility of DA, as a set of labels for a semantic interpretation of a given utterance, has led to their use in many NLP applications. In dialogue management systems they have been used as a representation of user and system dialogue turns, as a set of possible system actions, and as a means of dialogue state tracking (DST) (Cuayahuitl et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0030" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2016</a></span>; Firdaus et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0035" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2020</a></span>; Ge &amp; Xu, <span class="ref-lnk lazy-ref"><a data-rid="cit0036" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2015</a></span>; Griol et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0042" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>; Keizer &amp; Rieser, <span class="ref-lnk lazy-ref"><a data-rid="cit0049" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2017</a></span>; Li et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0053" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2017</a></span>). For spoken language translation Kumar et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0051" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>) utilized the contextual information provided by DAs to improve accuracy in phrase-based statistical speech translation. They have also been used to analyze the structure of dialogue within the intelligent tutoring domain (Boyer et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0014" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2009</a></span>, <span class="ref-lnk lazy-ref"><a data-rid="cit0015" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>), and everyday conversations (Iseki, <span class="ref-lnk lazy-ref"><a data-rid="cit0046" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2019</a></span>). While DA do provide valuable semantic and intentional information, they naturally consider utterances as an isolated unit. In so doing, they fail to recognize the sequential nature of interactions, and the influence that both context and position have, on the production and meaning of an utterance (Clift, <span class="ref-lnk lazy-ref"><a data-rid="cit0025" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2016</a></span>; Ekman &amp; Scherer, <span class="ref-lnk lazy-ref"><a data-rid="cit0033" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1984</a></span>). As Clift (<span class="ref-lnk lazy-ref"><a data-rid="cit0025" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2016</a></span>), points out, “<i>the form of an utterance alone cannot necessarily be relied upon to deliver how it is understood by its recipient</i>.” Consider the use of “Okay” in the following examples. In the first instance speaker B uses “Okay” in response to a question. In the second instance, speaker A uses “Okay” as confirmation that a response has been heard and understood.</p><preformat xml:space="preserve" position="float" orientation="portrait" id="_i2">
        1 A: How are you?   2 A: Do you need help with that?
 </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i3">
        &nbsp;&nbsp;B: Okay        &nbsp;&nbsp;&nbsp;B: No thank you.
 </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i4">
                    &nbsp;&nbsp;A: Okay 
 </preformat>
 <p>What is needed, then, is a method of representing not just the semantics of single utterances but the context within which they were produced and their contribution to the interaction as a whole. For this, we turn to the study of human conversation. Conversation Analysis (CA) is an area of sociological research that aims to define, and analyze, constructs that facilitate turn-taking in human conversations (Sacks et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0061" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1974</a></span>). Some key principles of CA are: that turns of talk have some organizational structure; that the structure itself has a descriptive quality for the utterances produced; and in turn, helps to shape the future utterances of the interaction (Schegloff, <span class="ref-lnk lazy-ref"><a data-rid="cit0062" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>; Sidnell, <span class="ref-lnk lazy-ref"><a data-rid="cit0066" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>). Within CA, this structure is defined using the concept of the Adjacency Pair (AP) as the base units of sequence-construction in talk. Utterances are labeled with AP such that they describe the relational structure <i>between</i> utterances of a dialogue. Therefore, DA labels may be considered descriptions of the <i>intra-utterance</i> features of a dialogue, while AP represent the <i>inter-utterance</i> features.</p>
 <p>In this article, we introduce the Conversation Analysis Modeling Schema (CAMS). With CAMS, we hope to produce richer and more expressive representations of dialogue, in a computationally compatible format, to aid in the development of Conversational Artificial Intelligence (CAI) tasks, such as dialogue management and DST, as well as other NLP applications. The schema defines a domain agnostic annotation scheme for dialogue that is aligned with relevant theories from within the CA literature, to express the general structure of an interaction, while leveraging the descriptive power of the DA for individual utterances. The schema defines both AP and DA labels which combine to form AP-types. The AP-type labels are intended to capture the semantic and syntactic structure of an interaction, in a format that is independent of the domain or topic, and which facilitate the computational modeling of dialogue. We evaluate CAMS by means of an annotation study, calculate measures of inter-annotator agreement in order to assess its efficacy when applied to both task and non-task-oriented dialogs, and determine the extent to which novice annotators arrive at a shared understanding of the categories within the coding scheme. We also record users’ self-reported annotation confidence scores, and average utterance annotation times, as an additional human-factors analysis. Through these measures, we hope to evaluate considerations, such as, choice of agreement coefficient, source of dialogue material, and annotator characteristics or behaviors, which may affect application of the schema for further annotation tasks.</p>
 <p>The following section provides a full description of CAMS, its labels and annotation guidelines. Then, Inter-Annotator Agreement measures are outlined, and the distance functions used for weighted agreement coefficients within this study are defined in Weighted Coefficient Distance Functions section. Data and Methods gives details of the methodological setup, selection of participants and dialogue corpora, before discussing the results obtained from the annotation procedure in Results and Discussion. And finally, our Conclusions are drawn.</p>
</div>
<div id="s0002" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i5" class="section-heading-2">Conversation analysis modeling schema overview</h2>
 <p>CAMS is intended to combine concepts of DA and AP into a single annotation scheme that is able to capture the semantic and syntactic structure of a dialogue at the <i>inter</i> and <i>intra</i> utterance level. Additionally, AP and DA may be applied to any type of conversational interaction, independent of domain and topic, and as such, the schema is entirely domain agnostic and applicable both to task and non-task-oriented dialogs.</p>
 <p>The schema defines two sets of labels, DA and AP, which are combined to form AP-type labels. When applying the schema, the intent is to assign each utterance of a dialogue one DA and one AP label, which together are considered the AP-type label for that utterance. The AP-type labels, for a fully annotated dialogue, can then be viewed as a representation of its semantic and syntactic structure, as described above. It should be noted that the concept of a <i>typed AP</i> is a key feature of AP present within the CA literature (Clift, <span class="ref-lnk lazy-ref"><a data-rid="cit0025" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2016</a></span>; Liddicoat, <span class="ref-lnk lazy-ref"><a data-rid="cit0054" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>; Schegloff, <span class="ref-lnk lazy-ref"><a data-rid="cit0062" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>; Sidnell, <span class="ref-lnk lazy-ref"><a data-rid="cit0066" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>). However, the standard annotation schemes for CA do not strictly require each utterance of dialogue to be labeled with an AP. Additionally, CA annotation often includes non-verbal sounds, pauses and other types of disfluencies. Gaps in annotations, where utterances are not labeled with AP, and other forms of non-verbal annotation, for example, “breathing,” are generally undesirable for computational purposes. CAMS, therefore, is an attempt to define these concepts, and how they may be applied, into a computationally compatible format where each utterance is labeled with an AP-type. The following sections provide an overview of AP, DA, and AP-types, and their respective sets of labels defined within the schema.<span class="ref-lnk fn-ref-lnk lazy-ref"><a data-rid="fn0001" href="#" data-reflink="fn"><span class="off-screen">Footnote</span><sup>1</sup></a></span></p>
 <div id="s0002-s2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i6">Adjacency pairs</h3>
  <p>AP are the base units of sequence-construction in talk, and in their basic unexpanded form, comprise of two turns by different speakers that take place one after the other. The initial turn is called the <i>First Pair Part</i> (FPP) and initiates an exchange, the second turn is a <i>Second Pair Part</i> (SPP) which is responsive to the prior FPP. AP may also be “type related,” for example, a question and an answer (Schegloff, <span class="ref-lnk lazy-ref"><a data-rid="cit0062" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>). This <i>pair-type</i> relation has the useful property of limiting the range of possible SPP responses to a given FPP, for example, a question could be followed by an answer (though not necessarily) but is unlikely to be followed by a greeting (Liddicoat, <span class="ref-lnk lazy-ref"><a data-rid="cit0054" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>). For the purpose of analysis within NLP, and particularly dialogue systems, this is advantageous because it reduces the set of all possible SPP responses to just a few types. Participants in conversation orient to this basic sequence structure in developing their talk and set up expectations about how talk will proceed. Within the schema they are assigned the FPP-base and SPP-base labels, and these represent the core activity through which speakers accomplish their communicative goals, or actions.</p><preformat xml:space="preserve" position="float" orientation="portrait" id="_i7">
    A: What time is it?&nbsp;&nbsp;&nbsp;
   <b><i>FPP-base</i></b>
  </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i8">
    B: Three o’ clock.&nbsp;&nbsp;&nbsp;&nbsp;
   <b><i>SPP-base</i></b> 
  </preformat>
  <div id="s0002-s2001-s3001" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i9">Expansions</h4>
   <p>To account for more complex dialogue structures, AP also include the concept of <i>expansion</i>, which allows the construction of sequences of talk that are made up of more than one AP, while still contributing to the same basic action (Liddicoat, <span class="ref-lnk lazy-ref"><a data-rid="cit0054" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>). Sequence expansion is constructed in relation to a base sequence of a FPP and SPP in which the core action under way is achieved. There are three types of expansion pairs <i>Pre, Post</i>, and <i>Insert</i>.</p>
   <div id="s0002-s2001-s3001-s4001" class="NLM_sec NLM_sec_level_4">
    <h5 class="section-heading-5" id="_i10">Pre-expansions</h5>
    <p>Are designed to be preliminary to some projected base sequence and may be considered as preludes to some other action.</p>
    <div class="tableViewerArticleInfo hidden">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="tableView">
     <div class="tableCaption">
      <p class="fulltext" align="left">Table</p>
     </div>
     <div class="tableDownloadOption" data-hascsvlnk="true" id="ut0001-table-wrapper">
      <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=ut0001&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="ut0001" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
     </div>
    </div>
    <p></p>
   </div>
   <div id="s0002-s2001-s3001-s4002" class="NLM_sec NLM_sec_level_4">
    <h5 class="section-heading-5" id="_i11">Post-expansions</h5>
    <p>Allow talk to occur after a base sequence, which is recognizably associated with the preceding sequence.</p>
    <div class="tableViewerArticleInfo hidden">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="tableView">
     <div class="tableCaption">
      <p class="fulltext" align="left">Table</p>
     </div>
     <div class="tableDownloadOption" data-hascsvlnk="true" id="ut0002-table-wrapper">
      <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=ut0002&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="ut0002" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
     </div>
    </div>
    <p></p>
   </div>
   <div id="s0002-s2001-s3001-s4003" class="NLM_sec NLM_sec_level_4">
    <h5 class="section-heading-5" id="_i12">Insert-expansions</h5>
    <p>Occur between base adjacency pairs and separates the FPP and SPP. Insert-expansions interrupt the activity previously underway but are still relevant to that action and allows the second speaker (who must produce the base SPP), to do interactional work relevant to the base SPP. Once the sequence is completed, the base SPP once again becomes relevant as the next action. For example, a question (FPP-base) could be followed by a question (FPP-insert), to elicit information required to better answer the initial question. The insert-expansion is then concluded before completing the original base pair, as in the following example.</p>
    <div class="tableViewerArticleInfo hidden">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="tableView">
     <div class="tableCaption">
      <p class="fulltext" align="left">Table</p>
     </div>
     <div class="tableDownloadOption" data-hascsvlnk="true" id="ut0003-table-wrapper">
      <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=ut0003&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="ut0003" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
     </div>
    </div>
    <p></p>
   </div>
  </div>
  <div id="s0002-s2001-s3002" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i13">Minimal-Expansions</h4>
   <p>Because dialogue does not always contain even numbers of utterances, there are also single-utterance <i>minimal-expansions</i>, for utterances that do not belong to conventional AP. CAMS defines three types of minimal-expansion <i>Pre, Post</i>, and <i>Insert</i>, which behave in a similar manner to their expansion counterparts. That is, they must be produced before, after, or inside a base sequence. These are closely related to the idea of minimal post-expansions (Schegloff, <span class="ref-lnk lazy-ref"><a data-rid="cit0062" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>), in that they are not designed to project any further sequences of talk, but rather open, close or add to sequences respectively. The primary role is to allow for additional turns that behave as expansions but consist only of one turn. There is no restriction on speaker order for minimal-expansions, which allows the same speaker to produce more than one utterance of different types in succession, or for a speaker to produce one utterance that does not belong to (initiate or conclude) an AP.</p>
   <div class="tableViewerArticleInfo hidden">
    <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>17 January 2022
     </div>
    </div>
   </div>
   <div class="tableView">
    <div class="tableCaption">
     <p class="fulltext" align="left">Table</p>
    </div>
    <div class="tableDownloadOption" data-hascsvlnk="true" id="ut0004-table-wrapper">
     <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=ut0004&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="ut0004" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
    </div>
   </div>
   <p></p>
   <p>In summary, there are 11 AP in the schema and the set includes: Two labels for the base pair, FPP-base and SPP-base. Six labels for expansion pairs. That is, FPP and SPP for pre, post and insert expansions, as described by Liddicoat (<span class="ref-lnk lazy-ref"><a data-rid="cit0054" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2007</a></span>) and Sidnell (<span class="ref-lnk lazy-ref"><a data-rid="cit0066" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>). And three labels for minimal expansions, pre, post, and insert.</p>
  </div>
 </div>
 <div id="s0002-s2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i14">Dialogue acts</h3>
  <p>Though it was philosophers such as Austin (<span class="ref-lnk lazy-ref"><a data-rid="cit0009" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1962</a></span>) and Searle (<span class="ref-lnk lazy-ref"><a data-rid="cit0064" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1969</a></span>), who reconceptualized speech as “actions,” the term <i>dialogue act</i> was introduced by Bunt (<span class="ref-lnk lazy-ref"><a data-rid="cit0017" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1978</a></span>). Bunt (<span class="ref-lnk lazy-ref"><a data-rid="cit0021" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2000</a></span>), argued that a notion of <i>communicative functions</i> is required, which establish semantic definitions in terms of dialogue context changes, and further that, communication has many “dimensions” that a speaker can address simultaneously. For instance, “Yes, but what is it?”, indicates both an understanding of what was previously said, and a request for more information. From this example we can define DA in terms of two components: i) its <i>communicative function</i>, what the speaker is trying to achieve, and ii) the <i>semantic content</i>, which describes the information that is being addressed – the entities, their properties, and relations that are referred to. Thus, while DA labels are intended for single utterances of dialogue, they can be both multidimensional (have more than one function), and be prospective, or reactive, to surrounding utterances; a property that is particularly advantageous when viewed in conjunction with the broader structural descriptions provided by AP.</p>
  <p>As previously discussed, DA are commonly used for NLP purposes. However, historically there has been quite a range of different labeling schemes developed. Most notably, the Discourse Annotation and Mark-up System of labeling (DAMSL) (Allen &amp; Core, <span class="ref-lnk lazy-ref"><a data-rid="cit0002" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1997</a></span>), which was used to annotate the Switchboard Dialogue Act dataset (Jurafsky et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0047" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1997</a></span>), and a slight variation was used to label the Meeting Recorder Dialogue Act (MRDA) corpus (Shriberg et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0065" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>). Also, corpora created for the development of dialogue systems, such as the Dialogue State Tracking Challenge (DSTC) (Williams et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0070" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2016</a></span>), and FRAMES (Asri et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0007" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2017</a></span>), typically define their own bespoke set of DA labels. While there is some commonality between them, the net result is a collection of different DA labeling schemes that are, to some degree, incompatible. In a move to address this problem the Dialogue Act Mark-up Language (DiAML) was developed and forms part of ISO 24617 (British Standards Institution, <span class="ref-lnk lazy-ref"><a data-rid="cit0016" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2012</a></span>). DiAML was developed as an empirically and theoretically well founded, application independent, DA annotation scheme and is also intended to be used by both human annotators and automatic annotation methods. There seems to be some growing recognition, within the DA research community, of the utility of a standardized method of DA annotation with several attempts to map existing DA labeled corpora to the DiAML scheme (Chowdhury et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0024" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2016</a></span>; Mezza et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0056" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2018</a></span>). As such, the 27&nbsp;DA labels defined within CAMS are entirely derived from a subset of DiAML labels. As shown in <button class="ref showTableEventRef" data-id="t0001">Table 1</button>, they remain grouped by their communicative function: Information-seeking, information-providing, commissives, directives, feedback, time management, owner and partner communication management, and social obligations management. Note that, within DiAML, the labels <i>autoPositive</i> and <i>autoNegative</i> represent positive or negative understanding of the previous utterance, for example, “Okay,” or “What?.” Within CAMS we have converted these into the slightly more intuitive labels of <i>feedbackPos</i> and <i>feedbackNeg</i>.</p>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <div class="short-legend">
     <h3><p class="captionText"><span class="captionLabel">Table 1. </span> The CAMS DA labels derived from DiAML and grouped by communicative function.</p></h3>
    </div>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="t0001-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0001&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0001" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p></p>
 </div>
 <div id="s0002-s2003" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i15">Adjacency pair types</h3>
  <p>In CAMS, an AP-type is simply the product of one AP label, and one DA label, for an utterance of dialogue. The combination of these two labels is considered an AP-type label. Due to the large number of possible combinations, and to allow flexibility, the schema does not explicitly define all valid DA and AP combinations. Instead, annotators should consider the meaning and context within which the individual labels being applied produce AP-types. The following shows a previous example, now fully labeled with both AP and DA, to create AP-types. In the example, <i>propQ</i> (propositionalQuestion) is a question that implies, but does not necessitate, a “yes” or “no” answer, and a <i>choiceQ</i> (choiceQuestion) where the speaker provides a list of alternatives with the assumption that the addressee knows which one is true, or will select one. The alternative question-type labels are: <i>setQuestion</i>, which corresponds to what is commonly termed a “WH-question” in the linguistic literature, that is, questions that typically begin with words such as, “Who,” “What” or “How”; and <i>checkQuestion</i>, which is produced by the speaker in order to know whether a proposition is true.</p>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <p class="fulltext" align="left">Table</p>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="ut0005-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=ut0005&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="ut0005" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p></p>
 </div>
</div>
<div id="s0003" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i16" class="section-heading-2">Inter-Annotator agreement</h2>
 <p>Inter-annotator agreement measures can be used as a means of assessing the <i>reproducibility</i> of a coding scheme or determining the <i>reliability</i> of a produced “gold standard” labeled dataset. Given that the focus of this study is the labeling schema itself, the purpose of measuring inter-annotator agreement refers to the former. That is, determining if the schema is inherently learnable, that the labels applied to utterances are not entirely dependent on the biases of an individual annotator, and that there is a common understanding of the meaning of labels and the utterances to which they are applicable (Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>). It should be noted, that reproducibility is a natural prerequisite to demonstrating reliability of a coding scheme. If annotators produce similar results, they likely have a similar understanding of the annotation scheme and guidelines, and that these are able to represent the desired characteristics of the data (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>). Within the literature chance-corrected coefficients, that is, accounting for the probability that annotators select the same label by chance, such as Cohen’s Kappa (Cohen, <span class="ref-lnk lazy-ref"><a data-rid="cit0026" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1960</a></span>), or Scott’s Pi (Scott, <span class="ref-lnk lazy-ref"><a data-rid="cit0063" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1955</a></span>), are the preferable measures of inter-annotator agreement (Carletta, <span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1996</a></span>; Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>; Di Eugenio, <span class="ref-lnk lazy-ref"><a data-rid="cit0032" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2000</a></span>). However, weighted coefficients, such as Krippendorff’s Alpha (Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), are more suitable to annotation tasks such as this, which require an element of semantic interpretation.</p>
 <div id="s0003-s2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i17">Weighted agreement coefficients</h3>
  <p>For some annotation tasks it does not make sense to treat all disagreements equally. For example, the DA <i>choiceQuestion</i> and <i>checkQuestion</i> are semantically more similar than <i>request</i> and <i>accept</i>. Both Pi and Kappa are limited in such circumstances because they only consider identical labels for agreement. This can result in very poor agreement values and as such they are not considered an acceptable measure of agreement for DA labeling tasks (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>; Geertzen &amp; Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0037" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>). A solution to this problem is the use of weighted agreement coefficients, which consider the magnitude of disagreement between assigned labels. Cohen (<span class="ref-lnk lazy-ref"><a data-rid="cit0027" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1968</a></span>), proposed a weighted variation of Kappa for two annotators. More frequently used however, and appropriate for this study, is Krippendorff’s Alpha (Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), and the Beta statistic, proposed by Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>). <a href="#f0001">Figure 1</a> summarizes some of the characteristics of each coefficient with respect to three different dimensions, bias and unbiased (Kappa and Pi), two or multiple coders (multi-Kappa and multi-Pi), and weighted (Alpha and Beta).</p>
  <p>Both Alpha and Beta are calculated from the observed and expected <i>disagreements</i>, rather than the agreement of the previously discussed coefficients. The ratio of observed (<i>o</i>) and expected (<i>e</i>) disagreement is then subtracted from 1 to produce the final agreement value: <disp-formula-group>
    <span class="NLM_disp-formula-image disp-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0001.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0001.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0001" class="disp-formula-label">(1) </span></span></span></span>
    <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       α
      </mi><mo>
       ,
      </mo><mi>
       β
      </mi><mo>
       =
      </mo><mn>
       1
      </mn><mo>
       −
      </mo><mrow>
       <mfrac>
        <mrow>
         <mrow>
          <msub>
           <mi>
            D
           </mi>
           <mi>
            o
           </mi>
          </msub>
         </mrow>
        </mrow>
        <mrow>
         <mrow>
          <msub>
           <mi>
            D
           </mi>
           <mi>
            e
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfrac>
      </mrow>
     </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0001" class="disp-formula-label">(1) </span></span></span></span>
   </disp-formula-group></p>
  <div class="figure figureViewer" id="f0001">
   <div class="hidden figureViewerArticleInfo">
    <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>17 January 2022
     </div>
    </div>
   </div>
   <div class="figureThumbnailContainer">
    <div class="figureInfo">
     <div class="short-legend">
      <p class="captionText"><span class="captionLabel">Figure 1. </span> Agreement coefficients in three dimensions, bias, number of coders, and weighted. Adapted from the “Coefficient Cube” (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>).</p>
     </div>
    </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0001image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0001_b.gif" loading="lazy" height="275" width="500"></a>
    <div class="figureDownloadOptions">
     <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
    </div>
   </div>
  </div>
  <div class="hidden rs_skip" id="fig-description-f0001">
   <p class="captionText"><span class="captionLabel">Figure 1. </span> Agreement coefficients in three dimensions, bias, number of coders, and weighted. Adapted from the “Coefficient Cube” (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>).</p>
  </div>
  <div class="hidden rs_skip" id="figureFootNote-f0001">
   <div class="figureFootNote-f0001"></div>
  </div>
  <p></p>
  <p>Further, weighted coefficients use a distance function (see section Weighted Coefficient Distance Functions), which returns a value in the range [0, 1] representing the similarity between an arbitrary pair of labels. 0 indicates the two labels are identical and 1 indicates they are completely dissimilar. This value is then used to weight pairs of assigned labels, penalizing those that are more dissimilar. The amount of disagreement for a given item is, therefore, the mean of the distances between all pairwise assignments for that item. The number of annotators who label item <i>i</i>, with label <i>l</i>, is <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0001.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0001.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mrow>
      <msub>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           n
          </mi>
         </mrow>
        </mrow>
       </mrow>
       <mrow>
        <mi>
         i
        </mi>
        <mi>
         l
        </mi>
       </mrow>
      </msub>
     </mrow>
    </math></span>. For every label pair <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0002.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0002.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mrow>
      <msub>
       <mi>
        l
       </mi>
       <mi>
        j
       </mi>
      </msub>
     </mrow>
    </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0003.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0003.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mrow>
      <msub>
       <mi>
        l
       </mi>
       <mi>
        k
       </mi>
      </msub>
     </mrow>
    </math></span>, there are <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0004.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0004.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mrow>
      <msub>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           n
          </mi>
         </mrow>
        </mrow>
       </mrow>
       <mrow>
        <mi>
         i
        </mi>
        <mrow>
         <msub>
          <mi>
           l
          </mi>
          <mi>
           j
          </mi>
         </msub>
        </mrow>
       </mrow>
      </msub>
     </mrow><mrow>
      <mtext>
       &nbsp;
      </mtext>
     </mrow><mrow>
      <msub>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           n
          </mi>
         </mrow>
        </mrow>
       </mrow>
       <mrow>
        <mi>
         i
        </mi>
        <mrow>
         <msub>
          <mi>
           l
          </mi>
          <mi>
           k
          </mi>
         </msub>
        </mrow>
       </mrow>
      </msub>
     </mrow>
    </math></span> pairs of assigned labels for an item, and each has a distance (<b>d</b>) of <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0005.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0005.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mrow>
      <msub>
       <mi>
        d
       </mi>
       <mrow>
        <mrow>
         <msub>
          <mi>
           l
          </mi>
          <mi>
           j
          </mi>
         </msub>
        </mrow>
        <mrow>
         <msub>
          <mi>
           l
          </mi>
          <mi>
           k
          </mi>
         </msub>
        </mrow>
       </mrow>
      </msub>
     </mrow>
    </math></span>, calculated by the distance function. The mean disagreement for an item is then the sum of all weighted label pairs, divided by the total number of annotator pairs, <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0006.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0006.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mrow>
      <mrow>
       <mrow>
        <mi>
         a
        </mi>
       </mrow>
      </mrow>
     </mrow><mfenced open="(" close=")">
      <mrow>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           a
          </mi>
         </mrow>
        </mrow>
       </mrow>
       <mo>
        −
       </mo>
       <mn>
        1
       </mn>
      </mrow>
     </mfenced>
    </math></span>: <disp-formula-group>
    <span class="NLM_disp-formula-image disp-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0002.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0002.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0002" class="disp-formula-label">(2) </span></span></span></span>
    <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       d
      </mi><mi>
       i
      </mi><mi>
       s
      </mi><mi>
       a
      </mi><mi>
       g
      </mi><mrow>
       <msub>
        <mi>
         r
        </mi>
        <mi>
         i
        </mi>
       </msub>
      </mrow><mo>
       =
      </mo><mrow>
       <mfrac>
        <mn>
         1
        </mn>
        <mrow>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             a
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mfenced open="(" close=")">
          <mrow>
           <mrow>
            <mrow>
             <mrow>
              <mi>
               a
              </mi>
             </mrow>
            </mrow>
           </mrow>
           <mo>
            −
           </mo>
           <mn>
            1
           </mn>
          </mrow>
         </mfenced>
        </mrow>
       </mfrac>
      </mrow><munderover>
       <mrow>
        <mo>
         ∑
        </mo>
       </mrow>
       <mrow>
        <mi>
         j
        </mi>
        <mo>
         =
        </mo>
        <mn>
         1
        </mn>
       </mrow>
       <mi>
        l
       </mi>
      </munderover><munderover>
       <mrow>
        <mo>
         ∑
        </mo>
       </mrow>
       <mrow>
        <mi>
         k
        </mi>
        <mo>
         =
        </mo>
        <mn>
         1
        </mn>
       </mrow>
       <mi>
        l
       </mi>
      </munderover><mrow>
       <msub>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            n
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mi>
          i
         </mi>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
        </mrow>
       </msub>
      </mrow><mrow>
       <msub>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            n
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mi>
          i
         </mi>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </msub>
      </mrow><mrow>
       <msub>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            d
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </msub>
      </mrow>
     </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0002" class="disp-formula-label">(2) </span></span></span></span>
   </disp-formula-group></p>
  <p>Observed disagreement is then the mean disagreement for all items: <disp-formula-group>
    <span class="NLM_disp-formula-image disp-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0003.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0003.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0003" class="disp-formula-label">(3) </span></span></span></span>
    <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         D
        </mi>
        <mi>
         o
        </mi>
       </msub>
      </mrow><mo>
       =
      </mo><mrow>
       <mfrac>
        <mn>
         1
        </mn>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            i
           </mi>
          </mrow>
         </mrow>
        </mrow>
       </mfrac>
      </mrow><munder>
       <mrow>
        <mo>
         ∑
        </mo>
       </mrow>
       <mrow>
        <mi>
         i
        </mi>
        <mo>
         ∈
        </mo>
        <mi>
         I
        </mi>
       </mrow>
      </munder><mi>
       d
      </mi><mi>
       i
      </mi><mi>
       s
      </mi><mi>
       a
      </mi><mi>
       g
      </mi><mrow>
       <msub>
        <mi>
         r
        </mi>
        <mi>
         i
        </mi>
       </msub>
      </mrow>
     </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0003" class="disp-formula-label">(3) </span></span></span></span>
   </disp-formula-group></p>
  <p>Where Alpha and Beta differ, is in their estimations of the distribution of assigned labels for an annotator operating only by chance, that is, how <span class="NLM_disp-formula-image inline-formula rs_preserve">
    <noscript>
     <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0007.gif" alt="">
    </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0007.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
    <math>
     <mi>
      P
     </mi><mo stretchy="false">
      (
     </mo><mi>
      l
     </mi><mrow>
      <mo>
       |
      </mo>
     </mrow><mrow>
      <msub>
       <mi>
        a
       </mi>
       <mi>
        k
       </mi>
      </msub>
     </mrow><mo stretchy="false">
      )
     </mo>
    </math></span> is estimated. When calculating <i>D<sub>e</sub></i>, Alpha estimates disagreement on the basis that each annotator assigns labels with the same distribution and therefore considered an <i>unbiased</i> coefficient, whereas Beta is <i>biased</i>, in that it calculates <i>D<sub>e</sub></i> from the observed distribution of individual annotators.</p>
  <div id="s0003-s2001-s3001" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i22">Alpha</h4>
   <p>Given the single probability distribution for all annotators, the probability of assigning a label to an item is the number of assignments of the label by all annotators, divided by the total number of assignments – items <b>i</b> multiplied by the number of annotators <b>a</b>. <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0004.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0004.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0004" class="disp-formula-label">(4) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mi>
        P
       </mi><mfenced open="(" close=")">
        <mi>
         l
        </mi>
       </mfenced><mo>
        =
       </mo><mrow>
        <mfrac>
         <mrow>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                n
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mi>
             l
            </mi>
           </msub>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <mrow>
            <mrow>
             <mi>
              a
             </mi>
             <mi>
              i
             </mi>
            </mrow>
           </mrow>
          </mrow>
         </mrow>
        </mfrac>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0004" class="disp-formula-label">(4) </span></span></span></span>
    </disp-formula-group></p>
   <p>Again, the probability that two annotators assign labels <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0008.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0008.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0009.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0009.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow>
     </math></span>, is the joint probability of each annotator assigning the label independently. The expected disagreement is, therefore, the sum of the weighted joint probabilities for all label pairs, divided by the total number of assignments: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0005.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0005.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0005" class="disp-formula-label">(5) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <msubsup>
        <mi>
         D
        </mi>
        <mi>
         e
        </mi>
        <mi>
         α
        </mi>
       </msubsup><mo>
        =
       </mo><mrow>
        <mfrac>
         <mn>
          1
         </mn>
         <mrow>
          <mrow>
           <mrow>
            <mrow>
             <mi>
              a
             </mi>
             <mi>
              i
             </mi>
            </mrow>
           </mrow>
          </mrow>
          <mfenced open="(" close=")">
           <mrow>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                a
               </mi>
               <mi>
                i
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
       </mrow><munderover>
        <mrow>
         <mo>
          ∑
         </mo>
        </mrow>
        <mrow>
         <mi>
          j
         </mi>
         <mo>
          =
         </mo>
         <mn>
          1
         </mn>
        </mrow>
        <mi>
         l
        </mi>
       </munderover><munderover>
        <mrow>
         <mo>
          ∑
         </mo>
        </mrow>
        <mrow>
         <mi>
          k
         </mi>
         <mo>
          =
         </mo>
         <mn>
          1
         </mn>
        </mrow>
        <mi>
         l
        </mi>
       </munderover><mrow>
        <msub>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             n
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             j
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow><mrow>
        <msub>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             n
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow><mrow>
        <msub>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             d
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             j
            </mi>
           </msub>
          </mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0005" class="disp-formula-label">(5) </span></span></span></span>
    </disp-formula-group></p>
  </div>
  <div id="s0003-s2001-s3002" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i25">Beta</h4>
   <p>The Beta coefficient is, in essence, multi-annotator generalization of Cohens weighted Kappa (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>); in that, it is a weighted coefficient which considers individual annotators label distributions (bias) and is applicable to more than two annotators. The probability that annotator <i>a</i>, assigns label <i>l</i>, to an item, is the total number of such assignments <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0010.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0010.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            n
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mi>
          a
         </mi>
         <mi>
          l
         </mi>
        </mrow>
       </msub>
      </mrow>
     </math></span>, divided by the total number of assignments for that annotator (the same as Kappa and Multi-kappa): <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0006.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0006.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0006" class="disp-formula-label">(6) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mi>
        P
       </mi><mfenced open="(" close=")">
        <mrow>
         <mi>
          l
         </mi>
         <mrow>
          <mrow>
           <mrow>
            <mo>
             |
            </mo>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mo>
        =
       </mo><mrow>
        <mfrac>
         <mrow>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                n
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mrow>
              <msub>
               <mi>
                a
               </mi>
               <mi>
                j
               </mi>
              </msub>
             </mrow>
             <mi>
              l
             </mi>
            </mrow>
           </msub>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             i
            </mi>
           </mrow>
          </mrow>
         </mrow>
        </mfrac>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0006" class="disp-formula-label">(6) </span></span></span></span>
    </disp-formula-group></p>
   <p>The probability that two annotators <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0111.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0111.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         m
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0011.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0011.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         n
        </mi>
       </msub>
      </mrow>
     </math></span>, selecting different labels <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0113.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0113.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0114.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0114.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow>
     </math></span>, is <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0012.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0012.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       P
      </mi><mo stretchy="false">
       (
      </mo><mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow><mrow>
       <mo>
        |
       </mo>
      </mrow><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         m
        </mi>
       </msub>
      </mrow><mo stretchy="false">
       )
      </mo><mi>
       P
      </mi><mo stretchy="false">
       (
      </mo><mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow><mrow>
       <mo>
        |
       </mo>
      </mrow><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         n
        </mi>
       </msub>
      </mrow><mo stretchy="false">
       )
      </mo><mo>
       +
      </mo><mi>
       P
      </mi><mo stretchy="false">
       (
      </mo><mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow><mrow>
       <mo>
        |
       </mo>
      </mrow><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         m
        </mi>
       </msub>
      </mrow><mo stretchy="false">
       )
      </mo><mi>
       P
      </mi><mo stretchy="false">
       (
      </mo><mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow><mrow>
       <mo>
        |
       </mo>
      </mrow><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         n
        </mi>
       </msub>
      </mrow><mo stretchy="false">
       )
      </mo>
     </math></span>. The probability that a given pair of coders assigns labels <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0013.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0013.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         m
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0014.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0014.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         l
        </mi>
        <mi>
         n
        </mi>
       </msub>
      </mrow>
     </math></span>, is the mean of the probabilities for all annotator pairs: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0007.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0007.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0007" class="disp-formula-label">(7) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mi>
        P
       </mi><mfenced open="(" close=")">
        <mrow>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mo>
        =
       </mo><mrow>
        <mfrac>
         <mn>
          1
         </mn>
         <mrow>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mfenced open="(" close=")">
           <mrow>
            <mi>
             i
            </mi>
            <mi>
             a
            </mi>
            <mo>
             −
            </mo>
            <mn>
             1
            </mn>
           </mrow>
          </mfenced>
         </mrow>
        </mfrac>
       </mrow><mrow>
        <munderover>
         <mo movablelimits="false">
          ∑
         </mo>
         <mrow>
          <mi>
           m
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mrow>
          <mi>
           a
          </mi>
          <mo>
           −
          </mo>
          <mn>
           1
          </mn>
         </mrow>
        </munderover>
       </mrow><mrow>
        <mrow>
         <munderover>
          <mo movablelimits="false">
           ∑
          </mo>
          <mrow>
           <mi>
            n
           </mi>
           <mo>
            =
           </mo>
           <mn>
            1
           </mn>
          </mrow>
          <mi>
           a
          </mi>
         </munderover>
        </mrow>
        <mrow>
         <mrow>
          <msub>
           <mi>
            n
           </mi>
           <mrow>
            <mrow>
             <msub>
              <mi>
               a
              </mi>
              <mi>
               m
              </mi>
             </msub>
            </mrow>
            <mrow>
             <msub>
              <mi>
               l
              </mi>
              <mi>
               j
              </mi>
             </msub>
            </mrow>
           </mrow>
          </msub>
         </mrow>
        </mrow>
       </mrow><mrow>
        <msub>
         <mi>
          n
         </mi>
         <mrow>
          <mrow>
           <msub>
            <mi>
             a
            </mi>
            <mi>
             n
            </mi>
           </msub>
          </mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow><mo>
        +
       </mo><mrow>
        <msub>
         <mi>
          n
         </mi>
         <mrow>
          <mrow>
           <msub>
            <mi>
             a
            </mi>
            <mi>
             m
            </mi>
           </msub>
          </mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow><mrow>
        <msub>
         <mi>
          n
         </mi>
         <mrow>
          <mrow>
           <msub>
            <mi>
             a
            </mi>
            <mi>
             n
            </mi>
           </msub>
          </mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             j
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0007" class="disp-formula-label">(7) </span></span></span></span>
    </disp-formula-group></p>
   <p>The expected agreement for Beta is then, the mean of the probabilities for each pair of labels weighted by the distances: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0008.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0008.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0008" class="disp-formula-label">(8) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <msubsup>
        <mi>
         D
        </mi>
        <mi>
         e
        </mi>
        <mi>
         β
        </mi>
       </msubsup><mo>
        =
       </mo><munderover>
        <mrow>
         <mo>
          ∑
         </mo>
        </mrow>
        <mrow>
         <mi>
          j
         </mi>
         <mo>
          =
         </mo>
         <mn>
          1
         </mn>
        </mrow>
        <mrow>
         <mi>
          L
         </mi>
         <mo>
          −
         </mo>
         <mn>
          1
         </mn>
        </mrow>
       </munderover><munderover>
        <mrow>
         <mo>
          ∑
         </mo>
        </mrow>
        <mrow>
         <mi>
          k
         </mi>
         <mo>
          =
         </mo>
         <mi>
          j
         </mi>
         <mo>
          +
         </mo>
         <mn>
          1
         </mn>
        </mrow>
        <mi>
         L
        </mi>
       </munderover><mi>
        P
       </mi><mfenced open="(" close=")">
        <mrow>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mrow>
          <msub>
           <mi>
            l
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mrow>
        <msub>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             d
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             j
            </mi>
           </msub>
          </mrow>
          <mrow>
           <msub>
            <mi>
             l
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0008" class="disp-formula-label">(8) </span></span></span></span>
    </disp-formula-group></p>
   <p>It is worth noting, that if all disagreements are considered equal, with distance 1, then Alpha and Beta produce the same result as their non-weighted equivalents Multi-pi and Multi-kappa. Similarly, if data from only two annotators is used, and the distances are equal, the results are the same as the non-weighted two annotator variants Pi and Kappa.</p>
  </div>
 </div>
 <div id="s0003-s2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i29">Weighted coefficient distance functions</h3>
  <p>The calculation of Alpha and Beta requires a distance function <b>d</b>, that returns a distance value in the range [0, 1] for each possible label pair. The value indicates the amount of dissimilarity between the two labels, with 0 indicating they are identical and 1 indicating they are completely dissimilar. In this section 3 distance functions are defined, one for each of the label types defined within the schema. The constraints suggested by Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>), to which all distance metrics in (Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), and (Geertzen &amp; Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0037" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>) conform, are adopted here. That is; (1) the distance between a label and itself is 0, and (2), the distance between two labels is not dependent on their order. Because CAMS defines DA and AP, and they combine to form AP-types, it is necessary to define distance functions, such that, the distance of the combined DA and AP label still falls in the range [0, 1] and conforms to the above constraints.</p>
  <div id="s0003-s2002-s3001" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i30">Dialogue act distance function</h4>
   <p>Geertzen and Bunt (<span class="ref-lnk lazy-ref"><a data-rid="cit0037" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>), proposed a distance function based on a hierarchical ancestor-offspring relationship between DA labels within the Dynamic Interpretation Theory (DIT<sup>++</sup>) annotation scheme. Given that DIT<sup>++</sup> shares many characteristics of the DAMSL scheme (Allen &amp; Core, <span class="ref-lnk lazy-ref"><a data-rid="cit0002" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1997</a></span>), and that both of these are precursors to DiAML (British Standards Institution, <span class="ref-lnk lazy-ref"><a data-rid="cit0016" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2012</a></span>), a similar approach is employed here. However, their metric considered both the difference in depth and the minimal depth between two labels in the hierarchy, and these are each modified by two constants <i>a</i> and <i>b</i>. To avoid selecting two arbitrarily chosen constant values, which may affect the coefficient calculation, the DA distance function defined here only considers the distance between two labels within the relationship hierarchy.</p>
   <p>The DA relationships are characterized in an undirected graph, where leaf nodes are DA labels and intermediate nodes represent the communicative function subcategories. All edges are considered to have an equal distance of 1. DA are arranged according to their communicative functions which closely match those defined in DiAML. However, in a number of cases DA have been separated into subcategories that more closely resemble their semantic intent. For example, within DiAML the information-providing functions include the DA <i>agreement</i> and <i>disagreement</i>, which clearly have opposing sentiments, positive and negative. In such cases, DA that are assigned to more appropriate subcategories, for example, positive and negative responses. <a href="#f0002">Figure 2</a> depicts the Information Transfer sub-tree of the DA relationship graph.</p>
   <div class="figure figureViewer" id="f0002">
    <div class="hidden figureViewerArticleInfo">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="figureThumbnailContainer">
     <div class="figureInfo">
      <div class="short-legend">
       <p class="captionText"><span class="captionLabel">Figure 2. </span> The Information Transfer sub-tree of the DA relationship graph. Leaf nodes are DA, while intermediate nodes represent the communicative function subcategories.</p>
      </div>
     </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0002image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0002_oc.jpg" loading="lazy" height="349" width="500"></a>
     <div class="figureDownloadOptions">
      <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
     </div>
    </div>
   </div>
   <div class="hidden rs_skip" id="fig-description-f0002">
    <p class="captionText"><span class="captionLabel">Figure 2. </span> The Information Transfer sub-tree of the DA relationship graph. Leaf nodes are DA, while intermediate nodes represent the communicative function subcategories.</p>
   </div>
   <div class="hidden rs_skip" id="figureFootNote-f0002">
    <div class="figureFootNote-f0002"></div>
   </div><span class="ref-lnk fn-ref-lnk lazy-ref"><a data-rid="fn0002" href="#" data-reflink="fn"><span class="off-screen">Footnote</span><sup>2</sup></a></span>
   <p></p>
   <p>For each pair of DA, <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0015.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0015.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       d
      </mi><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow><mo>
       ,
      </mo><mi>
       d
      </mi><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow><mrow>
       <mrow>
        <mrow>
         <mi>
           
         </mi>
        </mrow>
       </mrow>
      </mrow><mo>
       ∈
      </mo><mrow>
       <mrow>
        <mi mathvariant="bold">
         D
        </mi>
        <mi mathvariant="bold">
         A
        </mi>
       </mrow>
      </mrow>
     </math></span>, the distance value is calculated as follows. First, the path distance (<b>p</b>), between <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0016.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0016.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       d
      </mi><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0017.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0017.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       d
      </mi><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow>
     </math></span>, is calculated as the sum of the number (<b>N</b>) of edges <i>e</i>, each with distance 1, for the shortest path between <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0018.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0018.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       d
      </mi><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0019.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0019.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       d
      </mi><mrow>
       <msub>
        <mi>
         a
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow>
     </math></span>: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0009.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0009.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0009" class="disp-formula-label">(9) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mrow>
        <msub>
         <mi>
          p
         </mi>
         <mrow>
          <mi>
           d
          </mi>
          <mrow>
           <msub>
            <mi>
             a
            </mi>
            <mi>
             j
            </mi>
           </msub>
          </mrow>
          <mi>
           d
          </mi>
          <mrow>
           <msub>
            <mi>
             a
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow><mo>
        =
       </mo><mrow>
        <munderover>
         <mo movablelimits="false">
          ∑
         </mo>
         <mrow>
          <mi>
           i
          </mi>
          <mo>
           =
          </mo>
          <mn>
           1
          </mn>
         </mrow>
         <mi>
          N
         </mi>
        </munderover>
       </mrow><mrow>
        <mrow>
         <msub>
          <mi>
           e
          </mi>
          <mi>
           i
          </mi>
         </msub>
        </mrow>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0009" class="disp-formula-label">(9) </span></span></span></span>
    </disp-formula-group></p>
   <p>The path distance <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0020.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0020.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mi>
         p
        </mi>
        <mrow>
         <mi>
          d
         </mi>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mi>
          d
         </mi>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </msub>
      </mrow>
     </math></span>, is then normalized by the minimum and maximum path distances over the full DA relationship graph, for all possible label pairs (<b>P</b><i><sub>min</sub></i> and <b>P</b><i><sub>max</sub></i>), to yield the distance <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0021.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0021.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <mrow>
        <mrow>
         <mi>
          d
         </mi>
        </mrow>
       </mrow>
      </mrow><mfenced open="(" close=")">
       <mrow>
        <mi>
         d
        </mi>
        <mrow>
         <msub>
          <mi>
           a
          </mi>
          <mi>
           j
          </mi>
         </msub>
        </mrow>
        <mo>
         ,
        </mo>
        <mi>
         d
        </mi>
        <mrow>
         <msub>
          <mi>
           a
          </mi>
          <mi>
           k
          </mi>
         </msub>
        </mrow>
       </mrow>
      </mfenced>
     </math></span>, in the range [0, 1]: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0010.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0010.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0010" class="disp-formula-label">(10) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           d
          </mi>
         </mrow>
        </mrow>
       </mrow><mfenced open="(" close=")">
        <mrow>
         <mi>
          d
         </mi>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mi>
          d
         </mi>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mo>
        =
       </mo><mrow>
        <mfrac>
         <mrow>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                p
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              d
             </mi>
             <mrow>
              <msub>
               <mi>
                a
               </mi>
               <mi>
                j
               </mi>
              </msub>
             </mrow>
             <mi>
              d
             </mi>
             <mrow>
              <msub>
               <mi>
                a
               </mi>
               <mi>
                k
               </mi>
              </msub>
             </mrow>
            </mrow>
           </msub>
          </mrow>
          <mo>
           −
          </mo>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                P
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mi>
              i
             </mi>
             <mi>
              n
             </mi>
            </mrow>
           </msub>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                P
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mi>
              a
             </mi>
             <mi>
              x
             </mi>
            </mrow>
           </msub>
          </mrow>
          <mo>
           −
          </mo>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                P
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mi>
              i
             </mi>
             <mi>
              n
             </mi>
            </mrow>
           </msub>
          </mrow>
         </mrow>
        </mfrac>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0010" class="disp-formula-label">(10) </span></span></span></span>
    </disp-formula-group></p>
  </div>
  <div id="s0003-s2002-s3002" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i34">Adjacency pair distance function</h4>
   <p>AP, like DA, can be organized into categories that represent their function: <i>base, pre, post</i> and <i>insert</i>. However, the paired nature of FPP and SPP, means representing their relationship in a graph-like structure is less appropriate. For example, FPP-pre and FPP-post could be considered similar, in that they both initiate a sequence. Yet functionally, the <i>pre</i> and <i>post</i> expansion types have opposing meanings, pre-expansions should take place <i>before</i> a base pair and post-expansions <i>after</i>. Therefore, the distance function defined here considers the difference between the AP labels prefix and suffix, that is, whether they are part of an adjacency pair and initiating or responsive within a sequence (FPP or SPP), or a minimal expansion, and whether they belong to the same <i>base</i> sequence or <i>expansion type</i> (pre, post and insert).</p>
   <p>For each pair of AP, <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0022.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0022.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       a
      </mi><mrow>
       <msub>
        <mi>
         p
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow><mo>
       ,
      </mo><mi>
       a
      </mi><mrow>
       <msub>
        <mi>
         p
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow><mrow>
       <mrow>
        <mrow>
         <mi>
           
         </mi>
        </mrow>
       </mrow>
      </mrow><mo>
       ∈
      </mo><mrow>
       <mrow>
        <mi mathvariant="bold">
         A
        </mi>
        <mi mathvariant="bold">
         P
        </mi>
       </mrow>
      </mrow>
     </math></span>, the distance value is calculated as follows. First set the distance between <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0023.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0023.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       a
      </mi><mrow>
       <msub>
        <mi>
         p
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow>
     </math></span> and <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0024.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0024.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       a
      </mi><mrow>
       <msub>
        <mi>
         p
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow>
     </math></span> to 0, <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0025.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0025.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mo stretchy="false">
       (
      </mo><mrow>
       <msub>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            d
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mi>
          a
         </mi>
         <mrow>
          <msub>
           <mi>
            p
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mi>
          a
         </mi>
         <mrow>
          <msub>
           <mi>
            p
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </msub>
      </mrow><mo>
       =
      </mo><mn>
       0
      </mn><mo stretchy="false">
       )
      </mo>
     </math></span>. Then, separately compare the prefix and suffix of the two labels. If they do not match, increase the distance by .5: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0011.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0011.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0011" class="disp-formula-label">(11) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           d
          </mi>
         </mrow>
        </mrow>
       </mrow><mfenced open="(" close=")">
        <mrow>
         <mi>
          a
         </mi>
         <mrow>
          <msub>
           <mi>
            p
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mi>
          a
         </mi>
         <mrow>
          <msub>
           <mi>
            p
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mo>
        =
       </mo><msup>
        <mrow>
         <mo>
          ∑
         </mo>
        </mrow>
        <mn>
         0
        </mn>
       </msup><mn>
        .5
       </mn><mfenced open="(" close=")">
        <mrow>
         <mrow>
          <mn>
           1
          </mn>
          <mo>
           −
          </mo>
          <mi>
           δ
          </mi>
          <mo stretchy="false">
           (
          </mo>
          <mi>
           a
          </mi>
          <msubsup>
           <mi>
            p
           </mi>
           <mi>
            j
           </mi>
           <mrow>
            <mi>
             p
            </mi>
            <mi>
             r
            </mi>
            <mi>
             e
            </mi>
           </mrow>
          </msubsup>
          <mo>
           ,
          </mo>
          <mi>
           a
          </mi>
          <msubsup>
           <mi>
            p
           </mi>
           <mi>
            k
           </mi>
           <mrow>
            <mi>
             p
            </mi>
            <mi>
             r
            </mi>
            <mi>
             e
            </mi>
           </mrow>
          </msubsup>
         </mrow>
         <mo stretchy="false">
          )
         </mo>
        </mrow>
       </mfenced><mo>
        +
       </mo><mn>
        0.5
       </mn><mfenced open="(" close=")">
        <mrow>
         <mrow>
          <mn>
           1
          </mn>
          <mo>
           −
          </mo>
          <mi>
           δ
          </mi>
          <mo stretchy="false">
           (
          </mo>
          <mi>
           a
          </mi>
          <msubsup>
           <mi>
            p
           </mi>
           <mi>
            j
           </mi>
           <mrow>
            <mi>
             p
            </mi>
            <mi>
             o
            </mi>
            <mi>
             s
            </mi>
            <mi>
             t
            </mi>
           </mrow>
          </msubsup>
          <mo>
           ,
          </mo>
          <mi>
           a
          </mi>
          <msubsup>
           <mi>
            p
           </mi>
           <mi>
            k
           </mi>
           <mrow>
            <mi>
             p
            </mi>
            <mi>
             o
            </mi>
            <mi>
             s
            </mi>
            <mi>
             t
            </mi>
           </mrow>
          </msubsup>
         </mrow>
         <mo stretchy="false">
          )
         </mo>
        </mrow>
       </mfenced>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0011" class="disp-formula-label">(11) </span></span></span></span>
    </disp-formula-group></p>
   <p>Thus, two identical AP labels will have a distance of 0, and two completely different labels will have the maximum distance of 1, and two FPP labels will have a distance of .5, as in the previous example with FPP-pre and FPP-post. Similarly, a minimal expansion will have a distance of .5 to the FPP and SPP expansions within the same functional category.</p>
  </div>
  <div id="s0003-s2002-s3003" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i36">AP-type distance function</h4>
   <p>Within CAMS, an AP-type label is considered the combination of the DA and AP labels assigned to that utterance, and a similar approach is taken for the AP-type distance calculation. The distance between two AP-type labels is considered the sum of the distances for the individual components, <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0026.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0026.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <mrow>
        <mrow>
         <mi>
          d
         </mi>
        </mrow>
       </mrow>
      </mrow><mfenced open="(" close=")">
       <mrow>
        <mi>
         d
        </mi>
        <mrow>
         <msub>
          <mi>
           a
          </mi>
          <mi>
           j
          </mi>
         </msub>
        </mrow>
        <mo>
         ,
        </mo>
        <mi>
         d
        </mi>
        <mrow>
         <msub>
          <mi>
           a
          </mi>
          <mi>
           k
          </mi>
         </msub>
        </mrow>
       </mrow>
      </mfenced><mo>
       +
      </mo><mrow>
       <mrow>
        <mrow>
         <mi>
          d
         </mi>
        </mrow>
       </mrow>
      </mrow><mfenced open="(" close=")">
       <mrow>
        <mi>
         a
        </mi>
        <mrow>
         <msub>
          <mi>
           p
          </mi>
          <mi>
           j
          </mi>
         </msub>
        </mrow>
        <mo>
         ,
        </mo>
        <mi>
         a
        </mi>
        <mrow>
         <msub>
          <mi>
           p
          </mi>
          <mi>
           k
          </mi>
         </msub>
        </mrow>
       </mrow>
      </mfenced>
     </math></span>, normalized by the minimum and maximum distances for all possible label pairs (<b>D</b><i><sub>min</sub></i> and <b>D</b><i><sub>max</sub></i>). Thus, for each pair of AP-type labels, <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0027.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0027.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mi>
       a
      </mi><mi>
       p
      </mi><mrow>
       <msub>
        <mi>
         t
        </mi>
        <mi>
         j
        </mi>
       </msub>
      </mrow><mi>
       a
      </mi><mi>
       p
      </mi><mrow>
       <msub>
        <mi>
         t
        </mi>
        <mi>
         k
        </mi>
       </msub>
      </mrow><mo>
       ∈
      </mo><mfenced open="(" close=")">
       <mrow>
        <mi>
         D
        </mi>
        <mi>
         A
        </mi>
        <mrow>
         <mo>
          ∪
         </mo>
         <mrow>
          <mi>
           A
          </mi>
          <mi>
           P
          </mi>
         </mrow>
        </mrow>
       </mrow>
      </mfenced>
     </math></span>, the “raw” distances, <span class="NLM_disp-formula-image inline-formula rs_preserve">
     <noscript>
      <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0028.gif" alt="">
     </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0028.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
     <math>
      <mrow>
       <msub>
        <mrow>
         <mrow>
          <mrow>
           <mi>
            d
           </mi>
          </mrow>
         </mrow>
        </mrow>
        <mrow>
         <mi>
          a
         </mi>
         <mi>
          p
         </mi>
         <mrow>
          <msub>
           <mi>
            t
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mi>
          a
         </mi>
         <mi>
          p
         </mi>
         <mrow>
          <msub>
           <mi>
            t
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </msub>
      </mrow>
     </math></span>, are calculated as <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0012.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0012.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0012" class="disp-formula-label">(13) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mrow>
        <msub>
         <mrow>
          <mrow>
           <mrow>
            <mi>
             d
            </mi>
           </mrow>
          </mrow>
         </mrow>
         <mrow>
          <mi>
           a
          </mi>
          <mi>
           p
          </mi>
          <mrow>
           <msub>
            <mi>
             t
            </mi>
            <mi>
             j
            </mi>
           </msub>
          </mrow>
          <mi>
           a
          </mi>
          <mi>
           p
          </mi>
          <mrow>
           <msub>
            <mi>
             t
            </mi>
            <mi>
             k
            </mi>
           </msub>
          </mrow>
         </mrow>
        </msub>
       </mrow><mo>
        =
       </mo><mrow>
        <mrow>
         <mrow>
          <mi>
           d
          </mi>
         </mrow>
        </mrow>
       </mrow><mfenced open="(" close=")">
        <mrow>
         <mi>
          d
         </mi>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mi>
          d
         </mi>
         <mrow>
          <msub>
           <mi>
            a
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mo>
        +
       </mo><mrow>
        <mrow>
         <mrow>
          <mi>
           d
          </mi>
         </mrow>
        </mrow>
       </mrow><mfenced open="(" close=")">
        <mrow>
         <mi>
          a
         </mi>
         <mrow>
          <msub>
           <mi>
            p
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mi>
          a
         </mi>
         <mrow>
          <msub>
           <mi>
            p
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0012" class="disp-formula-label">(13) </span></span></span></span>
    </disp-formula-group></p>
   <p>The distance function is then: <disp-formula-group>
     <span class="NLM_disp-formula-image disp-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0013.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_m0013.gif&quot;}"><span class="mml-formula"><span class="disp_formula_label_div"><span id="m0013" class="disp-formula-label">(14) </span></span></span></span>
     <span class="NLM_disp-formula disp-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mrow>
        <mrow>
         <mrow>
          <mi>
           d
          </mi>
         </mrow>
        </mrow>
       </mrow><mfenced open="(" close=")">
        <mrow>
         <mi>
          a
         </mi>
         <mi>
          p
         </mi>
         <mrow>
          <msub>
           <mi>
            t
           </mi>
           <mi>
            j
           </mi>
          </msub>
         </mrow>
         <mo>
          ,
         </mo>
         <mi>
          a
         </mi>
         <mi>
          p
         </mi>
         <mrow>
          <msub>
           <mi>
            t
           </mi>
           <mi>
            k
           </mi>
          </msub>
         </mrow>
        </mrow>
       </mfenced><mo>
        =
       </mo><mrow>
        <mfrac>
         <mrow>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                d
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              a
             </mi>
             <mi>
              p
             </mi>
             <mrow>
              <msub>
               <mi>
                t
               </mi>
               <mi>
                j
               </mi>
              </msub>
             </mrow>
             <mi>
              a
             </mi>
             <mi>
              p
             </mi>
             <mrow>
              <msub>
               <mi>
                t
               </mi>
               <mi>
                k
               </mi>
              </msub>
             </mrow>
            </mrow>
           </msub>
          </mrow>
          <mo>
           −
          </mo>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                D
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mi>
              i
             </mi>
             <mi>
              n
             </mi>
            </mrow>
           </msub>
          </mrow>
         </mrow>
         <mrow>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                D
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mi>
              a
             </mi>
             <mi>
              x
             </mi>
            </mrow>
           </msub>
          </mrow>
          <mo>
           −
          </mo>
          <mrow>
           <msub>
            <mrow>
             <mrow>
              <mrow>
               <mi>
                D
               </mi>
              </mrow>
             </mrow>
            </mrow>
            <mrow>
             <mi>
              m
             </mi>
             <mi>
              i
             </mi>
             <mi>
              n
             </mi>
            </mrow>
           </msub>
          </mrow>
         </mrow>
        </mfrac>
       </mrow>
      </math><span class="mathjaxLabel"><span class="disp_formula_label_div"><span id="m0013" class="disp-formula-label">(14) </span></span></span></span>
    </disp-formula-group></p>
   <p>This simple formulation has the advantage of maintaining consistency with the DA and AP distance functions, allowing for comparison of coefficient values between the component label types. Additionally, the large number of possible combinations of DA and AP (297, though not all combinations are valid), would make defining a distinct AP-type distance function laborious and prone to errors and inconsistencies.</p>
  </div>
 </div>
 <div id="s0003-s2003" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i39">Coefficient selection</h3>
  <p>The following section discusses considerations around the selection of agreement coefficients for calculating inter-annotator agreement. Given that annotators assign DA and AP labels independently, and that each label type has a distinct distance function, it is also possible to calculate independent inter-annotator agreement values for each label type.</p>
  <p>The DA within the schema can be grouped into semantically similar communicative functions (Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0019" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2011</a></span>), such as, information seeking and information providing. Further, some utterances can be thought of as <i>multidimensional</i> (Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0018" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2006</a></span>), that is, they could be assigned two equally valid DA labels (or arguably both). Consider the following example:</p><preformat xml:space="preserve" position="float" orientation="portrait" id="_i40">
    A1: What is the weather going to be today and tomorrow?
  </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i41">
   B1: What city would you like to know the weather about?
  </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i42">
   A2: I want to know if it will drizzle in Durham. 
  </preformat>
  <p>Utterance A2 could be considered an answer to the previous question B1, the location they want to know the weather for, or a question in its own right, “<i>will it drizzle in Durham</i>.” Clearly, even with well-defined label definitions, there is a certain amount of subjectivity in assigning a single label to certain utterances. A similar semantic grouping is also true for AP, where, for example, FPP-insert and SPP-insert are more closely related to an insert-expansion than AP from the Pre and Post groups. It seems reasonable to treat assignments that belong to different expansion types more seriously than those from the same group. As with DA, there is also an element of subjective interpretation involved when assigning AP labels. For example, identifying which utterances represent the “core action” for a given sub-sequence of dialogue, and therefore should be assigned base-type labels, and those that should be considered expansions. The above, and the use of weighted agreement for DA annotation by (Geertzen &amp; Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0037" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>), indicates the use of weighted agreement measures, such as Alpha and Beta, are the appropriate choice for DA and AP annotation because the labels are not equally distinct from each other.</p>
  <p>What is less clear, however, is the choice between these two coefficients. There has been much debate on this matter (Artstein, <span class="ref-lnk lazy-ref"><a data-rid="cit0006" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2018</a></span>; Byrt et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0022" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1993</a></span>; Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>; Di Eugenio &amp; Glass, <span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>; Hsu &amp; Field, <span class="ref-lnk lazy-ref"><a data-rid="cit0045" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2003</a></span>; Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>; Zwick, <span class="ref-lnk lazy-ref"><a data-rid="cit0071" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1988</a></span>). Of course, Krippendorff built the notion of a single distribution into his Alpha coefficient, and Craggs and Wood (<span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>), argued strongly against the use of coefficients with bias, stating that, “<i>the purpose of assessing the reliability of coding schemes is not to judge the performance of the small number of individuals participating in the trial, but rather to predict the performance of the schemes in general</i>.” Yet, Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>), in their proposal of the Beta statistic believe that, “<i>assuming that coders act in accordance with the same probability distribution is too strong of an assumption, hence ‘biased’ measures are more appropriate</i>.”</p>
  <p>The argument against the use of biased coefficients, illustrated by Krippendorff (<span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), and others (Byrt et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0022" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1993</a></span>; Di Eugenio &amp; Glass, <span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>; Zwick, <span class="ref-lnk lazy-ref"><a data-rid="cit0071" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1988</a></span>), lies in its calculation of expected agreement. Though biased measures, such as Kappa and Beta, estimate expected agreement on the basis of individual annotator label distributions, they fail to account for unequal distributions <i>between</i> annotators. In so doing, biased coefficients effectively discount some of the disagreement resulting from different annotator distributions by incorporating it into expected agreement (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>). Thus, for a fixed observed agreement, when annotators produce unequal distributions for the available categories – when bias is present – the values of biased coefficients will <i>exceed</i> those of non-biased coefficients. The objection, then, is the “paradox” that as annotators become less similar, biased measures can <i>increase</i> (Di Eugenio &amp; Glass, <span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), and begin to diverge from their non-biased counterparts. However, Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>) point out that in practice the difference between biased and non-biased measures often doesn’t amount to much, and that bias is a source of disagreement in its own right. To this latter point, Banerjee et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0010" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1999</a></span>), in reference to Zwick (<span class="ref-lnk lazy-ref"><a data-rid="cit0071" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1988</a></span>), suggested that, “<i>rather than straightway ignoring marginal disagreement or attempting to correct for it, researchers should be studying it to determine whether it reflects important rater differences or merely random error</i>.” For example, Hsu and Field (<span class="ref-lnk lazy-ref"><a data-rid="cit0045" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2003</a></span>) demonstrated how Kappa can give useful information even when the individual annotators distributions are very different, and Wiebe et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0069" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1999</a></span>), exploited bias to improve the annotation process. In any case, what does seem to be agreed upon, is that as the number of annotators is increased the difference between biased and non-biased measures becomes less significant (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0003" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005a</a></span>, <span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>; Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>). Further, as stated by Di Eugenio and Glass (<span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), the biased and non-biased paradigms reflect distinct conceptualizations of the problem, and in agreement with Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>), the choice should depend on the desired interpretation of chance agreement. However, Di Eugenio and Glass (<span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), also believed the bias coefficient (Kappa) is more appropriate for discourse and DA tagging, because “<i>it is questionable whether the assumption of equal distributions underlying</i> Pi <i>is appropriate for coding in discourse and dialogue work</i>.” Yet, they also suggested reporting Kappa and Pi together, to account for the “bias problem” we have just described. Here a similar approach is taken, and both Alpha and Beta will be reported.</p>
 </div>
 <div id="s0003-s2004" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i43">Coefficient evaluation</h3>
  <p>To reiterate, the purpose of measuring agreement for this study is to assess the <i>reproducibility</i> of the schema for annotating dialogs with DA, AP and ultimately AP-types. If multiple annotators can be shown to <i>reliably</i> assign similar labels to a set of data, it can be inferred that they have a similar understanding of the meaning of the labels, the data items to which they are applicable and that the observed agreement (or disagreement) is not purely a product of chance or an individual’s interpretation of the scheme. Unfortunately, the question of what constitutes reliable agreement when interpreting agreement coefficients seems to be an unanswered question (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>; Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>; Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>).</p>
  <p>The principal approach is based on a range of values proposed by Landis and Koch (<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1977</a></span>). Values below zero are considered “Poor” agreement, and values between 0 and 1 are separated into five ranges: <i>Slight</i> (.0 – .2), <i>Fair</i> (.21 – .4), <i>Moderate</i> (.41 – .6), <i>Substantial</i> (.61 – .8), and <i>Perfect</i> (<i>&gt;</i>.81). Though they themselves concede that the divisions are arbitrary and only provide a useful benchmark. In Computational Linguistics, it is generally accepted that values of <i>&gt;</i> 0.8 can be considered “good reliability,” and values in the range [.67, .8] allow for “tentative conclusions to be drawn” (Carletta, <span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1996</a></span>; Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>). Though it is acknowledged that, as with the original Landis and Koch (<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1977</a></span>) values, because of diversity in both the phenomena being annotated and the applications of results, these ranges are not suitable in all cases (Carletta, <span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1996</a></span>; Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>; Di Eugenio &amp; Glass, <span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>; Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>). This is especially true for annotation tasks such as this, where there is a degree of subjectivity in choosing an appropriate label, where some prior subject-specific knowledge is required, and notably for AP, prefect agreement will generally require annotators to agree on two (or more) labels, rather than one for DA. Indeed, it has been shown that achieving even the minimum 0.67 value is extremely difficult for discourse annotation (Hearst, <span class="ref-lnk lazy-ref"><a data-rid="cit0044" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1997</a></span>; Poesio &amp; Vieira, <span class="ref-lnk lazy-ref"><a data-rid="cit0060" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1998</a></span>). This problem is further compounded when using weighted agreement coefficients, because the choice of distance function greatly impacts the calculated coefficient value, as shown by Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>). Furthermore, regarding the bias problem discussed in the previous section, differences in annotator distributions (bias) will <i>increase</i> biased coefficient values, causing them to diverge from non-biased measures. Thus, in the presence of bias, a biased coefficient will always be larger than a non-biased one, and for this reason Geiß (<span class="ref-lnk lazy-ref"><a data-rid="cit0039" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2021</a></span>) suggests that applying the same range of values is not appropriate, because they warrant different interpretations. Unfortunately, to the best of our knowledge no alternative scale for interpreting biased coefficients has been proposed within the literature, though some have made attempts to “correct” for bias when there are only two categories (Byrt et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0022" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1993</a></span>). We therefore choose to evaluate both coefficients, Alpha and Beta, with respect to the ranges typically adopted throughout the literature; with the caveat that, for Beta it is necessary to be cautious when drawing conclusions if there is a significant difference between the two coefficients. Ultimately, choosing an agreement threshold should not be the sole measure upon which an annotation schema, or labeled corpus, should be considered reliable (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>; Craggs &amp; Wood, <span class="ref-lnk lazy-ref"><a data-rid="cit0029" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005</a></span>). Instead, the methodology for collecting and calculating reliability should be thoroughly communicated, so that conclusions can be drawn based on the characteristics and motivations of the particular study (Artstein &amp; Poesio, <span class="ref-lnk lazy-ref"><a data-rid="cit0005" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>). The following annotation methodology considerations were suggested by Krippendorff (<span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>, ch. 11), and reiterated by (Artstein, <span class="ref-lnk lazy-ref"><a data-rid="cit0006" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2018</a></span>):</p>
  <ol class="NLM_list NLM_list-list_type-order">
   <li><p class="inline">Annotators must work independently, so agreements come from a shared understanding not through discussion.</p></li>
   <li><p class="inline">Annotators should come from a well-defined population, so that researchers are aware of previous knowledge or assumptions they bring to the annotation process.</p></li>
   <li><p class="inline">Annotation instructions should be exhaustively formulated, clear and contain step-by-step instructions on how to use it.</p></li>
  </ol>
  <p></p>
  <p>These methodological considerations, and other types of data collected – annotation time and confidence – are discussed in the following section.</p>
 </div>
</div>
<div id="s0004" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i44" class="section-heading-2">Data and methods</h2>
 <p>The following outlines details of the annotation procedure that was conducted to assess CAMS with respect to; (1) the extent to which multiple annotators agree when applying the schema to dialogue, the inter-annotator agreement, (2), its suitability for application to both task-oriented and non-task-oriented (general talk) dialogs, and (3), evaluate additional characteristics of the material, or annotator behaviors, which may affect application of the schema and the resulting agreement scores. These objectives are intended to establish whether CAMS is comprehensively and explicitly defined, such that it can be reliably applied by multiple annotators, and that it is generalizable to any conversation type, topic, or domain, in order to create corpora annotated with labels that express the syntactic and semantic structure.</p>
 <p>The study participants were asked to label five dialogs, containing both task and non-task-oriented conversations, using a specially developed software annotation tool<span class="ref-lnk fn-ref-lnk lazy-ref"><a data-rid="fn0003" href="#" data-reflink="fn"><span class="off-screen">Footnote</span><sup>3</sup></a></span> (<a href="#f0003">Figure 3</a>). In total, 15 participants took part in the study (see Participant Selection), and each was assigned one of the five different sets of dialogue for annotation (see Dialogue Selection). The dialogue sets were evenly distributed among the participants, resulting in three annotators per set. The first dialogue in each set is a practice dialogue, followed by the four dialogs in their respective set (two task-oriented and two non-task-oriented). The latter four dialogs were shown to participants in a random order to encourage independent annotation, and mitigate any learning effect of the software, or schema, on annotation results. The participants were given one hour to annotate all dialogs and had no previous training using the annotation tool or CAMS. Upon completion of each dialogue, participants were asked to rate, by means of a Likert Scale, how well their annotations fit the data. Timing data was also collected during the annotation process, which recorded how long participants spent annotating each utterance of dialogue. The timing and rating data were used, in addition to the calculated inter-annotator agreement, for further analysis of the manner in which annotators apply the schema, and comparison of task and non-task-oriented dialogs. The following discusses the evaluation measures, and the selection of participants and dialogs in more detail.</p>
 <div class="figure figureViewer" id="f0003">
  <div class="hidden figureViewerArticleInfo">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="figureThumbnailContainer">
   <div class="figureInfo">
    <div class="short-legend">
     <p class="captionText"><span class="captionLabel">Figure 3. </span> Annotation screen of the software annotation tool.</p>
    </div>
   </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0003image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0003_oc.jpg" loading="lazy" height="363" width="500"></a>
   <div class="figureDownloadOptions">
    <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
   </div>
  </div>
 </div>
 <div class="hidden rs_skip" id="fig-description-f0003">
  <p class="captionText"><span class="captionLabel">Figure 3. </span> Annotation screen of the software annotation tool.</p>
 </div>
 <div class="hidden rs_skip" id="figureFootNote-f0003">
  <div class="figureFootNote-f0003"></div>
 </div>
 <p></p>
 <div id="s0004-s2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i46">Dialogue selection</h3>
  <p>A key objective of this study is to assess CAMS when it is applied in both task-oriented and non-task-oriented settings. Here, a task-oriented dialogue is defined as, an interaction in which at least one participant has some predetermined goal, such as asking for directions, and engages in the conversation in order to meet that goal. Once that goal is met, or if it is unsuccessful, the interaction is concluded. In contrast, a non-task-oriented dialogue, or general talk, is one in which no participant has a specific predetermined purpose for the interaction other than social communication. Topics may change frequently, and while information may be exchanged it is not in the pursuit of some external predetermined purpose. The dialogs selected for this study are therefore representative of these two groups. Additionally, in order to provide a more representative selection between the groups, dialogs were chosen from four different corpora, with varying numbers of utterances, participants and formats.</p>
  <p>In total 20 dialogs were chosen, 5 from each corpus. These were then split into five dialogue sets, each containing one dialogue from each corpus, and grouped in order to keep the total number of utterances in each set roughly equivalent. Additionally, each set contained the same short practice dialogue, selected from the KVRET corpus. The practice dialogue is intended to mitigate any learning effect associated with the annotation software, and also provide a control dialogue annotated by each participant regardless of the dialogue set they are assigned. <button class="ref showTableEventRef" data-id="t0002">Table 2</button> provides an overview of each dialogue set used within the study. Next is a brief overview of each corpus.</p>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <div class="short-legend">
     <h3><p class="captionText"><span class="captionLabel">Table 2. </span> Summary of dialogs, and number of utterances, per dialogue set. Total column includes 6 utterances for the practice dialogue.</p></h3>
    </div>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="t0002-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0002&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0002" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p></p>
  <div id="s0004-s2001-s3001" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i47">KVRET</h4>
   <p>Key-Value Retrieval Networks for Task-Oriented Dialogue, is a multi-turn, multi-domain, task-oriented corpus (Eric &amp; Manning, <span class="ref-lnk lazy-ref"><a data-rid="cit0034" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2017</a></span>). The data was collected using a Wizard-of-Oz scheme, via 241 workers on Amazon Mechanical Turk. It contains 3,031 dialogs in 3 domains for an in-car personal assistant: calendar scheduling, weather information and point-of-interest navigation. The dialogs used for this study were randomly selected from the 304 dialogs in the KVRET test set.</p>
  </div>
  <div id="s0004-s2001-s3002" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i48">bAbI</h4>
   <p>The Dialogue bAbI Tasks data is a subset of the bAbI project by the Facebook AI Research group (Weston et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0068" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2015</a></span>). The set of six tasks are designed to test end-to-end dialogue systems in the restaurant booking domain (Bordes et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0012" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2017</a></span>). The dialogs used for this study were randomly selected from the 100 dialogs in the bAbI task 1 test set. Each dialogue follows a similar format. First greetings are exchanged, and the automated system asks the user what it can help them with. The user states their preference of cuisine, location, price range, and number of diners, and in some cases extra system turns clarify these preferences.</p>
  </div>
  <div id="s0004-s2001-s3003" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i49">CABNC</h4>
   <p>The Jeffersonian Transcription of the Spoken British National Corpus is a conversation analytic re-transcription of naturalistic conversations from a sub corpus of the British National Corpus (Albert et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0001" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2015</a></span>). It contains 1436 conversations with a total of 4.2 million words. There is a wide range in the number of utterances within the CABNC dialogs, in many cases hundreds or thousands of utterances. In order to, as much as possible, maintain a similar number of utterances across all dialogs and dialogue sets, and due to time constraints, those used for this study were randomly selected from dialogs with less than 10 utterances.</p>
  </div>
  <div id="s0004-s2001-s3004" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i50">SCoSE</h4>
   <p>The Saarbrucken Corpus of Spoken English consists of 14 transcribed dialogs of general talk on a range of topics between two or more participants (Norrick, <span class="ref-lnk lazy-ref"><a data-rid="cit0057" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>). As with the CABNC corpus, due to the large number of utterances, and time constraints, those chosen for this study were the 5 dialogs with the fewest utterances. In our set, the <i>mammoth, clone</i>, and <i>accident</i> dialogs take place between up to three undergraduate students sharing an apartment, while <i>hunter</i>, and <i>tipsy</i> take place between Helen and her three adult daughters before a late-afternoon Thanksgiving dinner.</p>
  </div>
 </div>
 <div id="s0004-s2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i51">Participant selection</h3>
  <p>The study participants comprised of 15 undergraduate students from the 1st year of an English Language and Linguistics course. For 5&nbsp;weeks prior to the study the participants received instruction on CA and AP as part of their linguistics syllabus. However, we also wanted to assess how intuitive the schema is to apply with only minimal prior knowledge. Given its purpose is for computational dialogue modeling, CAMS should ideally be usable by as wide a range of people as possible. Not only Conversation Analysts, but Computer Scientists, Computational Linguists, and other NLP practitioners, who either already have some familiarity with CA and AP, or who simply intend to follow the annotation guidelines and label definitions. This is particularly important when considering the application of the schema for further annotation tasks, for example, creating large datasets for training and evaluating deep-learning NLP models. Therefore, our participants were not provided any specific instruction regarding CAMS and did not receive any training in its application. As such, participants could reasonably be considered novice annotators, in that, they had some prior knowledge of CA theory but no previous experience in annotation or applying CAMS. The selection of Linguistics students as annotators was largely for pragmatic reasons:</p>
  <ol class="NLM_list NLM_list-list_type-order">
   <li><p class="inline">While DA labels could be considered somewhat intuitive, even for novice annotators, AP require some level of previous CA knowledge. Therefore, conducting a large-scale crowed-sourced annotation experiment, where we cannot guarantee any prior understanding of CA concepts, would be inappropriate.</p></li>
   <li><p class="inline">Even though expert annotators are more likely to produce high agreement (Geertzen et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0038" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>; Nowak &amp; Rüger, <span class="ref-lnk lazy-ref"><a data-rid="cit0058" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2010</a></span>; Snow et al., <span class="ref-lnk lazy-ref"><a data-rid="cit0067" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2008</a></span>), the number of available expert annotators is limited. Further, both Krippendorff (<span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), and Carletta (<span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1996</a></span>), argue that, for discourse and dialogue annotation schemes there are no real experts, and that what counts is how totally naïve annotators manage based on written instructions. While using naïve annotators is not appropriate here, the use of non-expert annotators should still provide some insight into the clarity of the CAMS label definitions and annotation guidelines.</p></li>
   <li><p class="inline">Bayerl and Paul (<span class="ref-lnk lazy-ref"><a data-rid="cit0011" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2011</a></span>), suggest using annotators with the same level of domain expertise. Using participants from the same student cohort, with a similar level of experience, should therefore reduce external factors which may influence the interpretation of the schema definitions and guidelines.</p></li>
  </ol>
  <p></p>
 </div>
 <div id="s0004-s2003" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i52">Timing and rating measures</h3>
  <p>The annotation tool collected additional utterance annotation timing and label confidence data for each annotator. The purpose is to augment the comparison between task-oriented and non-task-oriented dialogs, and the different label types within the schema, that would not be possible with agreement coefficient data alone. It also provides additional insight into the participants annotation behavior, such as a change in confidence, or the amount of time spent selecting labels, which may indicate how well annotators are able to learn and internalize the annotation scheme.</p>
  <div id="s0004-s2003-s3001" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i53">Annotation timing</h4>
   <p>The annotation software allows users to select an utterance of dialogue, which is then highlighted to signal it is the “target” for annotation. With an utterance selected, the user chooses a single DA and AP label to assign by clicking on their respective buttons. An utterance is considered <i>labeled</i> when it has been assigned one of each label type. At which point the software automatically selects the next unlabeled, or partially labeled, utterance. The time taken to annotate an utterance is measured as the total time the utterance is selected and unlabeled. This time is cumulative, so if a previously assigned label is removed, so that a different label can be selected, or it is unselected and re-selected later, any further annotation time is added to the previous total.</p>
  </div>
  <div id="s0004-s2003-s3002" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i54">Annotation confidence</h4>
   <p>Once a dialogue is fully labeled users are presented with a questionnaire screen. Here, they are asked to rate how well their assigned labels fit the dialogue in question. Ratings are provided by means of a Likert Scale between 1 and 7, with 1 representing <i>not at all</i>, and 7 <i>perfectly</i>. There are three questions, one for each label type; and the prompts emphasize the purpose of these label types. For example, how well the DA describe the communicative <i>meaning</i> of the utterances, AP the <i>structure</i>, and for AP-types, how well they combine to convey both structure and meaning. In addition to the confidence ratings, users are given the option to highlight any of the labels they assigned to the current dialogue. This is because users must fully label each utterance, there is no option to leave an utterance unlabeled, or partially labeled, and therefore provides an opportunity to indicate whether they feel certain labels did not adequately described the utterance, or selection of utterances.</p>
  </div>
 </div>
 <div id="s0004-s2004" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i55">Statistical analysis</h3>
  <p>Throughout our analysis we perform hypothesis testing in the form of Two-sided t-tests or Analysis of Variance (ANOVA), where appropriate. Where the results of an ANOVA reveal a significant overall effect, we perform a further Tukey’s Honest Significant Difference (Tukey-HSD) post-hoc analysis, in order to determine the factors contributing to the observed effect. Due to relatively small sample sizes, we calculate the <i>ω</i><sup>2</sup> effect size and adopt the standard ranges for interpretation, low (.01 – .059), medium (.06 – .139) and large (.14+). For t-tests we report Cohen’s d effect size, with standard interpretations of small (.2), medium (.5), and large (.8+). Throughout the analysis, we use a significance level <i>α&nbsp;</i>= .05, and, unless otherwise stated, the statistical power is <i>≥</i> .8.</p>
 </div>
</div>
<div id="s0005" class="NLM_sec NLM_sec_level_1">
 <h2 id="_i56" class="section-heading-2">Results and discussion</h2>
 <p>In this section the results of the annotation procedure are presented and some of the observations that arise are discussed. We begin with the inter-annotator agreement measures, firstly for each set of dialogue, before examining agreement for task and non-task-oriented dialogs, and each corpus. We then report the results for annotator confidence and timing data, respectively.</p>
 <div id="s0005-s2001" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i57">Inter-annotator agreement</h3>
  <p>Inter-annotator agreement was calculated for the Alpha and Beta coefficients from the recorded annotations for each dialogue set. <a href="#f0004">Figure 4</a> shows agreement values for each label type (DA, AP, and AP-type), and the overall mean agreement for each coefficient.</p>
  <p><a href="#f0004">Figure 4</a> and subsequent statistical analysis show that:</p>
  <ul class="NLM_list NLM_list-list_type-bullet">
   <li><p class="inline">According to the Landis and Koch (<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1977</a></span>), scale we find that agreement for the Beta metric is “substantial” for DA (.74) and AP-types (.67), and “moderate” (.6) for AP alone. Using the range [.67, .8] (Carletta, <span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1996</a></span>; Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), we find that only DA and AP-type labels are able to reach this threshold for the Beta coefficient.</p></li>
   <li><p class="inline">The Alpha metric produces the same pattern, but with lower values of agreement. DA agreement is ‘moderate’ (.47), while AP are ‘slight’ (.18), and AP-types ‘fair’ (.33). Comparing Alpha and Beta values, for each label type, show these are all significantly different (<i>p &lt;</i> .001,<i>d &gt;</i> 1). Possible reasons for this are explored further in section Alpha vs Beta.</p></li>
   <li><p class="inline">ANOVA over the label types (DA, AP, and AP-type) for each metric showed large effect sizes (<i>ω</i><sup>2&nbsp;</sup>= .186 and <i>ω</i><sup>2&nbsp;</sup>= .179 for Alpha and Beta respectively). Post-hoc analysis, reveals that this arose almost wholly from the AP:DA difference (<i>p &lt;</i> .001) for both metrics.</p></li>
  </ul>
  <div class="figure figureViewer" id="f0004">
   <div class="hidden figureViewerArticleInfo">
    <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>17 January 2022
     </div>
    </div>
   </div>
   <div class="figureThumbnailContainer">
    <div class="figureInfo">
     <div class="short-legend">
      <p class="captionText"><span class="captionLabel">Figure 4. </span> Alpha and Beta inter-annotator agreement values for each dialogue set.</p>
     </div>
    </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0004image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0004_oc.jpg" loading="lazy" height="500" width="500"></a>
    <div class="figureDownloadOptions">
     <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
    </div>
   </div>
  </div>
  <div class="hidden rs_skip" id="fig-description-f0004">
   <p class="captionText"><span class="captionLabel">Figure 4. </span> Alpha and Beta inter-annotator agreement values for each dialogue set.</p>
  </div>
  <div class="hidden rs_skip" id="figureFootNote-f0004">
   <div class="figureFootNote-f0004"></div>
  </div>
  <p></p>
  <p>Overall, we see a considerable difference between the values of Alpha and Beta. Though it is less pronounced for DA labels, with a mean difference of 0.27, than it is for AP, and AP-types, which differ by 0.42 and 0.34, respectively. These differences indicate that annotators had very different proclivities when assigning labels, and this bias has <i>increased</i> the values of Beta with respect to Alpha. In the case of AP this increase amounts to two full thresholds on the Landis and Koch (<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1977</a></span>) scale, from “slight” to “moderate,” and we therefore recommend that this is considered before drawing any conclusions of reliability from the Beta agreement values alone. However, that this difference is less for DA, and greater for AP, suggest that individual annotator distributions were more similar when assigning DA labels and less similar for AP labels. In other words, we see a higher degree of idiosyncratic interpretation between the annotators when selecting AP labels, and this is reflected in the difference between the two coefficients. This observation is discussed further in AP Label Agreement and Alpha vs Beta.</p>
  <div id="s0005-s2001-s3001" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i59">Task-oriented and Non-task-oriented dialogs</h4>
   <p>A primary focus of this study is to investigate the extent to which the schema can be applied to different types of dialogue. Annotated dialogs were therefore split into their respective task and non-task-oriented groups, and again agreement was calculated using Alpha and Beta for each label type. <a href="#f0005">Figure 5</a> shows the resulting agreement values for each dialogue group, and the practice dialogue:</p>
   <ul class="NLM_list NLM_list-list_type-bullet">
    <li><p class="inline">On the practice dialogue, the Beta metric reports “perfect” agreement for all three groups of labels on the Landis and Koch (<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1977</a></span>), scale (Beta <i>&gt;</i> .95).</p></li>
    <li><p class="inline">For the Alpha metric, agreement on the practice dialogue is again “perfect” for DA (.84), and high for the AP-types (.59) but lower for just the AP labels (.37).</p></li>
    <li><p class="inline">These practice results are consistently higher than the main results, possibly because there are more annotators, and (as will be seen later) due to the nature of the KVRET corpus.</p></li>
    <li><p class="inline">Agreement was consistently higher for task-oriented dialogs for all label types, and both coefficients. Overall, these differences are statistically significant (<i>p &lt;</i> .001,<i>d &gt;</i> 1) for both Alpha and Beta. Only when looking at just the AP labels, is the task vs. non-task distinction not statistically significant (<i>p</i> = .07,<i>d</i> = .86 and <i>p</i> = .56,<i>d</i> = .9 for Alpha and Beta, respectively).</p></li>
   </ul>
   <p></p>
   <p>Again, overall, the differences between the two coefficients is high in most cases, and consequently we advise caution when interpreting the Beta values with respect to typical agreement thresholds. However, it is worth noting that for DA labels the difference on the task-oriented dialogs (0.19), and the practice dialogue (0.15), is much smaller than previously observed. Therefore, we can conclude that, not only is agreement higher but individual annotator distributions were more similar.</p>
   <div class="figure figureViewer" id="f0005">
    <div class="hidden figureViewerArticleInfo">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="figureThumbnailContainer">
     <div class="figureInfo">
      <div class="short-legend">
       <p class="captionText"><span class="captionLabel">Figure 5. </span> Alpha and Beta Agreement values for task and non-task dialogs.</p>
      </div>
     </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0005image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0005_oc.jpg" loading="lazy" height="500" width="500"></a>
     <div class="figureDownloadOptions">
      <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
     </div>
    </div>
   </div>
   <div class="hidden rs_skip" id="fig-description-f0005">
    <p class="captionText"><span class="captionLabel">Figure 5. </span> Alpha and Beta Agreement values for task and non-task dialogs.</p>
   </div>
   <div class="hidden rs_skip" id="figureFootNote-f0005">
    <div class="figureFootNote-f0005"></div>
   </div>
   <p></p>
   <p>To examine the difference between the task-oriented and non-task-oriented groups further, <button class="ref showTableEventRef" data-id="t0003">Table 3</button> shows the assignments produced by two annotators, users 10 and 5, for a task (KVRET) and non-task (CABNC) dialogue. We selected users 10 and 5 for this analysis because both exhibit a competent understanding of CAMS and its application. Yet as we will see, their differing interpretations of the CABNC dialogue led to negative agreement values. On the other hand, for the KVRET dialogue they reached near perfect agreement. Thus, this pairing provides clear insight into the properties of task-oriented and non-task-oriented dialogs that contribute to the observed differences in agreement between these groups, even between annotators who demonstrate a similar understanding of the annotation scheme. Additionally, both annotators made some small errors in assigning AP or DA. We highlight these assignments here and explore some of these observations further in the AP Label Agreement section.</p>
   <div class="tableViewerArticleInfo hidden">
    <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>17 January 2022
     </div>
    </div>
   </div>
   <div class="tableView">
    <div class="tableCaption">
     <div class="short-legend">
      <h3><p class="captionText"><span class="captionLabel">Table 3. </span> Label assignments by users 5 and 10 for a task (KVRET) and non-task (CABNC) dialogue.</p></h3>
     </div>
    </div>
    <div class="tableDownloadOption" data-hascsvlnk="true" id="t0003-table-wrapper">
     <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0003&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0003" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
    </div>
   </div>
   <p></p>
   <p>Firstly, we can see both annotators assign an invalid AP label to utterance A3; user-5 begins a FPP-post without a closing SPP, and user-10 places an insert label <i>outside</i> of a FPP/SPP base-pair. User-10 also incorrectly begins a FPP-pre (A1) and closes with a SPP-base (B2), a pattern that is repeated in the KVRET dialogue. There are also some minor misuses of DA. In particular, user-5 assigns “stalling” to (A2), which represents a speakers need for a little extra time to construct their contribution, for example, “Let me see… ” or “Umm….” Given the nature of the following utterances, a question-type DA, or user-10’s assignment of negative feedback, is more appropriate. However, the assignment of negative feedback for A3 is certainly incorrect, as this DA represents the speakers mishearing, or misunderstanding, of the previous utterance; a conclusion that is not borne out by its content.</p>
   <p>Regarding AP, the main source of disagreement with the CABNC dialogue is what constitutes the core action or communicative goal, and thus should be assigned as base-type AP, and what utterances contribute to, or support, this action, and should therefore be expansions. Both correctly identify the core action as a request to turn the radio off in A1. However, user-5 considers this action complete with the refusal to do so in B1, and the following two utterances are merely clarifying the meaning of “whatsname.” On the other hand, user-10 considers that the response in B1 was a mishearing, or misunderstanding, by A and that this requires the insert-pair before the action is completed in B2. Clearly these two interpretations led to significant disagreement between the two annotators and is largely driven by the ambiguity of certain utterances within the transcription, particularly A2. If A2 were instead “the what?”, or “who?”, then user-5’s interpretation is preferred, or alternatively, “sorry what?”, might suggest user-10’s understanding was correct. Unfortunately, “what what” lends itself to both these possibilities and hence the alternative interpretations. This is also reflected in the negative agreement scores between these two annotators, with an Alpha of −.1, and a Beta of −.05. For the KVRET dialogue there is no such ambiguity in which utterances make up the core action, and this resulted in “perfect”, or near perfect, agreement of .8 and .77 for Alpha and Beta, respectively.</p>
   <p>For DA, we again see considerable disagreement for the CABNC dialogue, and this is largely driven by the alternative interpretations previously discussed. Of note, however, is the assignments of a “propositional question” and a “request” for utterance A1. Even though it is posed as a question, this statement is an indirect way of requesting that the radio be turned off, and therefore user-10’s assignment is more suitable (Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0020" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2017</a></span>). Yet, it is easy to see how a propositional question, which suggests a positive (accept) or negative (decline) answer, is a reasonable alternative interpretation. Interestingly, despite the similar form of utterances A1 and C1, neither annotator assigned the same DA label. These dialogs were not presented in the order shown here, but this does indicate a change, or inconsistency, in interpretation; perhaps influenced by the presence of an interrogation mark in C1 which implies a question-type DA is appropriate. For the CABNC dialogue we again see negative agreement, −.03 and −.06, and for the KVRET dialogue substantial agreement of .79 and .76 for Alpha and Beta, respectively.</p>
   <p>From these results, we can see that, while there is some incorrect usage of both AP and DA, the main source of disagreement stems from difficulties interpreting the non-task-oriented dialogue. The two alternative views discussed above suggest two different sets of AP assignments, depending on where one considers the core action to have been completed, and this is largely driven by the ambiguity of utterance A2 observed above. Macagno and Bigi (<span class="ref-lnk lazy-ref"><a data-rid="cit0055" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2018</a></span>), referred to this phenomenon as “imaginary ambiguity”, that is, a particular utterance can have multiple distinct interpretations for the intended effect on the recipient depending on the context. In this case, A2 is interpreted differently depending on the reading of B1 as a refusal, or misunderstanding. This kind of <i>meaning multiplicity</i> (Boxman-Shabtai, <span class="ref-lnk lazy-ref"><a data-rid="cit0013" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2020</a></span>) may arise, at least in part, from the nature of transcribed material of natural conversations, where social cues, such as prosody, intonation, and body language, are lost. Indeed, Collins et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0028" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2019</a></span>), were able to show that disfluencies in speech can have very different meanings when presented in spoken and written form, and we surmise that this is also true of illocutionary ambiguous utterances. As noted by Green et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0041" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1997</a></span>), “<i>a transcript is a text that ‘re’-presents an event; not the event itself</i>”, thus information is inevitably lost. In any case, these differing interpretations are a clear example of bias on the part of individual annotators, and have therefore contributed to the inflation of the Beta coefficient, and its divergence from Alpha, that we have previously discussed. On the other hand, for the task-oriented dialogue there is a clear delineation between the core action and the remaining “thanking” utterances. This concurs with the work of Grosz (<span class="ref-lnk lazy-ref"><a data-rid="cit0043" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2018</a></span>), who established that task-oriented dialogs are structured, with multiple utterances grouping into a dialogue segment, and their structure mirrors the structure of the task. This characteristic simplifies the identification of AP and we therefore see much higher agreement and lower bias.</p>
  </div>
  <div id="s0005-s2001-s3002" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i61">Corpora dialogs</h4>
   <p>An additional factor which may contribute to the observed difference in agreement between the task and non-task dialogue groups is the number of utterances in each dialogue. Dialogs in the SCoSE corpus contain an average of 23.6 utterances, around half of the total number of utterances in each dialogue set, and may therefore be contributing a disproportionate amount of agreement (or disagreement) to the overall agreement values. Hence <a href="#f0006">Figure 6</a> breaks the comparison into different corpora. A further ANOVA and post-hoc analysis of agreement between pairs of corpora, was performed for each label type and coefficient:</p>
   <ul class="NLM_list NLM_list-list_type-bullet">
    <li><p class="inline">The post-hoc analysis reveals that there is no significant difference in agreements (<i>p</i> = .9) between the two non-task-oriented corpora, CABNC and SCoSE, for both Alpha and Beta coefficients, despite a mean utterance length of 5.6 and 23.6, respectively. This is also the case when comparing the bAbI corpus (mean utterance length 5.8) and the non-task-oriented corpora. Therefore, it is unlikely that the number of utterances is contributing to the observed differences in agreement between the groups.</p></li>
    <li><p class="inline">Predominantly, the statistically significant results are for DA and AP-type labels between KVRET and the other corpora. This indicates that the difference in agreement values are a product of higher agreement for the KVRET corpus, rather than a difference between the groups. Certainly, agreement is higher on the KVRET corpus, for all label types and both agreement coefficients.</p></li>
    <li><p class="inline">These results also provide some insight into the previous observation, that there is no significant difference in agreement for AP labels between the groups. Only the KVRET and SCoSE comparison for the Alpha metric produced a significant result (<i>p</i> = .028) and in all other cases we still see no statistical difference for AP labels.</p></li>
   </ul>
   <p></p>
   <p>From these results, we can see that, once more, there is a large difference between Alpha and Beta, and this is greater for AP than DA, hence a larger degree of idiosyncratic interpretation between the annotators. However, in accordance with the previous remarks, this bias is lower for the KVRET corpus than it is for the other three. Thus, while agreement for DA is higher for both task-oriented corpora, for AP we see no difference in agreement between the bAbI corpus and the two non-task-oriented corpora.</p>
   <div class="figure figureViewer" id="f0006">
    <div class="hidden figureViewerArticleInfo">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="figureThumbnailContainer">
     <div class="figureInfo">
      <div class="short-legend">
       <p class="captionText"><span class="captionLabel">Figure 6. </span> Alpha and Beta Agreement values for each corpus.</p>
      </div>
     </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0006image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0006_oc.jpg" loading="lazy" height="497" width="500"></a>
     <div class="figureDownloadOptions">
      <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
     </div>
    </div>
   </div>
   <div class="hidden rs_skip" id="fig-description-f0006">
    <p class="captionText"><span class="captionLabel">Figure 6. </span> Alpha and Beta Agreement values for each corpus.</p>
   </div>
   <div class="hidden rs_skip" id="figureFootNote-f0006">
    <div class="figureFootNote-f0006"></div>
   </div>
   <p></p>
   <p>Dialogs in the bAbI corpus all follow the same basic format. First greetings are exchanged, and the automated system asks the user what it can help them with. The user states their preference of cuisine, location, price range, and number of diners. The system then either asks for clarification of one of the stated preferences, or confirms the preferences are understood, and finally states that it will “look into some options” for the user. As an example, the following is the bAbI test 894 dialogue:</p><preformat xml:space="preserve" position="float" orientation="portrait" id="_i63">
     A1: good morning
   </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i64">
    B1: hello what can i help you with today
   </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i65">
    A2: may i have a table in a cheap price range in london with spanish food for two
   </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i66">
    B2: i’m on it
   </preformat><preformat xml:space="preserve" position="float" orientation="portrait" id="_i67">
    B3: ok let me look into some options for you 
   </preformat>
   <p>Given that this structure is common to all bAbI dialogs we were able to examine the assignments across all participants and identified common sources of disagreement. For AP, the main source of disagreement is which utterances constitute the core action or communicative function of the dialogue. With bAbI, we see two common interpretations. Six of our annotators considered the core action to begin with utterance B1 and the systems’ question of “what can i help you with today”, thus assigning B1 and A2 as a <i>base-type</i> AP. The remaining annotators all considered B1 as part of the preliminary salutations and assigned a <i>pre-type</i> AP label to B1. This latter group therefore began the base-pair from A2 and concluded it at B2 or B3. It is easy to see how these two interpretations can be reached given the multidimensional nature of utterance B1 (Bunt, <span class="ref-lnk lazy-ref"><a data-rid="cit0018" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2006</a></span>), that is, both a greeting <i>and</i> a question. Though, only two annotators assigned a <i>greeting</i> DA label to B1 and eleven assigned a <i>question-type</i> label (the remaining two incorrectly assigned an offer label). The multidimensional nature also extends into the interpretation of AP. The greeting component of B1 is responsive to the greeting in A1, indicating it is the <i>concluding</i> utterance of a pair, while the question component creates the expectation of a response, suggesting it is <i>initiating</i> an AP. Hence, we see two valid readings of the utterances DA, and its relationship to the surrounding utterances, which is reflected in two different interpretations of the core action underway. Therefore, we can see that just as the semantically ambiguous utterance discussed in the previous section led to two valid interpretations of the dialogue, here a similar effect is caused by the multidimensionality of B1, resulting in a significant number of disagreements for AP on the bAbI corpus. Additionally, the multidimensional nature of utterances like B1 are likely to be a further contributor to the bias, and inflation of the Beta coefficient, that we have observed throughout our results.</p>
  </div>
  <div id="s0005-s2001-s3003" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i68">AP label agreement</h4>
   <p>As previously observed, there appears to be no significant difference in agreement for AP labels between the task and non-task dialogue groups, and further, that much of this is caused by the negligible difference between the bAbI, CABNC and SCoSE corpora. Manual inspection of the annotations revealed that a considerable amount of confusion seemed to arise around the valid use of FPP and SPP for AP. Often annotators would assign a SPP to initiate a sequence (rather than a FPP), or fail to create a valid sequence entirely, for example, by assigning a FPP without an accompanying SPP. This observation was explored further using an adjusted AP distance function, which ignores the AP prefix (FPP/SPP), and instead <i>only</i> considers the difference between the AP <i>base</i> or <i>expansion types</i> (pre, post, and insert). The “suffix-only” distance function treats all labels as equally distinct, with a distance of 1 for non-identical labels, and 0 otherwise. For example, two <i>insert</i> type labels (FPP-insert, SPP-insert or insert) would have a distance of 0 between them, but a distance of 1 with all other AP label types. Therefore, the suffix-only distance function should indicate the extent to which annotators misunderstanding of the valid use of FPP and SPP labels contributed to the observed AP agreement values. <a href="#f0007">Figure 7</a> shows the agreement values that were recalculated for using the suffix-only distance function.</p>
   <ul class="NLM_list NLM_list-list_type-bullet">
    <li><p class="inline">Using the suffix-only distance function both task-oriented corpora show improved agreement for AP labels, with a minimal improvement for the KVRET corpus but a considerable improvement for bAbI. For Alpha the bAbI agreement doubled from .12 to .24, and Beta shows an increase of .57 to .62.</p></li>
    <li><p class="inline">Both non-task-oriented corpora show a decrease in AP agreement, though, again the effect is greater for the Alpha coefficient, with a decrease of .05 and .07 for SCoSE and CABNC respectively, compared to .01 and .04 for Beta.</p></li>
    <li><p class="inline">Post-hoc analysis reveals there is now no longer a significant difference in AP-type labels when comparing the KVRET and bAbI corpora (<i>p</i> = .181 and <i>p</i> = .193, for Alpha and Beta, respectively).</p></li>
   </ul>
   <div class="figure figureViewer" id="f0007">
    <div class="hidden figureViewerArticleInfo">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="figureThumbnailContainer">
     <div class="figureInfo">
      <div class="short-legend">
       <p class="captionText"><span class="captionLabel">Figure 7. </span> Corpora agreement values calculated with the suffix-only AP distance function.</p>
      </div>
     </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0007image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0007_oc.jpg" loading="lazy" height="491" width="500"></a>
     <div class="figureDownloadOptions">
      <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
     </div>
    </div>
   </div>
   <div class="hidden rs_skip" id="fig-description-f0007">
    <p class="captionText"><span class="captionLabel">Figure 7. </span> Corpora agreement values calculated with the suffix-only AP distance function.</p>
   </div>
   <div class="hidden rs_skip" id="figureFootNote-f0007">
    <div class="figureFootNote-f0007"></div>
   </div>
   <p></p>
   <p>This indicates that, when annotators misunderstanding of the valid use of FPP and SPP is not considered, they tend to more often agree on the <i>base</i> and <i>expansion types</i> of AP labels for task-oriented dialogs. Whereas, for non-task-oriented dialogs the opposite is true, with a <i>decrease</i> in agreement that suggests annotators rarely agree on the AP <i>base</i> or <i>expansion types</i>. Perhaps unsurprisingly, this suggests that the structure of non-task-oriented dialogs is less well defined, and open to more subjective interpretation, than that of task-oriented dialogs. It may also offer explanation for the lack of significant difference in AP agreement, and high bias, that was previously observed. Using a two-sided t-test to compare the suffix-only agreement scores for AP labels between the task and non-task groups now results in a statistically significant difference for Alpha and Beta (<i>p</i> = .0028,<i>d &gt;</i> 1 and <i>p</i> = .0089,<i>d &gt;</i> 1, respectively). Therefore, the incorrect usage of FPP and SPP was <i>reducing</i> agreement for task-oriented dialogs, while for non-task dialogs <i>increasing</i> agreement, and “evening out” AP agreement values between the groups. These results also suggest that using non-expert annotators may not be suitable for this task, as many seem to lack a clear understanding of the proper use of AP, or alternatively, more training beforehand may help to improve understanding in this regard. It is also possible that some of the confusion was caused by the similarity between FPP and SPP, with only one-character difference between the two labels. Perhaps changing the labels to, for example, “first-part” and “second-part,” would help mitigate the problem of assigning these in the wrong order.</p>
  </div>
  <div id="s0005-s2001-s3004" class="NLM_sec NLM_sec_level_3">
   <h4 class="section-heading-4" id="_i70">Alpha vs beta</h4>
   <p>Previous results have shown that in all cases the Beta coefficient results in significantly higher agreement values than Alpha, and that this is principally caused by the differences in annotator label distributions increasing the Beta values. As discussed in the Inter-Annotator Agreement section, the difference between these two coefficients lies only in their calculation of expected disagreement. That is, Alpha estimates disagreement on the basis that all annotators assign labels with the same probability distribution, while Beta considers the individual annotators distributions. Here, these different estimations are tested, using the actual annotator label distributions from this study, to determine the extent to which annotators use similar, or different distributions.</p>
   <div id="s0005-s2001-s3004-s4001" class="NLM_sec NLM_sec_level_4">
    <h5 class="section-heading-5" id="_i71">Jensen-Shannon divergence</h5>
    <p>The difference, or similarity, between probability distributions can be calculated using the Jensen-Shannon divergence (JSD) method. Here, the generalization of JSD is adopted, which calculates a distance value between two or more probability distributions. The distance value is bounded in the range 0 <i>≤&nbsp;JSD ≤ log</i><sub>2</sub>(<i>n</i>), where <i>n</i> is the number of input distributions; the lower bound represents identical distributions and the upper bound maximally different distributions. For each dialogue set the JSD distance was calculated for the probability distributions of all annotators that labeled that set. Thus, in each case <i>n</i> = 3 and the range is 0 <i>≤&nbsp;JSD ≤</i> 1.58. <button class="ref showTableEventRef" data-id="t0004">Table 4</button> shows the JSD distances for the DA and AP label distributions over each dialogue set. We can see that both DA and AP have low distance values, within ~<span class="NLM_disp-formula-image inline-formula rs_preserve">
      <noscript>
       <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0150.gif" alt="">
      </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0150.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
      <math>
       <mrow>
        <mfrac>
         <mn>
          1
         </mn>
         <mn>
          6
         </mn>
        </mfrac>
       </mrow>
      </math></span><i><sup>th</sup></i> of the lower range, and therefore, overall differences between annotator distributions is relatively small using this measure. AP labels show a lower average distance than DA over all dialogue sets, with a mean of 0.22 and 0.25 respectively, which is likely due to the fewer number of AP labels. However, AP also show a higher standard deviation than DA and this may reflect the higher disagreement and bias for AP labels that was previously observed.</p>
    <div class="tableViewerArticleInfo hidden">
     <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
     <div class="articleAuthors articleInfoSection">
      <div class="authorsHeading">
       All authors
      </div>
      <div class="authors">
       <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
      </div>
     </div>
     <div class="articleLowerInfo articleInfoSection">
      <div class="articleLowerInfoSection articleInfoDOI">
       <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
      </div>
      <div class="articleInfoPublicationDate articleLowerInfoSection border">
       <h6>Published online:</h6>17 January 2022
      </div>
     </div>
    </div>
    <div class="tableView">
     <div class="tableCaption">
      <div class="short-legend">
       <h3><p class="captionText"><span class="captionLabel">Table 4. </span> JSD distance for DA and AP labels of each dialogue set.</p></h3>
      </div>
     </div>
     <div class="tableDownloadOption" data-hascsvlnk="true" id="t0004-table-wrapper">
      <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0004&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0004" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
     </div>
    </div>
    <p></p>
   </div>
   <div id="s0005-s2001-s3004-s4002" class="NLM_sec NLM_sec_level_4">
    <h5 class="section-heading-5" id="_i72">Pearson's Chi-squared</h5>
    <p>In addition to calculating the distance between groups of annotator probability distributions, we can also examine the extent to which label distributions are dependent on the individual annotators that assigned them. For this purpose, an <i>χ</i><sup>2</sup> test was conducted using the <i>cumulative</i> annotator label distributions. For each dialogue set a separate <i>χ</i><sup>2</sup> test was performed for all pairwise annotator combinations.<span class="ref-lnk fn-ref-lnk lazy-ref"><a data-rid="fn0004" href="#" data-reflink="fn"><span class="off-screen">Footnote</span><sup>4</sup></a></span> From these results, we can see that</p>
    <ol class="NLM_list NLM_list-list_type-order">
     <li><p class="inline">For DA, in none of the pairwise comparison between annotators are the observed label frequencies significantly different. In other words, regardless of which annotator assigned the labels, the distribution would still be largely the same – although individual assignments could still be very different.</p></li>
     <li><p class="inline">For AP, in <span class="NLM_disp-formula-image inline-formula rs_preserve">
        <noscript>
         <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0029.gif" alt="">
        </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0029.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
        <math>
         <mrow>
          <mfrac>
           <mn>
            1
           </mn>
           <mn>
            3
           </mn>
          </mfrac>
         </mrow>
        </math></span> of cases (2 in set 3 and all of set 5), we see significant results when comparing the critical value to the test statistic, and also significant <i>p</i>-values. As such, we must reject the null hypothesis and concluded that the label distributions (in <span class="NLM_disp-formula-image inline-formula rs_preserve">
        <noscript>
         <img src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0030.gif" alt="">
        </noscript><img src="//:0" alt="" class="mml-formula" data-formula-source="{&quot;type&quot; : &quot;image&quot;, &quot;src&quot; : &quot;/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/hcms_a_2020229_ilm0030.gif&quot;}"><span class="mml-formula"></span></span><span class="NLM_disp-formula inline-formula rs_preserve"><img src="//:0" alt="" data-formula-source="{&quot;type&quot; : &quot;mathjax&quot;}">
        <math>
         <mrow>
          <mfrac>
           <mn>
            1
           </mn>
           <mn>
            3
           </mn>
          </mfrac>
         </mrow>
        </math></span> of cases) were dependent on the annotator that assigned them. Therefore, certain annotators were producing label distributions that were quite distinct from each other.</p></li>
    </ol>
    <p></p>
    <p>These two conclusions seem to support the results from the JSD comparison. Firstly, there seems to be less variance in the annotator’s DA label assignments, likely contributing to the observed higher agreement values. Secondly, AP seem to be more dependent on the individual annotator which assigned them (overall <i>p</i>-values are lower, indicating a higher degree of idiosyncratic interpretation). As such, agreement for AP was lower, while bias was higher, and this may also be indicative of the misunderstanding surrounding the use of FPP and SPP that was discussed in the AP Label Agreement section, and the differences in interpretation observed in the task-oriented and non-task-oriented and corpora results. These results also suggest that both the JSD and <i>χ</i><sup>2</sup> tests could serve as additional measures for the homogeneity of annotators interpretation, and understanding, of the material and coding scheme.</p>
    <p>From these measures, and regarding Alpha and Beta, it seems that annotators do, in fact, use more similar distributions for DA labels. In most cases, this also appears true for AP, though there is a greater variance (in part due to misunderstanding FPP and SPP) between some groups of annotators. However, as we have seen, these small differences can result in drastically different values between the two coefficients. Given that there is a certain amount of semantic interpretation when assigning both DA and AP labels, the assumption that annotators will use the same distribution is, as Artstein and Poesio (<span class="ref-lnk lazy-ref"><a data-rid="cit0004" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2005b</a></span>) stated, too strong. Consequently, Alpha may be too harsh in its estimation of annotator distributions and punish individual interpretation too severely. Yet, as shown in our AP label agreement results, when using the suffix-only distance function, the Beta coefficient exhibited smaller changes in agreement values. Further, as shown throughout our results, in the presence of bias – which is itself a form of disagreement – the Beta coefficient is consistently higher than Alpha. Therefore, it may be a less sensitive measure of agreement, even hiding some causes of disagreement, which makes drawing conclusions of reliability problematic, using the Beta coefficient alone. However, that Alpha and Beta diverge, and the extent to which they do, can provide useful information in its own right. In our case it has clearly signified the higher degree of idiosyncratic interpretation between annotators when assigning AP labels, and also highlighted differences between task and non-task-oriented, or dialogue corpora, groups. This information would not have been apparent from the calculation of either coefficient alone, and so in agreement with Di Eugenio and Glass (<span class="ref-lnk lazy-ref"><a data-rid="cit0031" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), for annotation that require a high degree of semantic interpretation, it seems more helpful to report both biased and unbiased values. Though, if the goal is to reach high agreement values, and hence reliability of labeled data, the more stringent unbiased coefficient should be used.</p>
   </div>
  </div>
 </div>
 <div id="s0005-s2002" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i73">Annotation confidence scores</h3>
  <p>Analysis of participants confidence scores supports some of the observations from the previous sections. Overall, annotators reported a higher confidence in their assigned labels for task-oriented dialogs than for non-task-oriented dialogs (<button class="ref showTableEventRef" data-id="t0005">Table 5</button>), which coincides with the higher agreement for task-oriented dialogs observed in our previous results. Notably, although the mean confidence between labeling tasks differed, the standard deviation of confidences range between 0.64 and 1.31, in other words, less than two Likert scale points. The difference in confidence between task and non-task was significant (<i>p &lt;</i> .001) for the overall AP-type labels and both AP, and DA.<span class="ref-lnk fn-ref-lnk lazy-ref"><a data-rid="fn0005" href="#" data-reflink="fn"><span class="off-screen">Footnote</span><sup>5</sup></a></span></p>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <div class="short-legend">
     <h3><p class="captionText"><span class="captionLabel">Table 5. </span> Mean and standard deviation of confidence scores by label type, corpus, and dialogue type.</p></h3>
    </div>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="t0005-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0005&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0005" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p></p>
  <p>If we again examine confidence scores with respect to each corpus, we also see a result similar to that for agreement values. That is, confidence is highest for the KVRET corpus and lowest for SCoSE, with the other task-oriented corpus being marginally higher than CABNC in most cases (<a href="#f0008">Figure 8</a>). For each label type, an ANOVA over confidence scores per-corpora concur with those of agreement. Overall results are significant (<i>p ≤</i> .027), and effect size is large for AP and AP-types (<i>ω</i><sup>2&nbsp;</sup><i>&gt;</i> .14), and medium for DA (<i>ω</i><sup>2&nbsp;</sup>= .1).<span class="ref-lnk fn-ref-lnk lazy-ref"><a data-rid="fn0006" href="#" data-reflink="fn"><span class="off-screen">Footnote</span><sup>6</sup></a></span> Post-hoc analysis shows the only place we see significant differences is between KVRET and the other corpora, particularly with AP. Similarly, the difference between the two non-task-oriented corpora and bAbI is statistically non-significant in all cases. This indicates that, as with agreement, the division is not necessarily between task and non-task-oriented dialogs, but primarily between KVRET and the other three corpora.</p>
  <p>These results show that there is a remarkable similarity between the annotators reported confidence scores and the resulting agreement values. When considered from the perspectives of task and non-task-oriented dialogs, individual corpora, and different label types, where higher confidence was reported, agreement was also higher. Annotators were therefore quite good at assessing how well their assigned labels fit the data, reporting higher confidence for dialogs where appropriate labels, or dialogue structure, was more intuitive, and lower confidence on the less structured dialogue types. This also suggests that incorporating confidence scores could be a valuable resource assessing labeling accuracy. Kazai (<span class="ref-lnk lazy-ref"><a data-rid="cit0048" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2011</a></span>), showed that annotators who rated the task easier also had a higher accuracy. While Oyama et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0059" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2013</a></span>), used self-reported confidence scores, along with their assigned labels, to estimate the “true” labels using the expectation-maximization (EM) algorithm.</p>
  <div class="figure figureViewer" id="f0008">
   <div class="hidden figureViewerArticleInfo">
    <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>17 January 2022
     </div>
    </div>
   </div>
   <div class="figureThumbnailContainer">
    <div class="figureInfo">
     <div class="short-legend">
      <p class="captionText"><span class="captionLabel">Figure 8. </span> Reported annotator confidence scores for each dialogue and label type.</p>
     </div>
    </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0008image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0008_oc.jpg" loading="lazy" height="344" width="500"></a>
    <div class="figureDownloadOptions">
     <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
    </div>
   </div>
  </div>
  <div class="hidden rs_skip" id="fig-description-f0008">
   <p class="captionText"><span class="captionLabel">Figure 8. </span> Reported annotator confidence scores for each dialogue and label type.</p>
  </div>
  <div class="hidden rs_skip" id="figureFootNote-f0008">
   <div class="figureFootNote-f0008"></div>
  </div>
  <p></p>
 </div>
 <div id="s0005-s2003" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i75">Annotation time</h3>
  <p>The time participants took to completely annotate each utterance was also recorded. Because participants likely spent some time reading utterances and considering labels at the beginning of each dialogue, here all reported times are the average time taken, in seconds, to annotate an utterance for that dialogue. Unlike agreement values and confidence scores, utterance times reveal that there is little difference between task and non-task-oriented dialogs, or the different corpora, as shown in <button class="ref showTableEventRef" data-id="t0006">Table 6</button>. Therefore, despite reporting lower confidence for non-task-oriented dialogs, and the SCoSE corpus also containing around 4 times as many utterances, this did not seem to affect the average amount of time spent annotating those dialogs.</p>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <div class="short-legend">
     <h3><p class="captionText"><span class="captionLabel">Table 6. </span> Mean and standard deviation of utterance annotation time (seconds) per corpus and dialogue type.</p></h3>
    </div>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="t0006-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0006&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0006" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p></p>
  <p>If we instead look at the average utterance time in the order dialogs were annotated, regardless of the specific dialogue, we see that annotation habits do indeed change over time. <a href="#f0009">Figure 9</a> and <button class="ref showTableEventRef" data-id="t0007">Table 7</button> show that, for all participants, annotation time became faster as they progressed through the task, starting with an average of 77.89&nbsp;seconds for the practice dialogue and ending with 19.81&nbsp;seconds by dialogue 4. And further, that the variance between participants times also grew smaller over time, moving from a standard deviation of 27.52 on the practice dialogue, to just 6.03 on dialogue 4. These results seem to show a clear learning-effect, which echoes the results of Aulamo et al. (<span class="ref-lnk lazy-ref"><a data-rid="cit0008" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2019</a></span>), where participants start with slow annotation speed, then, after a period of familiarization with the task, speed is increased and maintained for the remaining time. It may also be valuable to determine if there is a similar change in agreement over time, as annotators became more familiar with the schema and tool. Unfortunately, because all but the practice dialogue was shown in a random order for each participant, it is not possible to show that data and it will be left for future work. However, given that the practice dialogue also resulted in the highest agreement values, we suspect that this may not have a significant impact on agreement.</p>
  <div class="figure figureViewer" id="f0009">
   <div class="hidden figureViewerArticleInfo">
    <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
    <div class="articleAuthors articleInfoSection">
     <div class="authorsHeading">
      All authors
     </div>
     <div class="authors">
      <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
     </div>
    </div>
    <div class="articleLowerInfo articleInfoSection">
     <div class="articleLowerInfoSection articleInfoDOI">
      <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
     </div>
     <div class="articleInfoPublicationDate articleLowerInfoSection border">
      <h6>Published online:</h6>17 January 2022
     </div>
    </div>
   </div>
   <div class="figureThumbnailContainer">
    <div class="figureInfo">
     <div class="short-legend">
      <p class="captionText"><span class="captionLabel">Figure 9. </span> Distribution of annotators mean utterance annotation time (seconds) in the order dialogs were completed.</p>
     </div>
    </div><a href="#" class="thumbnail" aria-label="thumbnail image"><img id="f0009image" src="/na101/home/literatum/publisher/tandf/journals/content/hcms20/2022/hcms20.v016.i03/19312458.2021.2020229/20230223/images/medium/hcms_a_2020229_f0009_oc.jpg" loading="lazy" height="344" width="500"></a>
    <div class="figureDownloadOptions">
     <a href="#" class="downloadBtn btn btn-sm" role="button">Display full size</a>
    </div>
   </div>
  </div>
  <div class="hidden rs_skip" id="fig-description-f0009">
   <p class="captionText"><span class="captionLabel">Figure 9. </span> Distribution of annotators mean utterance annotation time (seconds) in the order dialogs were completed.</p>
  </div>
  <div class="hidden rs_skip" id="figureFootNote-f0009">
   <div class="figureFootNote-f0009"></div>
  </div>
  <div class="tableViewerArticleInfo hidden">
   <span class="figViewerTitle">Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue</span>
   <div class="articleAuthors articleInfoSection">
    <div class="authorsHeading">
     All authors
    </div>
    <div class="authors">
     <a class="entryAuthor" href="/action/doSearch?Contrib=Duran%2C+Nathan"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Duran%2C+Nathan"><span class="NLM_given-names">Nathan</span> Duran</a> <a href="https://orcid.org/0000-0001-6084-4406"><img src="/templates/jsp/images/orcid.png"></a>, <a class="entryAuthor" href="/action/doSearch?Contrib=Battle%2C+Steve"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Battle%2C+Steve"><span class="NLM_given-names">Steve</span> Battle</a> <a href="https://orcid.org/0000-0002-7154-7869"><img src="/templates/jsp/images/orcid.png"></a> &amp; <a class="entryAuthor" href="/action/doSearch?Contrib=Smith%2C+Jim"><span class="hlFld-ContribAuthor"></span></a><a href="/author/Smith%2C+Jim"><span class="NLM_given-names">Jim</span> Smith</a> <a href="https://orcid.org/0000-0001-7908-1859"><img src="/templates/jsp/images/orcid.png"></a>
    </div>
   </div>
   <div class="articleLowerInfo articleInfoSection">
    <div class="articleLowerInfoSection articleInfoDOI">
     <a href="https://doi.org/10.1080/19312458.2021.2020229">https://doi.org/10.1080/19312458.2021.2020229</a>
    </div>
    <div class="articleInfoPublicationDate articleLowerInfoSection border">
     <h6>Published online:</h6>17 January 2022
    </div>
   </div>
  </div>
  <div class="tableView">
   <div class="tableCaption">
    <div class="short-legend">
     <h3><p class="captionText"><span class="captionLabel">Table 7. </span> Min, max, mean, and standard deviation of annotators mean utterance annotation time (seconds) in the order dialogs were completed.</p></h3>
    </div>
   </div>
   <div class="tableDownloadOption" data-hascsvlnk="true" id="t0007-table-wrapper">
    <a class="downloadButton btn btn-sm" role="button" href="/action/downloadTable?id=t0007&amp;doi=10.1080%2F19312458.2021.2020229&amp;downloadType=CSV"> Download CSV</a><a data-id="t0007" class="downloadButton btn btn-sm displaySizeTable" href="#" role="button">Display Table</a>
   </div>
  </div>
  <p></p>
 </div>
 <div id="s0005-s2004" class="NLM_sec NLM_sec_level_2">
  <h3 class="section-heading-3" id="_i77">Conclusion</h3>
  <p>In this article, we have presented CAMS, which utilizes the CA concepts of AP, in conjunction with DA derived from the DiAML, to create a unified dialogue annotation scheme that captures the semantic and syntactic structure of dialogue for computational purposes. We assessed the schema by means of an exploratory annotation task, completed by novice annotators, and measured their inter-annotator agreement using dialogs from task-oriented and non-task-oriented settings. We also proposed distance functions, for each label type within the schema, that may be used when calculating inter-annotator agreement using weighted coefficients, such as Alpha and Beta.</p>
  <p>Our findings indicate that inter-annotator agreement is significantly higher for the biased Beta coefficient, than that of unbiased Alpha, and this is principally caused by the differences in annotator label distributions increasing the Beta values. We therefore advise caution when comparing the two coefficients using the standard scales of interpretation (Geiß, <span class="ref-lnk lazy-ref"><a data-rid="cit0039" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2021</a></span>), particularly when biased measures diverge from unbiased ones. Nevertheless, if we assess agreement values of each dialogue set, using the somewhat arbitrary scale of Landis and Koch (<span class="ref-lnk lazy-ref"><a data-rid="cit0052" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1977</a></span>), we find that for Beta DA and AP-type agreement can be considered “substantial,” while AP fall into the “moderate” agreement category. However, agreement for the Alpha coefficient is less convincing. DA show a “moderate” level of agreement, while AP and AP-types only achieve “slight” and “fair” respectively. If we use the more stringent range [.67, .8], often used in Computational Linguistics to allow for “tentative conclusions to be drawn” (Carletta, <span class="ref-lnk lazy-ref"><a data-rid="cit0023" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1996</a></span>; Krippendorff, <span class="ref-lnk lazy-ref"><a data-rid="cit0050" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>2004</a></span>), we find that only DA and AP-type labels are able to reach this threshold for the Beta coefficient. These results seem to concur with Poesio and Vieira (<span class="ref-lnk lazy-ref"><a data-rid="cit0060" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1998</a></span>), and Hearst (<span class="ref-lnk lazy-ref"><a data-rid="cit0044" data-reflink="_i78 _i80" href="#"><span class="off-screen">Citation</span>1997</a></span>), that reaching the .67 threshold is difficult for discourse annotation tasks. In this case, it may be due to our use of non-expert annotators, who have been shown to misunderstand the proper use of AP, and therefore more intense training should be provided, or expert annotators used. It may also be due to differences in individual annotator interpretations of the dialogs and appropriate AP labels. However, these agreement values can be considered an indication of moderate reliability.</p>
  <p>Regarding task-oriented and non-task-oriented dialogs, both annotator agreement and self-reported annotator confidence scores are higher for task-oriented dialogs than non-task. However, when considered from the perspective of the individual corpora this distinction is not as clear. With the (task-oriented) KVRET corpus resulting in higher agreement and confidence scores than the other 3. We therefore conclude that, while CAMS is indeed applicable to both task and non-task-oriented dialogs, our results show that it is more intuitively applied to task-oriented dialogs. The determining factor, however, is not the division between task and non-task, but rather the content of the dialogue itself. Notably, we observed that utterances where the DA label is ambiguous, or multidimensional, can lead to different interpretations of the dialogue and result in a high number of disagreements for both DA <i>and</i> AP. Regarding the constituent label types within the schema, we found that DA labels consistently resulted in higher agreement and confidence scores than AP. This is perhaps not surprising, given that DA labels need only apply to one utterance at a time and generally use more intuitive names. AP on the other hand, require more specialized knowledge, and annotators must also consider relationships between utterances in order to apply them correctly. We found that many annotators misunderstood, and incorrectly applied the FPP and SPP labels. If labeling accuracy is required for the creation of an annotated corpus, this task may be better suited to experts, or novice annotators who have received more training than ours. Additionally, in order to produce accurate agreement scores the annotation tool intentionally placed no restrictions on label assignments; In future iterations this could be altered, to prevent, for example, the invalid creation of a new AP before a prior pair is completed. Unfortunately, given our procedural setup we were unable to measure if there is any improvement in agreement over time, once annotators had learned the annotation tool and schema. However, measuring the average time taken to annotate each utterance shows a clear pattern of learning, with annotation time decreasing for all annotators the longer they spent on the task. This indicates that the schema is inherently learnable and becomes more intuitive to apply with practice.</p>
  <p>This article also explored some of the different assumptions around chance agreement for the unbiased (Alpha) and biased (Beta) agreement coefficients. We show, by means of JSD and Chi-squared analysis, that the annotators did indeed use similar distributions. Though the variance is larger for AP, which may require a greater degree of semantic interpretation, and where our annotators were often shown to misunderstand. However, these small differences in distributions resulted in dramatic differences between agreement scores for the Alpha and Beta coefficients, with consistently lower values for Alpha, and highlighting that the biased Beta coefficient is a less sensitive measure. Yet, if biased and unbiased measures diverge, the extent to which they do can provide useful information in its own right; by highlighting differences in annotator understanding of appropriate label categories, or between the annotation material itself. We therefore conclude that, if labeling accuracy is key, an unbiased measure such as Alpha should be used. However, for annotation tasks that require a high degree of semantic interpretation reporting both measures may be more beneficial.</p>
 </div>
</div>