<div>
 <div class="article-formatted-body article-formatted-body article-formatted-body_version-2">
  <div xmlns="http://www.w3.org/1999/xhtml">
   <h2>Введение</h2>
   <p>Сегодня искусственный интеллект стал одной из&nbsp;самых популярных для&nbsp;изучения и обсуждаемых тем. Сегодняшний уровень развития искусственного интеллекта (ИИ) позволяет создавать беспилотные автомобили, системы, обыгрывающие чемпионов мира в&nbsp;Го и шихматы, полностью ведут производство на&nbsp;различных фабриках. Тенденции к&nbsp;развитию ИИ требуют исследования проблемы «монополии» на&nbsp;сознание у&nbsp;человека, различия «слабого» и «сильного» искусственного интеллекта и возможности создания «искусственного сознания».</p>
   <p>Долгое время в&nbsp;философии существует ряд проблем, связанных с&nbsp;ИИ [15]:</p>
   <ol>
    <li><p>Как&nbsp;работает разум?</p></li>
    <li><p>Могут&nbsp;ли машины действовать разумно?</p></li>
    <li><p>Может&nbsp;ли у&nbsp;машины&nbsp;быть сознание?</p></li>
    <li><p>Каковы моральные и этические проблемы и каковы их решения при&nbsp;использовании ИИ?</p></li>
   </ol>
   <p>Нельзя рассматривать текущий уровень развития ИИ как&nbsp;стабильный или&nbsp;финальный. Существует большое количество прогнозов, которые не&nbsp;прошли испытание временем. Так математик и философ Дуглас Хофштадтер в&nbsp;своей книге «Гёдель, Эшер, Бах: эта бесконечная гирлянда» предполагал, что&nbsp;в&nbsp;ближайшем будущем появятся программы для&nbsp;игры в&nbsp;шахматы, которые не&nbsp;сможет обыграть человек и при&nbsp;этом данные программы будут обладать разумом и характером [Хофштадтер, 2001]. Спустя несколько десятилетий появились программы, которые способны обыграть в&nbsp;шахматы любого человека, но&nbsp;не&nbsp;являются системами искусственного интеллекта и не&nbsp;обладают признаками сознания, в&nbsp;интуитивном понимание данного термина.</p>
   <h2>Теория сознания</h2>
   <p>Автором концепции сознания в&nbsp;современном понимание является Джон Локк и формулируется она как «восприятие того, что&nbsp;происходит в&nbsp;собственном разуме человека». На&nbsp;данный момент не&nbsp;существует определения термина «сознание». Эту проблему выразил Стюарт Сазерленд в&nbsp;своей статье, где утверждал, что&nbsp;сознание&nbsp;— это удивительное, но&nbsp;неуловимое явление: невозможно определить, что&nbsp;это такое, что&nbsp;оно делает и почему оно эволюционировало [19]. В&nbsp;философии термин «сознание» используется для&nbsp;четырех основных тем:</p>
   <ol>
    <li><p>Знания в&nbsp;целом.</p></li>
    <li><p>Преднамеренность.</p></li>
    <li><p>Интроспекция.</p></li>
    <li><p>Основанный на&nbsp;ощущениях опыт.</p></li>
   </ol>
   <p>Большую часть существующих определений можно рассматривать как&nbsp;взгляд автора на&nbsp;основные свойства или&nbsp;концепцию сознания. Как&nbsp;следствие, формулировка независящего от&nbsp;теории определения в&nbsp;ближайшем будущем скорее невозможна [29]. На&nbsp;данный момент можно выделить несколько терминов, которые в&nbsp;некоторой степени определяют термин «сознание», к&nbsp;основным относятся [17]:</p>
   <ol>
    <li><p>Осознанность&nbsp;— способность воспринимать, чувствовать события, сенсорные закономерности или&nbsp;объекты.</p></li>
    <li><p>Чувствительность&nbsp;— способность воспринимать свое окружение или&nbsp;иметь собственный, субъективный опыт.</p></li>
    <li><p>Самосознание&nbsp;— способность отделять себя от&nbsp;окружающей среды, других объектов окружающей среды и проводить самоанализ.</p></li>
    <li><p>Разумность&nbsp;— умственная способность действовать с&nbsp;надлежащим суждением. Может рассматриваться как&nbsp;часть интеллекта, но&nbsp;может рассматриваться, как&nbsp;и отдельный элемент в&nbsp;дополнение к&nbsp;интеллекту.</p></li>
    <li><p>Квалиа&nbsp;— отдельные моменты субъективного, сознательного опыта.</p></li>
   </ol>
   <p>Первые теории сознания встречаются еще в&nbsp;работах Аристотеля, однако в&nbsp;центр внимания данную тему поставили работы Рене Декарта, где он утверждал, что&nbsp;разум&nbsp;— это не&nbsp;физическая субстанция отличная от&nbsp;тела [13]. В&nbsp;дальнейшем множество философов формулировали свою теорию сознания. Все эти теории можно разделить на&nbsp;два больших класса: метафизические теории, пытающиеся локализовать сознание в&nbsp;общей онтологической схеме реальности и более конкретными теориями, которые представляют детальную природу, роль и особенности сознания.</p>
   <p>Метафизические теории пытаются ответить на «психофизиологическую проблему» проблему, поставленную Декартом в&nbsp;части «сознания», в&nbsp;противоположность «мыслительной». Такие теории привели к&nbsp;появлению монизма и теории дуализма.</p>
   <p>Дуалистические теории предполагают, что&nbsp;мир состоит из&nbsp;фундаментальных сущностей: материя и разум. Обычно дуалистические теории рассматривают&nbsp;лишь часть аспектов сознания как&nbsp;отделенные от&nbsp;физической части. Большинство подобных теорий сталкивается с&nbsp;трудностями при&nbsp;ответе на «трудную проблему сознания» [1], которая может&nbsp;быть сформулирована различными способами, но&nbsp;всегда отвечает на&nbsp;два вопроса:</p>
   <ol>
    <li><p>Почему мозг порождает сознание?</p></li>
    <li><p>Каким образом мозг порождает сознание?</p></li>
   </ol>
   <p>Если предположить, что&nbsp;существует возможность порождения сознания искусственным интеллектом, то данная проблема встает и в&nbsp;объяснение данного феномена.</p>
   <p>Следующим видом теорий сознания является монизм, который утверждает, что&nbsp;существует только одна фундаментальная сущность: только ментальная (идеалистический монизм), сущность является не&nbsp;ментальной, не&nbsp;физической (нейтральный монизм), сущность является физической (натуралистический монизм). Основная монистическая теория, называется физикализмом, она не&nbsp;отделяет разума от&nbsp;тела, то есть психическое состояние&nbsp;— есть физическое состояние.</p>
   <p>В&nbsp;контексте искусственного интеллекта часто рассматривается теория дуализма свойств. В&nbsp;данной теории ментальность рассматривается с&nbsp;точки зрения свойства сознания, то есть утверждается, что&nbsp;иметь разум&nbsp;— значит обладать определенными свойствами [16]. Дуализм свойств противопоставляется как&nbsp;онтологическим монистическим взглядам, так и дуализму сущностей. Самым известным аргументом в&nbsp;пользу данной теории является «аргумент знания», который выдвинул Фрэнк Джексон [23]. Как&nbsp;основное следствие данной теории выступает утверждение, что&nbsp;ментальные свойства&nbsp;— это нечто большее чем физические свойства. Такое утверждение можно понимать двумя способами:</p>
   <ol>
    <li><p>Психические свойства обладают независимыми причинно‑следственными связями и могут оказывать влияние на&nbsp;физический мир.</p></li>
    <li><p>Психические свойства должны&nbsp;быть способны изменяться вне зависимости от&nbsp;своих физических состояний.</p></li>
   </ol>
   <p>Более конкретной теорией, которую стоит упомянуть в&nbsp;контексте ИИ, является «типовая теория сознания». Данная теория основывается на&nbsp;утверждение, что&nbsp;одному состоянию мозга соответствует одно психическое состояние [37].</p>
   <h2>Искусственный интеллект</h2>
   <p>Началом теории искусственного интеллекта принято считать выход статьи Алана Тьюринга в 1950&nbsp;году, где ставился вопрос: «Может&nbsp;ли машина думать?» [28]. Тьюринг считал, что&nbsp;используемые в&nbsp;этом вопросе термины плохо определены и предлагал использовать «игру в&nbsp;имитацию», через которую определял думающие субъекты. Данная игра сейчас широко известна как&nbsp;тест Тьюринга.</p>
   <p>Алан Тьюринг предлагал считать машину разумной в&nbsp;случае, если в&nbsp;результате общение с&nbsp;экспертом, в&nbsp;течение некоторого времени, данный эксперт придет ко мнению, что&nbsp;общается с&nbsp;человеком, а&nbsp;не&nbsp;с&nbsp;машиной. На&nbsp;сегодняшний день данный тест принято считать ненадежным и не&nbsp;показывающим наличие разума или&nbsp;сознания у&nbsp;машины.</p>
   <p>Современное определение ИИ&nbsp;было введено Джоном Маккарти, искусственный интеллект&nbsp;— свойство интеллектуальных систем выполнять творческие функции, которые традиционно считаются прерогативой человека; наука и технология создания интеллектуальных машин, особенно интеллектуальных компьютерных программ [35].</p>
   <p>В&nbsp;современной науке нет четкого определения термина «интеллект», которое не&nbsp;привязано к&nbsp;человеческому интеллекту. В&nbsp;данном случае основная проблема связана с&nbsp;тем, что&nbsp;интеллект, в&nbsp;частности ИИ не&nbsp;обязательно связан с&nbsp;человеческим интеллектом а, трудности в&nbsp;создание ИИ связаны с&nbsp;незнанием многих свойств интеллекта или&nbsp;не&nbsp;пониманием работы известных свойств.</p>
   <p>Интересным является факт того, что&nbsp;в&nbsp;своей статье 2007&nbsp;года Маккарти, аналогично Хофштадтеру, делает утверждение, что&nbsp;машина, не&nbsp;имеющая сознание не&nbsp;сможет научиться играть в «Го». Но&nbsp;в 2016&nbsp;году нейронная сеть AlphaGo смогла обыграть чемпиона мира в «Го», хотя данная программа не&nbsp;проявляет никаких признаков сознания.</p>
   <p>Так как&nbsp;работа в&nbsp;области ИИ направлена на&nbsp;воспроизведение интеллектуальной деятельности человека, то и классификацию ИИ принято производить по&nbsp;сходству с&nbsp;возможностями интеллекта человека. Выделяют два основных вида классификации. Согласно первому способу, выделяются четыре класса ИИ [33]:</p>
   <ol>
    <li><p>Реактивные машины. Данные машины не&nbsp;способны создавать воспоминания и использовать прошлый опыт.</p></li>
    <li><p>Машины с&nbsp;ограниченной памятью. Это машины, которые не&nbsp;только обладают возможностями чисто реактивных машин, но&nbsp;и способны учиться принятию решений на&nbsp;основе исторических данных. Почти все существующие приложения, о&nbsp;которых мы знаем, относятся к&nbsp;этой категории ИИ.</p></li>
    <li><p>Машины с&nbsp;моделью психического состояния. Машины, которые понимают, что&nbsp;другие объекты в&nbsp;мире могут иметь свои мысли и эмоции, которые влияют на&nbsp;их поведение.</p></li>
    <li><p>Машины с&nbsp;самосознанием. Машины, которые могут формировать представление о&nbsp;себе.</p></li>
   </ol>
   <p>Другой метод классификации предлагает три класса ИИ, данный метод больше подходит для&nbsp;практического применения:</p>
   <ol>
    <li><p>Узкий искусственный интеллект. Это ИИ, который используя методы схожие с&nbsp;человеческими, автономно, способен выполнять узкие задачи.</p></li>
    <li><p>Общий искусственный интеллект. Это ИИ который полностью подобен человеку в&nbsp;интеллектуальной деятельности.</p></li>
    <li><p>Искусственный супе‑интеллект. Это ИИ, который превосходит все интеллектуальные возможности человека.</p></li>
   </ol>
   <p>При&nbsp;рассмотрении «сознания» в&nbsp;рамках создания ИИ требуется рассмотреть понятия слабый и сильный искусственный интеллект. Под&nbsp;слабым искусственным интеллектом понимают машину, которая способна выполнять высокоинтеллектуальные задачи, которые выполняет человек, но&nbsp;не&nbsp;будет обладать сознанием. Под&nbsp;сильным ИИ подразумевают машину, которая способна решать сложные интеллектуальные, но&nbsp;при&nbsp;этом обладает собственным сознанием и действительно мыслит.</p>
   <p>Современные исследователи не&nbsp;сомневаются в&nbsp;слабом ИИ и их не&nbsp;волнует сильный ИИ, до&nbsp;тех пор, пока машина выполняет свою задачу нет разницы есть&nbsp;ли у&nbsp;нее сознание.</p>
   <p>При&nbsp;этом, в&nbsp;философии интересен вопрос создания сильного искусственного интеллекта. Еще с&nbsp;момента написания ранее упомянутой статьи Алана Тьюринга идут неугасающие споры о&nbsp;возможности создания сильного ИИ и методов определения наличия сознания у&nbsp;машины. Например, Джефферсон считал, что&nbsp;единственной возможностью определить есть&nbsp;ли у&nbsp;машины сознания является возможность стать этой машиной и понять, что&nbsp;действительно есть сознание [24]. С&nbsp;другой стороны, Курцвейл утверждает, что&nbsp;возможность создания сильного ИИ заключается в&nbsp;создание вычислительной системы с&nbsp;мощностью равной мощности человеческого мозга, что&nbsp;ожидается в 2030&nbsp;году, учитывая текущие темпы роста производительности. И возможностью спроектировать человеческий мозг [34]. Данная позиция не&nbsp;бесспорна, что&nbsp;можно показать мысленным экспериментом «Китайская комната», который более подробно будет рассмотрен далее в&nbsp;данной работе.</p>
   <h2>Современный искусственный интеллект и основные аспекты сознания</h2>
   <p>Исходя из&nbsp;предыдущей главы можно сделать предположение, что&nbsp;сознание должно возникать в&nbsp;ИИ с&nbsp;моделью психического состояния (Theory of mind). Модель психического сознания&nbsp;— это способность как&nbsp;собственные, так и сторонние убеждения, намерения и знания, что&nbsp;позволяет объяснять и прогнозировать поведение [26]. Существуют различные теории модели психического состояния особый интерес в&nbsp;данном случае представляет вычислительная модель психического состояния («вычислительная теория разума», ВТР).</p>
   <p>Данная теория заключается в&nbsp;идее о&nbsp;том, что&nbsp;интеллект является вычислительной системой, которая по&nbsp;своим параметрам и умственным процессам похожа на&nbsp;машину Тьюринга и ее вычислительные процессы соответственно [38]. ВТР предполагает, что&nbsp;разум не&nbsp;просто похож на&nbsp;вычислительную систему, а&nbsp;является ей. При&nbsp;таком подходе, абстрагируясь от&nbsp;конкретной технической реализации, можно получить абстрактную вычислительную модель, описывающую основные психические процессы.</p>
   <p>Данную теорию ввел Хилари Путнэм [14], он противопоставлял ее теории идентификации типа и логическому бихевиоризму. Согласно данной теории, система имеет разум, когда имеет соответствующий функционал. Психические состояния&nbsp;— это состояния, играющие роль в&nbsp;функциональной организации системы, каждое из&nbsp;которых отделено взаимодействиями с&nbsp;моторным выходом, с&nbsp;сенсорным входом, и другими психическими состояниями.</p>
   <p>Еще одной веткой в&nbsp;исследование ИИ стал коннекционизм, который вдохновлялся не&nbsp;логикой или&nbsp;вычислительной техникой, а&nbsp;нейрофизиологией. Такой подход породил технологию нейронных сетей, которые значительно отличаются от&nbsp;машины Тьюринга, но&nbsp;данные технологии не&nbsp;взаимоисключают друг друга. Существует два подхода, возможно реализовать нейронную сеть в&nbsp;классической модели, так можно и реализовать классическую модель в&nbsp;рекуррентной нейронной сети [32].</p>
   <p>Новый подход к&nbsp;моделированию психического состояния предлагает Алан Винфилд [21]. Он предлагает моделировать предполагаемы потребности и действия других объектов, сочетать результаты с&nbsp;заранее заданным инструкциями и на&nbsp;основе такого анализа выдавать конкретный ответ.</p>
   <p>Для&nbsp;достижения такого эффекта роботу необходимо заранее заданное «понимание» предметной области, например, роботу, который может симулировать результаты своего движения по&nbsp;определенной траектории необходимы базовые знание физики.</p>
   <p>На&nbsp;данный момент эта технология реализована для&nbsp;достаточно простых ситуаций. Следующим шагом в&nbsp;развитие является возможность словесного описания роботом своих намерений и прошлых действий, а&nbsp;также возможность взаимодействия между несколькими роботами.</p>
   <p>Многие исследователи, в&nbsp;частности Амели Шрайбер [39] считают, что&nbsp;необходимо обратить свое внимание и на&nbsp;другие виды разума, отличные от&nbsp;человеческого, например, на&nbsp;разум животных. Такие виды разума могут стать ключом к&nbsp;пониманию интеллекта, который значительно отличается и в&nbsp;некоторых аспектах превосходит человеческий.</p>
   <p>Часто в&nbsp;современной философии возникают концептуальные основания для&nbsp;идеи о&nbsp;том, что&nbsp;преднамеренные состояния не&nbsp;относятся к&nbsp;животным или&nbsp;компьютерам [30]. Данная аргументация строится на&nbsp;введение интенциональности, которую пытаются применить к&nbsp;животным, показывая, что&nbsp;это невозможно. Значительная часть таких идей построена на&nbsp;том, что&nbsp;для&nbsp;того, чтобы иметь концепцию убеждения необходимо иметь возможность интерпретировать ее в&nbsp;лингвистических высказываниях.</p>
   <p>Рассмотрение данных концепций выходит за&nbsp;рамки работы, но&nbsp;общий вывод можно сформулировать так: необходимым условием для&nbsp;существования интенциональности является использованием языка. В&nbsp;рамках изучения искусственного интеллекта, чаще всего интенциональность рассматривается как&nbsp;свойство машины, основывающееся на&nbsp;используемых алгоритмах и инженерных знаниях. Цзичэнь Чжу предлагает четыре характеристики, которыми обладают интенциональные системы:</p>
   <ol>
    <li><p>Авторский замысел.</p></li>
    <li><p>Узнаваемое поведение.</p></li>
    <li><p>Системная автономность.</p></li>
    <li><p>Функциональная непрозрачность.</p></li>
   </ol>
   <p>Как&nbsp;один из&nbsp;вариантов решения проблемы определения самосознания у&nbsp;робота&nbsp;было предложено использовать зеркальный тест, аналогичный тесту с&nbsp;животными. Сам тест не&nbsp;признается достоверным, так как&nbsp;существуют причины, приводящие к&nbsp;ложноположительным или&nbsp;ложноотрицательным результатам. К&nbsp;примеру, используя метод с&nbsp;пятном краски можно получить ложноположительный результат, если сама краска является тактильным раздражителем, а&nbsp;ложноотрицательный в&nbsp;случае, если существу нравится его внешний вид с&nbsp;этим пятном.</p>
   <p>В 2013&nbsp;году&nbsp;был проведен эксперимент, в&nbsp;котором робот R с&nbsp;возможностью двигаться вперед и назад&nbsp;был проверен на&nbsp;возможность различать:</p>
   <ol>
    <li><p>собственное зеркальное отражение R;</p></li>
    <li><p>другого робота, имитирующего R;</p></li>
    <li><p>другого робота, управляемого R;</p></li>
    <li><p>робота, который ведет себя случайно.</p></li>
   </ol>
   <p>Данный тест показывает наличие самосознания у&nbsp;робота R.</p>
   <h2>Проблемы и критика</h2>
   <p>Попытки создания искусственного интеллекта сталкиваются с&nbsp;различными проблемами как&nbsp;фундаментальными, так и практическими.</p>
   <p>Теория машинного функционализма встала перед несколькими проблемами [20]. Первая из&nbsp;них называется «проблема продуктивности мышления». Данная проблема заключается в&nbsp;том, что&nbsp;психические состояния в&nbsp;машине отождествляются с&nbsp;конечным количеством состояний вероятностного автомата, когда человек может иметь счетное множество пропозиций. Безусловно, на&nbsp;практике человек способен входить в&nbsp;конечное число пропозиций, но&nbsp;это ограничивается продолжительностью жизни, а&nbsp;не&nbsp;некоторым психологическим законом. Таким образом, машинный функционализм ограничивает количество возможности человеческого познания.</p>
   <p>Другая проблема называется «проблемой систематичности мышления». Данная проблема выражается в&nbsp;том, что&nbsp;хорошая система должна отражать систематические связи, которыми обладают психические состояния. Но&nbsp;в&nbsp;машинном функционализме сопоставляются неструктурированные машинные состояния, в&nbsp;которых отсутствуют необходимые систематические связи с&nbsp;другими состояниями с&nbsp;психическими состояниями. По&nbsp;этой причине машинный функционализм не&nbsp;объясняет системности.</p>
   <p>ВТР имеет большое количество критики [38]. Одним из&nbsp;самых известных обвинений является обвинение в&nbsp;тривиальности. Критики теории показывают, что&nbsp;практически любую физическую систему можно описать как&nbsp;выполняющую вычисления. Сторонники теории опровергают это утверждение тем, что&nbsp;оно не&nbsp;включает в&nbsp;себя ограничения в&nbsp;технической реализации.</p>
   <p>Роджер Пенроуз приводит критику, основанную на&nbsp;теореме Геделя о&nbsp;полноте, показывая с&nbsp;ее помощью, что&nbsp;математические способности человека превышают математические способности машины Тьюринга [3]. Но&nbsp;на&nbsp;сегодня существует консенсус о&nbsp;том, что&nbsp;хотя и возможен такой исход его невозможно показать, используя теорему Геделя.</p>
   <p>Еще одним важным аргументом против ВТР является «проблема воплощенного сознания». Данный аргумент базируется на&nbsp;том, что&nbsp;ВТР рассматривает психическую активность только как&nbsp;статическую манипуляцию словами, не&nbsp;учитывая влияния окружающей среды. При&nbsp;этом существует множество способов влияния окружающей среды на&nbsp;ментальную активность.</p>
   <p>Критики подвергается и сама концепция искусственного интеллекта, точнее возможность создания сильного ИИ. Как&nbsp;один из&nbsp;главных аргументов к&nbsp;невозможности создания сильного ИИ является мысленный эксперимент «Китайская комната».</p>
   <p>Данный эксперимент&nbsp;был предложен Джоном Серлом в 1983&nbsp;году [18]. Серл предлагает представить англоязычного человека, который не&nbsp;знает китайского языка в&nbsp;закрытой комнате. Человеку передают некоторый текст на&nbsp;китайском языке, у&nbsp;него есть правила сопоставления одного китайского иероглифа другому и на&nbsp;основе этих правил человек в&nbsp;комнате составляет новый текст на&nbsp;китайском языке и возвращает из&nbsp;комнаты. При&nbsp;таком подходе человек вне комнаты будет уверен, что&nbsp;общается с&nbsp;человеком, владеющим китайским языком, так как&nbsp;получает разумный ответ на&nbsp;свой текст, но&nbsp;по&nbsp;условиям эксперимента человек в&nbsp;комнате не&nbsp;владеет китайским и не&nbsp;представляет значение текста на&nbsp;входе и на&nbsp;выходе.</p>
   <p>Данный эксперимент долгое время&nbsp;был одним из&nbsp;основных аргументов против возможности создания сильного ИИ, пока не&nbsp;был опровергнут Питером Кугелем в 2004&nbsp;году [25]. В&nbsp;данном опровержение выделяется три предположения, которые читатель должен принять:</p>
   <ol>
    <li><p>Комната обладает всеми возможностями компьютера.</p></li>
    <li><p>Комната создает видимость знание китайского языка.</p></li>
    <li><p>В&nbsp;действительности человек в&nbsp;комнате не&nbsp;знает китайского языка.</p></li>
   </ol>
   <p>Третье утверждение является верным, если принять первые два, но&nbsp;в&nbsp;действительности комната не&nbsp;обладает всеми возможностями компьютера, как&nbsp;следствие, все утверждения оказываются ложными. Как&nbsp;пример опровержения наличия видимого понимания китайского языка может служить замена человеком вне комнаты значения одного слова значением другого слова (заменить значение «плохой» на&nbsp;значение «хороший») и сообщить об&nbsp;этом человеку в&nbsp;комнате. Так как&nbsp;человек в&nbsp;комнате действует исключительно по&nbsp;правилам соответствия двух иероглифов, когда человек вне комнаты будет использовать слово с&nbsp;новым значением, он будет получать уже не&nbsp;осмысленный текст.</p>
   <p>Еще одной критикой ИИ в&nbsp;современном варианте является отсутствие у&nbsp;него грамматики и эмпатии [36]. Под&nbsp;грамматикой в&nbsp;данном случае понимается возможноcть распознавания закономерностей в&nbsp;окружающей среде. К&nbsp;примеру, не&nbsp;нейронная сеть, которая распознает&nbsp;лица на&nbsp;фотографиях работает как «черный ящик» назначая метки для&nbsp;объектов, а&nbsp;не «объясняет» свои действия: нахожу глаза на&nbsp;фотографии, затем рот и нос, признаю&nbsp;лицом человека.</p>
   <p>С&nbsp;точки зрения эмпатии современные алгоритмы способны распознать эмоции человека по&nbsp;фото или&nbsp;видео, но&nbsp;порождаемая ими реакция будет заранее заложена разработчиком. Такой алгоритм не&nbsp;способен определить причину эмоций и правильно отреагировать учитывая всю совокупность факторов, аналогично человеку.</p>
   <h2>Заключение</h2>
   <p>Многие существующие теории сознания сталкиваясь с&nbsp;концепцией сильного искусственного интеллекта приходят к&nbsp;проблемам и парадоксам. Самые сложные вопросы связаны с&nbsp;возможностью машины иметь реальные субъективные переживания.</p>
   <p>Большинство классических теорий требуют наличия промежуточного уровня для&nbsp;появления сознания. Но&nbsp;введение такого промежуточного уровня порождает новые проблемы, требуя объяснить определить этот уровень, его характеристики и связь с&nbsp;сознанием. Теории, основанные на&nbsp;данной идее, появляются из‑за того, что&nbsp;они кажутся более простыми и понятными, нежели само сознание.</p>
   <p>Но&nbsp;при проектирование разумных машин необходимы теории сознания, которые базируются на&nbsp;физическом мире, все упомянутые в&nbsp;главе «современный искусственный интеллект и основные аспекты сознания» основаны именно на&nbsp;данной парадигме. Для&nbsp;нахождения решения требуется отбросить предубеждение, которое формулируется в «трудной проблеме сознания», а&nbsp;именно отказаться от&nbsp;идеи того, что&nbsp;сознание является не&nbsp;физической сущностью.</p>
   <p>В&nbsp;контексте построения ИИ необходимо воспринимать сознание объект физического мира, который обладает всеми соответствующими свойствами, что&nbsp;его можно наблюдать и измерить. И что&nbsp;сознание находится в&nbsp;пространстве и времени и обладает причинно‑следственными связями. Возможно, ответ будет найден в&nbsp;области нейропсихологии, рассмотрение, которой&nbsp;было за&nbsp;рамками данной работы, учитывая то, что&nbsp;сегодня наиболее близкой технологией к&nbsp;сильному ИИ являются нейронные сети.</p>
   <p>Сегодня теорий ИИ и некоторые теорий сознания развиваются совместно. Однако можно заметить, что&nbsp;гипотеза «сильного» искусственного интеллекта ведет к&nbsp;несовместимости с&nbsp;ней многих существующих теорий сознания.</p>
   <p>Несмотря на&nbsp;то, что&nbsp;возможность появления «сильного» искусственного интеллекта не&nbsp;ясна, основные аргументы против него, такие как «китайская комната», все больше уступают новым разработкам в&nbsp;области «умных машин».</p>
   <h2>Список литературы</h2>
   <ol>
    <li><p>Васильев В. В. Трудная проблема сознания. / Васильев В. В. Москва: Прогресс‑Традиция, 2009&nbsp;г.</p></li>
    <li><p>Левитов Н. Д. О&nbsp;психических состояниях человека. / Левитов Н. Д. / Москва: Просвещение, 1964&nbsp;г.</p></li>
    <li><p>Пенроуз Р. Новый ум короля. О&nbsp;компьютерах, мышлении и законах физики» / Пенроуз Р. / Едиториал УРСС, ЛКИ, 2016.</p></li>
    <li><p>Прист С. Теории сознания. / Прист С. / Москва: Идея‑Пресс, 2000&nbsp;г.</p></li>
    <li><p>Хофштадтер Д. Р. Гёдель, Эшер, Бах: эта бесконечная гирлянда. / Хофштадтер Д. Р. / Самара: ИД «Бахрах‑М», 2001&nbsp;г.</p></li>
    <li><p>Чалмерс Д. Сознающий ум. В&nbsp;поисках фундаментальной теории. / Чалмерс Д. / Едиториал УРСС, 2019&nbsp;г.</p></li>
    <li><p>Braitenberg V. Vehicles: Experiments in synthetic psychology. / Braitenberg V. / Cambridge: MIT Press&nbsp;— 1984&nbsp;г.</p></li>
    <li><p>Bringsjord S., Govindarajulu N. Toward a Modern Geography of Minds, Machines, and Math. Philosophy and theory of artificial intelligence / Bringsjord S., Govindarajulu N. / Publisher: Springer&nbsp;— 2013&nbsp;г.&nbsp;— С. 151–165</p></li>
    <li><p>Churchland P. Neurophilosophy: toward a unified science of the mind/brain. / Churchland P. / MIT Press.&nbsp;— 1986&nbsp;г.</p></li>
    <li><p>Davidson D. Mind and Language. / Davidson D / Oxford University Press&nbsp;— 1975&nbsp;г.</p></li>
    <li><p>Dennett D. Consciousness Explained. / Dennett D / New York: Little, Brown&nbsp;— 1991&nbsp;г.</p></li>
    <li><p>Dennett D. C. The Intentional Stance. / Dennett D. C. / MIT Press&nbsp;— 1987&nbsp;г.</p></li>
    <li><p>Descartes R. Descartes and the Pineal Gland. / Descartes R. / Stanford University&nbsp;— 2013&nbsp;г.</p></li>
    <li><p>Putnam H. Psychophysical Predicates. / Putnam H. / Art, Mind, and Religion&nbsp;— 1976&nbsp;г.</p></li>
    <li><p>Russel S., J. Norvig, P. Artificial Intelligence. A Modern Approach. Third Edition. / Russel S., J. Norvig, P. / Harlow: Pearson Education Limited&nbsp;— 2016&nbsp;г.</p></li>
    <li><p>Salazar H., Hendricks C., Vintiadis E. Introduction to Philosophy: Philosophy of Mind. / Salazar H., Hendricks C., Vintiadis E., Asoulin E., Blum P., Haas D., Cheng T. / Rebus Foundation&nbsp;— 2019&nbsp;г.</p></li>
    <li><p>Schneider S., Velmans M. The Blackwell Companion to Consciousness. / Schneider S., Velmans M. / Wiley Blackwell&nbsp;— 2008&nbsp;г.</p></li>
    <li><p>Searle J. Intentionality. An essay in the philosophy of mind. / Searle J. / Cambridge University Press&nbsp;— 2012&nbsp;г.</p></li>
    <li><p>Sutherland S. Macmillan Dictionary of Psychology / Sutherland S. / Red Globe Press&nbsp;— 1989&nbsp;г.</p></li>
    <li><p>Fodor J., Block N. What Psychological States Are Not. / Fodor J., Block N. / The Philosophical Review&nbsp;— 1972&nbsp;г.&nbsp;— С 159–181</p></li>
    <li><p>Blum C., Hafner V., Winfield A. Simulation‑Based Internal Models for Safer Robots. / Blum C., Hafner V., Winfield A. // Frontiers in Robotics and AI&nbsp;— 2018&nbsp;г.&nbsp;— №&nbsp;4:74</p></li>
    <li><p>Chella A., Gaglio S. In Search of Computational Correlates of Artificial Qualia. / Chella A., Gaglio S. // Proceedings of the 2nd Conference on Artificial General Intelligence&nbsp;— 2009&nbsp;г.</p></li>
    <li><p>Jackson F. Epiphenomenal Qualia / Jackson F. // Philosophical Quarterly&nbsp;— 1982&nbsp;г.&nbsp;— №&nbsp;32&nbsp;— С127–136</p></li>
    <li><p>Jefferson G. The Mind of Mechanical Man. / Jefferson G. // British Medical Journal&nbsp;— 1949&nbsp;г.&nbsp;— №&nbsp;1(4616)&nbsp;— С 1105–1121.</p></li>
    <li><p>Kugel P. The Chinese room is a trick. / Kugel P. // Behavioral and brain sciences&nbsp;— 2004&nbsp;г.&nbsp;— №&nbsp;27&nbsp;— С 153–168</p></li>
    <li><p>Premack D., Woodruff G. Does the chimpanzee have a theory of mind? / Premack D., Woodruff G. // Behavioral and Brain Sciences&nbsp;— 1978&nbsp;г.&nbsp;— №&nbsp;1&nbsp;— С 515–526</p></li>
    <li><p>Turing A. M. On Computable Numbers, with an Application to the Entscheidungsproblem. / Turing A. M. // Proceedings of the London Mathematical Society&nbsp;— 1937&nbsp;г.&nbsp;— №&nbsp;42&nbsp;— с 230–265.</p></li>
    <li><p>Turing A. M. Computing Machinery and Intelligence. / Turing A. M. // Mind&nbsp;— 1950&nbsp;г.&nbsp;— №&nbsp;59&nbsp;— С 433&nbsp;— 460</p></li>
    <li><p>Vimal R. L. Meanings attributed to the term «consciousness». / Vimal R. L. // Journal of Consciousness Studies&nbsp;— 2009&nbsp;г.&nbsp;— №&nbsp;16(5)&nbsp;— С 9–27</p></li>
    <li><p>Allen C. Intentionality: Natural and Artificial. [Электронный ресурс] / Allen C. // Department of History &amp; Philosophy of Science. University of Pittsburgh.&nbsp;— 2021&nbsp;г. Режим доступа: <a href="https://colinallen.dnsalias.org/Papers/1995-CACS-Intentionality.pdf" rel="noopener noreferrer nofollow"><u>https://colinallen.dnsalias.org/Papers/1995-CACS‑Intentionality.pdf</u></a></p></li>
    <li><p>Coldeway D., Lardinois F. DeepL school»s other online translators with clever machine learning. [Электронный ресурс] / Coldeway D., Lardinois F. / 2021&nbsp;г.&nbsp;— Режим доступа: <a href="https://techcrunch.com/2017/08/29/deepl-schools-other-online-translators-with-clever-machine-learning/" rel="noopener noreferrer nofollow"><u>https://techcrunch.com/2017/08/29/deepl‑schools‑other‑online‑translators‑with‑clever‑machine‑learning/</u></a></p></li>
    <li><p>Graves A., Wayne G., Danihelka I. Neural Turing Machines [Электронный ресурс] / Graves A., Wayne G., Danihelka I. // 2021&nbsp;г.&nbsp;— Режим доступа: <a href="https://arxiv.org/pdf/1410.5401.pdf" rel="noopener noreferrer nofollow">https://arxiv.org/pdf/1410.5401.pdf</a></p></li>
    <li><p>Joshi N. 7&nbsp;Types Of Artificial Intelligence [Электронный ресурс] / Joshi N. // 2021&nbsp;г.&nbsp;— Режимдоступа: <a href="https://www.forbes.com/sites/cognitiveworld/2019/06/19/7-types-of-artificial-intelligence/?sh=6367aca233ee" rel="noopener noreferrer nofollow"><u>https://www.forbes.com/sites/cognitiveworld/2019/06/19/7-types‑of‑artificial‑intelligence/?sh=6367aca233ee</u></a></p></li>
    <li><p>Kurzweil R. Long Live AI. [Электронный ресурс] / Kurzweil R. // 2021&nbsp;г.&nbsp;— Режим доступа:<a href="https://www.forbes.com/home/free_forbes/2005/0815/030.html?sh=3c45acb85ff7" rel="noopener noreferrer nofollow"><u>https://www.forbes.com/home/free_forbes/2005/0815/030.html?sh=3c45acb85ff7</u></a></p></li>
    <li><p>McCarthy J. Artificial Intelligence. [Электронный ресурс] / McCarthy J. // 2021&nbsp;г.&nbsp;— Режим доступа: <a href="http://jmc.stanford.edu/artificial-intelligence/index.html" rel="noopener noreferrer nofollow"><u>http://jmc.stanford.edu/artificial‑intelligence/index.html</u></a></p></li>
    <li><p>Mumford D. Can an artificial intelligence machine be conscious? [Электронный ресурс] / Mumford D. // 2021&nbsp;г.&nbsp;— Режим доступа:<a href="https://www.dam.brown.edu/people/mumford/blog/2019/conscious.html" rel="noopener noreferrer nofollow"><u>https://www.dam.brown.edu/people/mumford/blog/2019/conscious.html</u></a></p></li>
    <li><p>Philosophy Index. Type Identity Theory. [Электронный ресурс] / 2021&nbsp;г.&nbsp;— Режим доступа: <a href="http://www.philosophy-index.com/philosophy/mind/type-physicalism.php" rel="noopener noreferrer nofollow"><u>http://www.philosophy‑index.com/philosophy/mind/type‑physicalism.php</u></a></p></li>
    <li><p>Rescorla M. The Computational Theory of Mind. [Электронный ресурс] / Rescorla M. // 2021&nbsp;г.&nbsp;— Режим доступа: <a href="https://plato.stanford.edu/entries/computational-mind/" rel="noopener noreferrer nofollow"><u>https://plato.stanford.edu/entries/computational‑mind/</u></a></p></li>
    <li><p>Schreiber A. AI Theory of Mind. [Электронный ресурс] / Schreiber A / 2021&nbsp;г.&nbsp;— Режим доступа: <a href="https://medium.com/@thesingularity.research/ai-theory-of-mind-faac45c988a" rel="noopener noreferrer nofollow"><u>https://medium.com/@thesingularity.research/ai‑theory‑of‑mind‑faac45c988a</u></a></p></li>
   </ol>
   <p></p>
  </div>
 </div>
</div> <!----> <!---->